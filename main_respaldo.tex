% Template LaTeX para Informes de Proyectos de Grado de Computación
% InCo, Facultad de Ingeniería, Universidad de la República
% 06/2023

\documentclass{prgrado}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Datos del Proyecto:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% título del proyecto (debe escribirse en minúscula, con excepción de la
% letra inicial de la primera palabra y nombres propios)
\title{Título que va a poner a su proyecto de grado}                   

% autores
\author{Santiago Silveira, Micaela Vaucher}  

% fecha de la defensa
\date{\today}                                 

% supervisor
\supervisor{Luis Chiruzzo}                

% cosupervisor (comentar si no tiene)
\cosupervisor{Santiago Góngora}

% licencia creative commons del documento
% opciones: by, by-sa, by-nd, by-nc, by-nc-sa y by-nc-nd
% opción por defecto: by-nc-nd versión 4.0
\cclicense{by}{4.0}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%links con colores 
\hypersetup{
  colorlinks   = true,
  urlcolor     = blue,
  linkcolor    = blue,
  citecolor    = red
}


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Parte inicial
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frontmatter % numeración en romanos, capitulos sin numerar

% carátula
\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% agradecimientos
\chapter*{Agradecimientos}

Agradecer, siempre es bueno agradecer.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% resumen
\chapter*{Resumen}

El resumen (200-500 palabras) debe dar una idea completa de todo el
proyecto, mencionando claramente los formalismos, técnicas, herramientas y lenguajes
utilizados. No debe limitarse a describir el problema abordado, sino que debe describir
la solución del problema, con una evaluación de la misma. No debe incluir referencias
bibliográficas ni referencias a otras partes del informe. Tampoco debe utilizar
acrónimos sin explicar su significado.


\hfill \break
\keywords{Template, Proyectos de Grado, Computación}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% índice
\tableofcontents
\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Parte central
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mainmatter %numeración en arábicos, numerar capítulos 

% introducción
\chapter{Introducción}

% Aquí se motiva el trabajo, se plantea y define el problema, se deja claro cuáles son los objetivos (general del proyecto, si correspondiese o si está inmerso en un proyecto de mayor alcance, y los específicos), se plantean los resultados esperados, se establecen resumidamente las conclusiones y se describe la
% organización general del documento.

% Este y los siguientes capítulos pueden incluir referencias, algunos ejemplos de referencias pueden ser \cite{RiedlBulitko}, \cite{CitekeyBook}, \cite{CitekeyInproceedings}, \cite{CitekeyManual} y \cite{CitekeyMisc}. Se sugiere citar usando el formato APA.

% 1 Introduccion
% 1.1 Objetivos
% 1.2 Estructura del documento

Todos hemos percibido, durante los últimos tres años, el avance acelerado que han tenido los \textbf{Grandes Modelos de Lenguaje}. Es un fenómeno que, por un lado, puede causar vértigo o preocupación por sus capacidades, pero que por otro lado abre una gran cantidad de puertas que despiertan la curiosidad por explorar qué es lo que pueden lograr y hasta dónde pueden llegar sus capacidades. Las posibilidades son enormes, y aunque existen muchas áreas donde vale la pena explorar este potencial, una que nos parece muy interesante es la de la \textbf{narrativa interactiva}, donde el jugador participa activamente en el desarrollo de una historia, tomando decisiones que afectan su curso \cite{riedl2013interactive}. Conociendo más esta área, nos topamos con la \textbf{ficción interactiva}, un género de videojuegos basados en texto donde el jugador explora mundos y resuelve desafíos mediante comandos escritos, lo que nos llevó a preguntarnos: ¿es posible pedirle a ChatGPT que genere ``un mundo'' y ``jugarlo'' o explorarlo mediante comandos de texto, como se hacía en los primeros videojuegos hace años (p. ej., la saga de videojuegos Zork)?

La narrativa interactiva busca que el jugador se sienta parte de un mundo vivo. Esta idea nos inspiró a hacernos algunas preguntas: ¿Puedo pedirle un mundo sobre mi película favorita y explorar finales alternativos? ¿Puedo hacer que tenga desafíos y un objetivo? ¿Sería posible construir un sistema que use un LLM no solo para contar una historia, sino también para crear todo un mundo de ficción interactiva desde cero y que tenga sentido? ¿Dónde está el límite y cuáles son los desafíos técnicos?

Consideremos un ejemplo concreto: Imaginemos pedirle al sistema: \textit{``Créame un mundo inspirado en Harry Potter''} y que el sistema genere automáticamente:

\begin{itemize}
    \item \textbf{Un mundo jugable}: Múltiples ubicaciones interconectadas (p. ej., Bosque Prohibido, Salón de Pociones, Torre de Astronomía)
    \item \textbf{Personajes con propósito}: NPCs temáticos que el jugador puede encontrar (p. ej., un profesor de pociones que necesita ingredientes)
    \item \textbf{Objetos funcionales}: Ítems que sirven para resolver desafíos (p. ej., una varita mágica, ingredientes de pociones)
    \item \textbf{Puzzles coherentes}: Acertijos relacionados con la temática (p. ej., resolver un enigma mágico para acceder a una ubicación bloqueada)
    \item \textbf{Un objetivo claro}: Una meta principal que da sentido a todo (p. ej., ``Encuentra los tres ingredientes para la poción curativa'')
\end{itemize}

El jugador entonces podría interactuar mediante comandos como \texttt{ir al Bosque Prohibido}, \texttt{hablar con el profesor}, \texttt{tomar la varita}, \texttt{resolver el acertijo}, y el sistema mantendría coherencia narrativa recordando acciones previas y adaptando la historia según las decisiones del jugador. Todo esto generado automáticamente por el LLM.

Al investigar sobre el tema, vimos que no éramos los únicos con estas ideas; existen varios sistemas que han abordado este problema de generación automática de mundos interactivos con enfoques muy particulares y distintos entre sí. Durante esta exploración, nos llamó la atención el enfoque neurosimbólico, el cual busca un balance entre usar el LLM para la parte creativa y fluida, y mantener estructuras lógicas para el estado del mundo, de esta manera proponiendo una forma controlada de actualizar lo que pasa durante el juego. Al ver que era posible, nuestro objetivo fue tomar esa base y trabajar sobre ella para intentar llevarla a un nivel más alto, explorando hasta dónde podíamos llevarla.

Partiendo de esta inquietud, intentamos construir un sistema neurosimbólico que genere mundos ficticios que personas puedan jugar como en un sistema de ficción interactiva, un problema que está capturando interés en la comunidad de Procesamiento de Lenguaje Natural y de investigación en videojuegos. Para abordar este desafío, utilizamos como base \textbf{PAYADOR}~\cite{payador}, un sistema neurosimbólico existente que ya implementaba la interacción mediante texto entre el jugador y el mundo. Esto nos permitió enfocarnos principalmente en el desafío de generación automática de mundos coherentes y jugables, junto con las extensiones arquitectónicas necesarias para soportar esta funcionalidad. El resultado de este trabajo es \textbf{IVIE} (\textit{Incremental Validated Interactive Experiences}).

La idea es que el sistema pueda \textbf{generar la aventura} completa de manera autónoma mediante un proceso de \textbf{generación incremental} ---esto es, construyendo el mundo paso a paso: desde el concepto general de la historia y el personaje, hasta un mundo jugable con sus ubicaciones y desafíos---, sin descuidar que esa aventura tenga sentido, y, asimismo, que todo gire en torno a un objetivo central que el jugador debe completar. En lugar de pedirle al modelo que haga todo de una sola vez, nuestro sistema va construyendo cada componente del mundo de forma iterativa y validada. Durante el desarrollo tuvimos que resolver problemas importantes, como la interpretación y estructuración de las respuestas en lenguaje natural del LLM en representaciones que el motor pueda procesar, y la implementación de un sistema de memoria que permita al modelo de narrador mantener coherencia contextual a lo largo de partidas extensas.

\section{Objetivos}

El objetivo general de este trabajo es diseñar, implementar y evaluar un sistema avanzado para la generación completa de mundos de ficción interactiva que sean coherentes, jugables y narrativamente interesantes.

Los objetivos específicos de este trabajo son los siguientes:

\begin{itemize}
    \item \textbf{Extender el enfoque neurosimbólico de PAYADOR}: Desarrollar un proceso de generación incremental que permita crear mundos complejos y jugables desde cero, superando las limitaciones del sistema original que requería mundos predefinidos.
    \item \textbf{Implementar una arquitectura \textit{goal-oriented}}: Diseñar un sistema donde toda la estructura del mundo (ubicaciones, personajes, objetos y puzzles) esté lógica y narrativamente conectada a un objetivo principal a cumplir en el escenario jugable (p. ej., conseguir una llave de color dorado), garantizando que cada elemento tenga un propósito dentro de la experiencia de juego.
    \item \textbf{Garantizar la coherencia estructural del mundo}: Desarrollar validaciones automáticas mediante tests lógicos simbólicos que aseguren la conectividad espacial de las ubicaciones, la accesibilidad de los recursos necesarios, y la completabilidad del objetivo principal.
    \item \textbf{Integrar memoria contextual}: Implementar un sistema de memoria que permita al modelo de narrador recordar eventos, diálogos y acciones previas del jugador, mejorando la coherencia narrativa y la profundidad de las interacciones durante partidas extensas.
    \item \textbf{Implementar persistencia y rejugabilidad}: Desarrollar funcionalidades que permitan guardar mundos generados para ser rejugados posteriormente, así como visualizar el historial completo de partidas anteriores, facilitando tanto la reutilización de contenido exitoso como el análisis de las experiencias de juego.
    \item \textbf{Desarrollar una interfaz de usuario mejorada}: Crear una nueva interfaz que facilite la interacción del jugador con el sistema, en especial con estas nuevas funcionalidades.
    \item \textbf{Evaluar el sistema con múltiples LLMs}: Comparar el rendimiento y la calidad de las generaciones utilizando al menos dos modelos de lenguaje distintos (Google Gemini y OpenAI GPT-4o-mini), analizando diferencias en coherencia narrativa, cumplimiento de restricciones, y experiencia del usuario.
     \item \textbf{Validar la compatibilidad de PAYADOR con generación procedimental}: Comprobar si el enfoque neurosimbólico de PAYADOR es compatible con técnicas de generación procedimental mediante LLMs, identificando las capacidades y limitaciones de esta integración.
\end{itemize}

\section{Estructura del documento}

El presente documento se organiza de la siguiente manera. En el Capítulo~\ref{cap:marco} revisamos los conceptos fundamentales de la narrativa interactiva, la generación procedimental de contenido y la evolución de los modelos de lenguaje. Además, analizamos las arquitecturas de referencia en el campo del \textit{storytelling} interactivo con LLMs, y presentamos el enfoque neurosimbólico y PAYADOR, que será usado en el trabajo presentado en este documento. El Capítulo~\ref{cap:central} detalla en profundidad el diseño y la implementación de nuestro sistema, describiendo la arquitectura del proceso de generación incremental, los esquemas de datos, el constructor de mundos, la lógica de validación y la integración del sistema de memoria. En el Capítulo~\ref{cap:experimentacion} presentamos el diseño experimental, la configuración del entorno de pruebas y la metodología utilizada para evaluar la calidad técnica de los mundos generados y la experiencia de usuario, seguido de un análisis de los resultados obtenidos. Finalmente, en el Capítulo~\ref{cap:conclusiones} sintetizamos el trabajo presentado en este documento, discutimos las conclusiones extraídas de la experimentación y proponemos futuras mejoras y líneas de investigación y desarrollo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% antecedentes
\chapter{Marco Teórico y Estado del Arte} \label{cap:marco}

En este capítulo presentamos los conceptos clave necesarios para comprender el trabajo desarrollado: narrativa interactiva y generación procedimental de contenido, Grandes Modelos de Lenguaje y técnicas para intentar controlar y mejorar la forma en que genera sus salidas, arquitecturas neurosimbólicas que combinan creatividad lingüística con representaciones simbólicas del mundo, y finalmente PAYADOR, el framework neurosimbólico sobre el cual construimos IVIE.


\section{Narrativa Interactiva y Generación de Mundos}

En esta sección describimos los conceptos centrales del storytelling interactivo y las estrategias para generar mundos de juego. Se discuten formas paradigmáticas de narrativa, la evolución de los juegos de rol computarizados y técnicas de generación procedimental que favorecen la rejugabilidad y la improvisación.


\subsection{Storytelling Interactivo e Improvisacional}

% El \textit{storytelling} interactivo se caracteriza por la participación activa del usuario en el desarrollo narrativo, donde las decisiones y acciones influyen en el curso de la historia. Esta forma de narrativa se distingue por tres conceptos fundamentales: interactividad, improvisación y narrativa emergente.

% La \textbf{narrativa interactiva} es una forma de experiencia interactiva digital en la cual los usuarios crean o influencian una historia dramática a través de sus acciones \cite{RiedlBulitko}. El objetivo de un sistema de narrativa interactiva es sumergir a los usuarios en un mundo virtual de tal manera que crean que son una parte integral de una historia que se desarrolla y que sus acciones pueden alterar significativamente la dirección o el resultado de la historia.

% La distinción entre la narrativa interactiva y otras formas de entretenimiento digital es que los sistemas de narrativa interactiva permiten al jugador actuar de maneras que alteran fundamentalmente la dirección o el resultado de la historia que se desarrolla \cite{RiedlBulitko}. La agencia del usuario (su capacidad de control sobre el desarrollo narrativo) es una característica clave que predice una mayor conexión entre el usuario y los personajes o la historia \cite{DillmanCarpentierRogersBarnard2015}. Esta capacidad de influir en la narrativa a través de las acciones del usuario constituye el elemento central de la interactividad en estos sistemas, y se manifiesta de diversas formas en juegos como los libros de `elige tu propia aventura' (CYOA) y los juegos de rol de mesa (TTRPGs), como se explorará más adelante.

% La \textbf{improvisación} en el contexto narrativo se entiende generalmente como la coincidencia entre invención y ejecución, es decir, como una creación que ocurre en el mismo momento de su realización. Una actuación es improvisada cuando aquello que se produce mediante las acciones de los participantes no resulta de ejecutar un plan de acción predeterminado, sino que se inventa `sobre la marcha' \cite{BertinettoBertram2020}.
% Sin embargo, como señala Schiaffini (2006), improvisar no equivale simplemente a ser creativo o espontáneo: es una práctica que requiere técnica, memoria, aprendizaje y una profunda conciencia del contexto cultural y musical que la sustenta, por lo que en este sentido, puede entenderse no como ausencia de estructura, sino como un equilibrio dinámico entre preparación y creación \cite{Sawyer2000}.

La narrativa convencional sitúa al espectador en un rol pasivo, donde la historia se desarrolla de manera predeterminada sin posibilidad de intervención. Sin embargo, las narrativas digitales han transformado esta dinámica, permitiendo que el experimentador asuma un rol activo en el desarrollo de la historia \cite{trichopoulos2023digital}.

La \textbf{narrativa interactiva} (\textit{Interactive Storytelling}, en inglés) es una forma de experiencia interactiva digital en la cual los usuarios crean o influencian una historia dramática a través de sus acciones \cite{RiedlBulitko}. El objetivo de un sistema de narrativa interactiva es sumergir a los usuarios en un mundo virtual de tal manera que tengan la sensación de que son una parte integral de una historia que se desarrolla.

Estas historias suceden en lo que denominamos \textbf{mundos ficticios}, espacios virtuales donde habitan diferentes tipos de personajes. Los personajes que el usuario puede controlar directamente se denominan \textbf{personajes jugables} o \textbf{personajes de jugador}. Por otro lado, los personajes que son controlados por el sistema (ya sea mediante inteligencia artificial, reglas predefinidas, o ambas) se denominan \textbf{Personajes No Jugables} (NPCs, por sus siglas en inglés \textit{Non-Player Characters}). La interacción entre el personaje jugable y los NPCs, así como con el entorno del mundo ficticio, constituye la base de la experiencia narrativa interactiva.

Esta narrativa, además, se caracteriza por tres conceptos fundamentales: interactividad, improvisación y narrativa emergente. La distinción clave con otras formas de entretenimiento digital radica en la \textbf{libertad del usuario}, es decir, su capacidad de actuar de maneras que alteran fundamentalmente la dirección o el resultado de la historia \cite{RiedlBulitko}. Diversos estudios han demostrado que esta capacidad de libertad genera una mayor conexión emocional entre el usuario y los personajes o la historia \cite{DillmanCarpentierRogersBarnard2015}. Esta interactividad se manifiesta de diversas formas en distintos medios, desde libros interactivos de `Elige tu propia aventura' (CYOA) hasta los juegos de rol de mesa (TTRPGs), como se explorará más adelante.

La \textbf{improvisación} en el contexto narrativo se entiende generalmente como la coincidencia entre invención y ejecución, es decir, como una creación que ocurre en el mismo momento de su realización. Una actuación es improvisada cuando aquello que se produce mediante las acciones de los participantes no resulta de ejecutar un plan de acción predeterminado, sino que se inventa `sobre la marcha' \cite{BertinettoBertram2020}.

Sin embargo, improvisar no equivale simplemente a ser creativo o espontáneo. Aunque Schiaffini ~\cite{Schiaffini2006} analiza este concepto en el contexto de la improvisación musical, sus observaciones son aplicables a la narrativa interactiva: la improvisación es una práctica que requiere técnica, memoria, aprendizaje y una profunda conciencia del contexto cultural que la sustenta, por lo que en este sentido, puede entenderse no como ausencia de estructura, sino como un equilibrio dinámico entre preparación y creación \cite{Sawyer2000}.

La \textbf{Narrativa Emergente} es un paradigma de \textit{storytelling} interactivo que busca crear experiencias narrativas en tiempo real utilizando la interacción entre los actores como mecanismo generativo \cite{RiedlBulitko}. Este enfoque surge como un intento de resolver la `paradoja narrativa' (\textit{narrative paradox}), que establece un conflicto entre las estructuras de trama previamente diseñadas por los autores y la libertad de acción del jugador (\textit{player agency}) característica de los medios interactivos en entornos gráficos en tiempo real \cite{Aylett1999}.

En un sistema de narrativa emergente, la historia se crea de abajo hacia arriba (\textit{bottom-up}) a través de la interacción entre componentes esencialmente simples, a diferencia de los modelos narrativos tradicionales, donde el proceso ocurre a la inversa (\textit{top-down}), dirigidos por un guion predefinido \cite{Aylett1999}. La narrativa emerge de la actividad fortuita del personaje en ese mundo (\textit{happenstance of character activity}) \cite{GustafssonHolmeMackay2020}. Cuando se opera a un nivel de alta interactividad, se sitúa en el extremo más participativo del espectro, donde el usuario y los NPCs autónomos asumen conjuntamente la responsabilidad del desarrollo de la historia. Esto significa que, si bien la progresión coherente de la historia es un desafío central, la experiencia del usuario está impulsada por las decisiones no coordinadas de los NPCs y las acciones del propio usuario \cite{RiedlBulitko}.

Para comprender mejor el espectro de la narrativa interactiva y cómo estos conceptos se manifiestan en la práctica, a continuación examinaremos dos ejemplos paradigmáticos: los libros de ``elige tu propia aventura'' (CYOA) y los juegos de rol de mesa (TTRPGs). Estos últimos están particularmente relacionados con el concepto de narrativa emergente, ya que las historias en estos juegos se generan precisamente por la actividad de juego de rol de los participantes humanos, donde la trama emerge de manera \textit{bottom-up} a través de la interacción entre jugadores, el director del juego, y las mecánicas del sistema \cite{AylettLouchart2007}.

\subsubsection{Literatura de `Elige Tu Propia Aventura'}

Los libros del género \textit{Gamebook}, ampliamente conocidos como Choose Your Own Adventure (CYOA), representan una de las formas más tempranas y populares de narrativa interactiva. Estos libros permiten al lector tomar decisiones en puntos específicos de la historia, navegando a diferentes páginas según sus elecciones, creando así una experiencia de lectura \textbf{no lineal}—es decir, donde no existe una única secuencia predeterminada de eventos, sino múltiples caminos posibles que el lector puede explorar según sus decisiones. En la investigación de Procesamiento de Lenguaje Natural, estos libros siguen siendo relevantes como ejemplos fundamentales para el estudio de estructuras narrativas ramificadas y toma de decisiones en narrativas interactivas \cite{Tikhonov2024}.

Los libros CYOA fueron popularizados en la década de 1970 cuando la serie original de Edward Packard, comenzando con \textit{The Cave of Time} (1979), estableció el modelo de narrativa ramificada como un género literario legítimo \cite{bachmann2024bitter}. La serie, publicada por Bantam Books entre 1979 y 1998, alcanzó un éxito inmense con 184 libros en su tirada original, convirtiéndose en un fenómeno cultural que expuso a millones de lectores angloparlantes a la narrativa interactiva durante la década de 1980 \cite{bachmann2024bitter}. Su impacto ha trascendido el medio literario, inspirando videojuegos, aplicaciones educativas, y sistemas de aprendizaje interactivo. La simplicidad del modelo de ramificación de estos libros, donde cada decisión lleva a un nuevo nodo narrativo, ha permitido su aplicabilidad en diversos contextos, tanto para propósitos educativos como de entretenimiento \cite{SimonTattleTaleSW}. Esto incluye la creación de experiencias de aprendizaje adaptativo donde los estudiantes toman decisiones que afectan su recorrido educativo \cite{OhLimHwang2020}, así como herramientas de storytelling que permiten crear variaciones sobre una historia base o extender narrativas existentes \cite{PorteousEtAl2021}.

\subsubsection{Juegos de Rol de Mesa}
En contraste con el modelo de ramificación pre-autorizada de los CYOA, los juegos de rol de mesa (Tabletop Role-Playing Games, TTRPGs) constituyen una actividad de narrativa colaborativa donde los jugadores toman el rol de un personaje ficticio e interactúan en un entorno narrativo compartido \cite{AlmenEkman2022}. A diferencia de otros juegos de mesa, los TTRPGs enfatizan la creatividad, la improvisación y el trabajo en equipo. Los jugadores crean sus propios personajes con habilidades únicas, que luego utilizan para navegar escenarios ficticios dirigidos por un Game Master (GM).

El GM actúa como narrador, guiando la historia e interpretando las reglas mientras los jugadores toman decisiones que moldean el resultado \cite{AlmenEkman2022}. Los TTRPGs utilizan mecánicas como tiradas de dados y estadísticas para resolver desafíos, añadiendo un elemento de azar y estrategia. Estos juegos frecuentemente se basan en escenarios de fantasía, ciencia ficción o históricos que sumergen a los jugadores en mundos ricos y detallados.

A diferencia de los sistemas de narrativa de ramificación (CYOA), donde todas las trayectorias narrativas están predefinidas, la narrativa emergente en los TTRPGs resulta de la interacción en tiempo real entre los NPCs (controlados por el director del juego), los jugadores, y las mecánicas del sistema de juego. La experiencia es impulsada enteramente por las decisiones no coordinadas de los jugadores humanos, las respuestas del director del juego, y las consecuencias emergentes de las reglas del sistema \cite{RiedlBulitko}. En este sentido, los TTRPGs representan el extremo opuesto en cuanto a la interactividad: mientras los CYOA ofrecen un conjunto finito de caminos narrativos predefinidos, los TTRPGs generan historias únicas e irrepetibles a través de la improvisación colaborativa, ejemplificando así el concepto de narrativa emergente discutido anteriormente.

\subsubsection{Videojuegos de Decisión Narrativa}

Entre los extremos del espectro representados por los CYOA y los TTRPGs, los videojuegos de decisión narrativa contemporáneos, como \textit{Life is Strange}, \textit{The Walking Dead} de Telltale Games, o \textit{Detroit: Become Human}, ocupan un espacio intermedio significativo. Estos juegos utilizan grafos de ramificación (\textit{branching story graphs}) donde los nodos representan fragmentos de contenido narrativo autorizado y los arcos dirigidos representan las elecciones explícitas que los usuarios pueden tomar \cite{RiedlBulitko}. Cada trayectoria narrativa posible está manualmente autorizada, lo que asegura que la visión del autor se preserve con precisión, aunque todas las posibilidades están predeterminadas y codificadas \textit{ex ante} por los desarrolladores \cite{Trapova2021}.

La narrativa ramificada puede entenderse como una forma mínimamente interactiva de participación, que permite navegar un conjunto de posibilidades pre-autorizadas a través de decisiones del usuario en puntos de elección específicos, aislando así las posibilidades interactivas de los elementos narrativos no interactivos \cite{AylettLouchart2007}. Esta distinción se vuelve particularmente evidente en videojuegos donde escenas cinemáticas completamente guionizadas (\textit{cut scenes}) se intercalan con elecciones interactivas.

A diferencia de los CYOA tradicionales, estos videojuegos generan grafos de magnitud considerable, con múltiples variables de estado que rastrean las decisiones del jugador a lo largo del tiempo. Esta complejidad arquitectónica crea una \textit{ilusión de libertad ilimitada}, aunque las líneas narrativas ramificadas resultan en que los jugadores tengan cierta libertad, pero sus elecciones son limitadas y deben ser previstas por el escritor \cite{PeinadoGervas2004}. El contenido narrativo que debe ser creado puede crecer exponencialmente con el número de puntos de elección, presentando limitaciones prácticas significativas \cite{RiedlBulitko}.

En términos de la taxonomía propuesta por Riedl y Bulitko \cite{RiedlBulitko}, estos sistemas se sitúan en el extremo de fuerte intención autorial, donde los NPCs carecen de autonomía real y responden según patrones predefinidos. Esta aproximación representa un compromiso pragmático entre mantener la coherencia narrativa y ofrecer experiencias interactivas, pero permanece fundamentalmente distinta de los sistemas de narrativa emergente donde la historia surge de manera improvisada.


\subsection{Juegos de Rol Computarizados}

\subsubsection{Evolución Histórica: De Text Adventures a CRPGs Modernos}
La historia de los juegos de rol computarizados (CRPGs) está estrechamente vinculada con la evolución de las interfaces de lenguaje y los modelos de interacción entre jugador y sistema. Desde sus orígenes, ciertos juegos digitales han buscado emular, con distintos grados de éxito, la libertad narrativa que caracteriza a los juegos de rol de mesa como Dungeons \& Dragons.

En los años 1970 y 1980, las primeras \textit{text adventures} como Zork introdujeron un paradigma interactivo basado exclusivamente en texto. Estos juegos, antecesores de la ficción interactiva moderna, dependían de la capacidad del jugador para comunicarse mediante comandos escritos que el sistema debía interpretar. Aún así, estas experiencias presentaban limitaciones importantes: los \textit{parsers} tenían un vocabulario restringido y no siempre podían reconocer o contextualizar las acciones del jugador, lo que afectaba la inmersión. Aun así, sentaron las bases para el desarrollo de interfaces de lenguaje más expresivas y sistemas de interpretación semántica más flexibles \cite{Tikhonov2024}.

Durante los años 1990, los CRPGs comenzaron a incorporar elementos visuales y sistemas de reglas derivados directamente de los juegos de rol tradicionales. Títulos como Baldur’s Gate (1998) trasladaron al entorno digital la estructura narrativa y mecánica de Dungeons \& Dragons, combinando decisiones estratégicas con una narrativa ramificada. Décadas más tarde, Baldur’s Gate 3 (2023) retomó y expandió esa tradición: ofrece un nivel de libertad comparable al de una sesión de mesa, donde cada elección del jugador tiene consecuencias tangibles en el desarrollo de la historia \cite{Corpuz2024}. En este sentido, los CRPGs no solo replican el universo de D\&D, sino que lo amplían a través de un sistema híbrido entre reglas predefinidas y narrativa emergente, lo que constituye una forma de improvisación guiada por el sistema.

Con el avance del poder computacional en las décadas siguientes, la inteligencia artificial se volvió un componente esencial en la construcción de mundos y personajes interactivos. \citeA{Assaf2023} analiza cómo la IA pasó de algoritmos estáticos a sistemas capaces de adaptarse al comportamiento del jugador, introduciendo la noción de “IA dinámica”. Este cambio permitió la creación de entornos más impredecibles y personajes no jugadores (NPCs) con comportamientos verosímiles, lo que reforzó la sensación de libertad y coautoría narrativa.

En la actualidad, los sistemas de IA y los modelos de lenguaje natural abren nuevas posibilidades para el diseño de experiencias narrativas interactivas. El trabajo de \citeA{SimonTattleTaleSW} muestra que los modelos de planificación narrativa pueden guiar a los grandes modelos de lenguaje (LLMs) en la generación de historias, asegurando coherencia y consistencia sin limitar la flexibilidad del lenguaje natural. Estas ideas son especialmente relevantes para los juegos de rol conversacionales, donde el jugador interactúa directamente con el sistema mediante texto o voz, y donde la coherencia narrativa debe sostenerse en tiempo real.

Así, la evolución desde Zork hasta Baldur’s Gate 3 y los actuales experimentos con IA generativa evidencia una trayectoria común: el intento de equilibrar libertad creativa y estructura narrativa. En los chatbots de rol contemporáneos, este equilibrio se reinterpreta mediante la generación dinámica de mundos, personajes y eventos, donde el lenguaje se convierte en la interfaz principal entre jugador y ficción.

\subsubsection{Limitaciones de las Interfaces Clásicas}
Si bien los primeros juegos de rol computarizados (CRPGs) y las aventuras interactivas sentaron las bases del diálogo entre jugador y sistema, su diseño estaba condicionado por la naturaleza fija de los mundos que presentaban. Cada interacción, objeto y evento debía ser programado manualmente, lo que restringía la posibilidad de sorpresa y rejugabilidad. Según \citeA{Tikhonov2022}, los sistemas basados en parsers clásicos, como los de \textit{Zork}, sufrían limitaciones tanto técnicas como conceptuales: comandos no reconocidos, respuestas repetitivas y una falta de adaptabilidad frente a las acciones del jugador. Estas restricciones afectaban la inmersión y generaban frustración cuando el sistema no podía interpretar acciones aparentemente lógicas dentro del contexto narrativo.

Además, la naturaleza predefinida de los mundos implicaba un alto costo de desarrollo. La creación manual de niveles, personajes y reglas requiere equipos numerosos y largos períodos de trabajo, lo que limita la diversidad y experimentación en el diseño \cite{Shaker2016}. En este sentido, el problema no es únicamente técnico, sino también estructural: un modelo de desarrollo centrado en el contenido estático reducía las posibilidades de crear narrativas verdaderamente personalizadas.

Toda historia interactiva enfrenta una tensión inherente entre libertad y estructura \cite{FernandezVara2011}. En los primeros juegos de aventura, esta tensión se resolvía restringiendo la cantidad de \textit{user agency} dentro de arcos narrativos cerrados y sistemas de reglas limitados. Con el tiempo, el género tendió hacia una simplificación de las acciones posibles y una mayor abstracción de las simulaciones, en un esfuerzo por mantener la coherencia narrativa a costa de la libertad de exploración \cite{FernandezVara2011}.

En síntesis, las limitaciones de las interfaces textuales y de los mundos predefinidos revelaron un desafío fundamental para la narrativa interactiva: cómo sostener la coherencia y la inmersión sin sacrificar la libertad del jugador. Esta problemática motiva la búsqueda de enfoques generativos que permitan equilibrar ambos extremos.


\subsection{Generación procedimental de Contenido (PCG)}

La transición hacia la generación procedimental de contenido (PCG, por sus siglas en inglés) surge como una respuesta directa a las limitaciones de los mundos manualmente diseñados. El término PCG se refiere a la creación algorítmica de contenido de juego —niveles, mapas, objetos, historias o reglas— mediante procedimientos computacionales con mínima o indirecta intervención humana \cite{Shaker2016}. Esta aproximación permite reducir costos de producción, aumentar la rejugabilidad y, sobre todo, habilitar experiencias personalizadas para cada jugador.

Los primeros experimentos exitosos en PCG se remontan a los años 1980 con juegos \textit{roguelike} como \textit{Rogue} o \textit{Diablo}, donde los niveles eran generados dinámicamente en cada partida. Sin embargo, los métodos empleados eran principalmente \textit{constructivos}, es decir, generaban estructuras fijas sin retroalimentación o evaluación del resultado \cite{Shaker2016}. Con el tiempo, el campo evolucionó hacia métodos más sofisticados, como los enfoques basados en búsqueda o los modelos de planificación, que permiten controlar la coherencia interna de los mundos generados.

El uso de técnicas procedimentales también abrió la posibilidad de desarrollar juegos adaptativos, capaces de modificar el entorno en función del comportamiento o las preferencias del jugador. Este enfoque, conocido como \textit{player-adaptive generation}, combina PCG con modelado de jugadores para ajustar dinámicamente la dificultad, el ritmo o la narrativa \cite{Shaker2016}. Así, la generación de contenido dejó de ser únicamente una cuestión de eficiencia para convertirse en una herramienta de diseño expresivo y creativo.

Según \citeA{TechBullion2023} y \citeA{Assaf2023}, el uso de algoritmos procedimentales marcó un punto de inflexión en la evolución de la inteligencia artificial en los videojuegos. Juegos como \textit{Spore} (2008) demostraron la capacidad de la IA para generar diversos mundos de juego, y así reducir el tiempo de desarrollo. Más recientemente, el uso de modelos generativos y aprendizaje profundo ha extendido esta tendencia hacia narrativas emergentes, donde el sistema no solo genera niveles o entornos, sino también NPC's que aprenden del jugador en tiempo real, ejemplos de esto siendo `Red Dead Redemption 2' y `The Last of Us 2'.

En este contexto, los modelos de planificación narrativa propuestos por \citeA{SimonTattleTaleSW} representan un punto de convergencia entre la generación procedimental y el lenguaje natural. Su trabajo demuestra que combinar planificación automática con modelos de lenguaje permite producir historias coherentes y flexibles, superando las limitaciones tanto de los sistemas predefinidos como de los modelos puramente estadísticos. En consecuencia, el campo de la narrativa interactiva se dirige hacia una integración entre PCG, IA adaptativa y modelos de lenguaje, donde el objetivo ya no es solo crear contenido, sino diseñar sistemas capaces de \textit{contar historias junto al jugador}.


\subsection{El Desafío de la Coherencia Diegética}

La generación de mundos narrativos mediante LLMs presenta desafíos específicos relacionados con la coherencia diegética—la consistencia interna del universo ficticio. A diferencia de la simple generación de texto narrativo, la creación de mundos requiere mantener la persistencia de elementos como ubicaciones, personajes, objetos y sus propiedades a lo largo de múltiples interacciones.

Los enfoques basados en modelos de lenguaje neural para la generación automatizada de historias sufren de limitaciones importantes en este aspecto. Primero, los generadores basados en modelos de lenguaje generalmente no trabajan hacia un objetivo o final dado. Segundo, a menudo pierden coherencia a medida que la historia se hace más larga \cite{Castricato2021}. Esta pérdida de coherencia es particularmente problemática para la generación de mundos, donde la inconsistencia puede manifestarse como personajes que olvidan información previamente establecida o ubicaciones que cambian sus descripciones sin justificación narrativa.

Simon \& Muise señalan que, si bien LLMs como GPT-3 pueden generar narrativas basadas en prompts, carecen de coherencia y pueden ser propensos a la repetición y al lenguaje artificial. Para superar estos problemas, proponen que el planning automatizado puede aplicarse a la generación de texto en lenguaje natural para crear narrativas coherentes y creíbles \cite{SimonTattleTaleSW}.

La tarea de crear dominios de planificación narrativa se ha identificado como un cuello de botella para el desarrollo del campo. Los dominios de planificación narrativa deben ser capaces de generar conjuntos diversos de narrativas para asegurar la rejugabilidad del sistema, y también deben poder responder de manera robusta ante fallas de ejecución narrativa debido a la interacción del usuario \cite{PorteousEtAl2021}. Porteous et al. introducen un enfoque novedoso basado en la expansión automática de un dominio de planificación base mediante la aplicación de operaciones principadas aplicadas tanto a operadores como a predicados, con el objetivo de mejorar la diversidad y robustez de los mundos generados.

En conjunto, estos enfoques apuntan a una integración híbrida entre planificación simbólica y generación neural, capaz de sostener mundos narrativos más estructurados y coherentes.

En la siguiente sección examinamos cómo los LLMs y técnicas como RAG y grounding pueden ayudar a mitigar estos problemas.




\section{Modelos de Lenguaje para Narrativa Interactiva}

Aquí examinamos las herramientas de lenguaje que permiten automatizar la generación narrativa: desde la evolución del NLP hasta técnicas modernas de prompting, estrategias para obtener salida estructurada, y mecanismos para extender la memoria del modelo (RAG) y anclar su conocimiento (grounding).


\subsection{Evolución del NLP hacia los LLMs}

El procesamiento de lenguaje natural ha evolucionado desde los sistemas basados en reglas hasta los modelos de lenguaje de gran escala. En 1957, Noam Chomsky introdujo las estructuras sintácticas, una teoría formal de la gramática generativa, sentando las bases de la lingüística moderna \cite{Chomsky1957}. No obstante, su visión del lenguaje como sistema estable y bien definido fue cuestionada por Charles Hockett \cite{Hockett1966}, quien señaló que tal formalización no reflejaba la complejidad y variabilidad del uso real del lenguaje.

La década de 1980 marcó un cambio decisivo hacia el aprendizaje automático y el NLP estadístico, donde el análisis sintáctico se abordaba asignando probabilidades a reglas individuales determinadas mediante algoritmos de aprendizaje \cite{Nadkarni2011}. Actualmente, el aprendizaje profundo (deep learning) ha revolucionado el campo: a diferencia de los enfoques basados en reglas, los algoritmos deducen por sí mismos el proceso de mapear entradas a salidas. El éxito del aprendizaje profundo se debe principalmente al aumento de datos disponibles y al mayor poder de procesamiento, lo que permite entrenar modelos con mayor precisión sobre una gran variedad de ejemplos \cite{Johri2021}.

Este recorrido histórico sienta las bases para comprender cómo los modelos contemporáneos de lenguaje permiten hoy generar descripciones ricas, coherentes y contextualmente adaptativas —una capacidad esencial para la creación de mundos narrativos interactivos.


\subsection{La Arquitectura Transformer como punto de inflexión}
El desarrollo de los Grandes Modelos de Lenguaje (LLMs) modernos fue posible gracias a la introducción de la arquitectura Transformer en 2017 \cite{Vaswani2017}. Antes de su aparición, los modelos de lenguaje se basaban predominantemente en arquitecturas recurrentes (RNNs) o convolucionales (CNNs), que procesan el texto de manera secuencial. Este enfoque secuencial presentaba dificultades para capturar dependencias a larga distancia en el texto, lo que limitaba la capacidad de los modelos para comprender contextos largos y complejos.

El componente fundamental de la arquitectura Transformer es el mecanismo de \textit{self-attention} (auto-atención). A diferencia de los modelos secuenciales, la auto-atención permite al modelo ponderar la importancia de todas las palabras en el texto de entrada simultáneamente, sin importar su posición. Al procesar una palabra, el modelo puede ``prestar atención'' a otras palabras relevantes en la misma secuencia, permitiéndole construir representaciones contextuales mucho más ricas y precisas \cite{Vaswani2017}. Esta capacidad para modelar relaciones complejas a lo largo de todo el texto, junto con su diseño paralelizable que facilitó el entrenamiento en hardware a gran escala, convirtió a la arquitectura Transformer en la base sobre la cual se construyen prácticamente todos los LLMs contemporáneos, incluyendo las familias de modelos GPT y Gemini \cite{Vaswani2017}.


\subsection{Interacción con LLMs: \textit{Prompting}}
La interacción con los LLMs se realiza principalmente a través del \textit{prompting}, que consiste en formular instrucciones en lenguaje natural para guiar al modelo hacia la generación de una salida deseada. La efectividad con la que un LLM realiza una tarea depende en gran medida de la calidad y escritura del \textit{prompt}. Esta práctica ha dado lugar al área de la ingeniería de \textit{prompts} (\textit{prompt engineering}).

Una de las formas de clasificar las estrategias de \textit{prompting} es según la cantidad de ejemplos que se proporcionan al modelo para contextualizar la tarea:
\begin{itemize}
    \item \textbf{Zero-shot prompting}: En esta modalidad, se le solicita al modelo que realice una tarea sin proporcionarle ningún ejemplo previo \cite{Brown2020}. El éxito de esta técnica depende de la capacidad del modelo para generalizar a partir de su entrenamiento preexistente y comprender la instrucción directa.
    \item \textbf{Few-shot prompting}: Consiste en incluir en el \textit{prompt} un pequeño número de ejemplos que ilustran el formato de entrada y salida esperado \cite{Brown2020}. Al observar estos ejemplos, el modelo puede inferir mejor la naturaleza de la tarea y generar respuestas más precisas y consistentes con el patrón deseado.
\end{itemize}
Más allá de la cantidad de ejemplos, las técnicas también se distinguen por el proceso de razonamiento que inducen. Para tareas que requieren lógica o planificación, se han desarrollado enfoques avanzados como \textbf{Chain-of-Thought (CoT) prompting}, que instruye al modelo a descomponer un problema en pasos intermedios y a ``pensar en voz alta'' antes de dar una respuesta final \cite{Wei2022}. En el ámbito de la narrativa interactiva, esta técnica es de particular utilidad para mantener la coherencia del estado del mundo frente a una acción del jugador cuyas consecuencias son alteraciones complejas del mismo. El CoT permite guiar al modelo para que deduzca y aplique todas las alteraciones necesarias sobre el estado simbólico del mundo ficticio de forma consistente y lógica.
Finalmente, otra dimensión de clasificación es la función o el rol que se le asigna al modelo. El \textbf{Role-Playing Prompting} consiste en asignar al LLM una ``persona'' o rol específico dentro del \textit{prompt} (p. ej., ``Actúa como un narrador omnisciente de una novela de fantasía''). Esta técnica es particularmente interesante porque nos permite ganar control sobre el tono, el estilo, el vocabulario y la perspectiva de la narración generada \cite{White2023}. En la práctica, estas distintas estrategias se combinan para construir \textit{prompts} precisos, robustos y multifacéticos.


\subsection{Control sobre la creatividad: Generación con Salida Estructurada}
Una de las principales limitaciones de los LLMs para su integración en sistemas computacionales es que, por defecto, generan texto libre y no estructurado \cite{Liu2024}. Esta naturaleza, impredecible, dificulta el uso de su salida como entrada para componentes de software que requieren datos en un formato específico, como es el caso de un sistema simbólico que representa el estado de un mundo.

Para resolver este problema, se emplea la técnica de \textbf{generación con salida estructurada}. El objetivo es forzar al LLM a que su respuesta se ajuste a un esquema predefinido y parseable, como los formatos JSON o XML. Esto permite una comunicación fiable entre el componente neural (el LLM) y otros módulos del sistema \cite{Liu2024}.

Existen dos enfoques principales para lograrlo \cite{Geng2023}:
\begin{enumerate}
    \item \textbf{Mediante \textit{prompting}}: Se instruye explícitamente al modelo dentro del \textit{prompt} para que formatee su respuesta como un JSON, a menudo proporcionando un ejemplo de la estructura deseada. Si bien es una técnica accesible, no garantiza que la salida sea siempre sintácticamente correcta \cite{Liu2024}.
    \item \textbf{Mediante herramientas y librerías}: Se utilizan herramientas externas o funcionalidades de la API del modelo que validan la salida en tiempo real mediante técnicas de \textit{grammar-constrained decoding} (decodificación restringida por gramáticas) \cite{Geng2023, BeurerKellner2024}. Estos sistemas fuerzan al modelo a generar únicamente los \textit{tokens} que se ajustan al esquema definido, garantizando así una salida estructuralmente válida que puede ser directamente deserealizada por el programa \cite{Geng2023}.
\end{enumerate}
Esta capacidad de controlar la estructura de la salida resulta beneficiosa para los sistemas neurosimbólicos, ya que actúa como el puente que permite que la creatividad del modelo de lenguaje modifique de manera controlada un estado complejo (en lo que refiere a las entidades y conexiones) del mundo simbólico.


\subsection{Memoria y Contexto: Aumentar la Coherencia con RAG}
Los LLMs presentan dos limitaciones inherentes que afectan su capacidad para mantener la coherencia en interacciones prolongadas: su conocimiento es estático, limitado a los datos con los que fueron entrenados, y su ``memoria'' a corto plazo está restringida por el tamaño de su ventana de contexto. Una vez que la información sale de esta ventana, el modelo la ``olvida'', lo que puede generar inconsistencias narrativas \cite{Zhao2023}.

Una técnica clave para mitigar estos problemas es la \textbf{Generación Aumentada por Recuperación} (\textit{Retrieval-Augmented Generation} o RAG) \cite{Lewis2020}. RAG es un enfoque que le proporciona al LLM el acceso a una base de conocimiento externa y actualizada en el momento de la generación. El proceso se desarrolla en dos fases:
\begin{enumerate}
    \item \textbf{Recuperación (\textit{Retrieval})}: Ante una consulta o \textit{prompt} del usuario, un sistema recuperador busca en una base de datos externa (generalmente una base de datos vectorial) los fragmentos de información más relevantes para la consulta actual. Esta base de datos puede contener el historial de la conversación, descripciones del estado del mundo, lore del universo ficticio, acciones pasadas en la historia, etc \cite{Lewis2020}.
    \item \textbf{Aumentación y Generación (\textit{Augmentation and Generation})}: Los fragmentos de información recuperados se insertan en el \textit{prompt} del LLM junto con la consulta original. De esta manera, el modelo recibe un contexto adicional y relevante que le permite generar una respuesta más informada, precisa y coherente con la información previa, aunque se encuentre fuera de su ventana de contexto inmediata \cite{Lewis2020}.
\end{enumerate}
RAG permite, en efecto, extender la memoria del modelo y anclar sus respuestas en una fuente de verdad externa, lo cual puede ser clave para mantener la coherencia del mundo en narrativas interactivas largas.


\subsection{\textit{Grounding} Simbólico: Anclar las Representaciones del LLM}
Los LLMs almacenan el conocimiento de manera implícita en los pesos de su red neuronal \cite{Coplu2024}, sin mantener estructuras de datos explícitas que representen entidades, propiedades o relaciones \cite{Pan2023}. Esta naturaleza del conocimiento implícito dificulta el mantenimiento explícito y preciso de información estructurada, como el estado de un mundo narrativo \cite{SymbolicKD2024}. Para abordar esta limitación en sistemas neurosimbólicos, se emplea el \textbf{grounding simbólico}: el proceso de anclar las representaciones y salidas del LLM a estructuras simbólicas externas y explícitas \cite{Skrlj2025}.

El \textit{grounding} simbólico puede implementarse mediante diferentes estructuras de datos:
\begin{itemize}
    \item \textbf{Grafos de conocimiento}: Representan entidades y sus relaciones como nodos y aristas, permitiendo consultas estructuradas y razonamiento sobre las conexiones entre elementos del mundo \cite{Skrlj2025}.
    \item \textbf{Bases de datos relacionales}: Permiten almacenar la información en tablas estructuradas, donde el LLM genera instrucciones SQL para consultar y modificar la información de manera precisa \cite{ChatDB}.
    \item \textbf{Programación orientada a objetos}: Representan la información mediante clases y objetos con propiedades y métodos definidos, permitiendo al LLM generar instrucciones estructuradas para manipular instancias de estas entidades de forma controlada, resultando especialmente natural para modelar mundos narrativos, ya que los personajes, ubicaciones y objetos pueden ser directamente representados como objetos con atributos y comportamientos.
\end{itemize}

Como se mencionó previamente, los LLMs operan con ventanas de contexto limitadas, lo que puede resultar problemático para mantener la consistencia de mundos narrativos a lo largo del tiempo. El \textit{grounding simbólico} aborda este problema al externalizar el estado del mundo en una ``memoria simbólica'' persistente y consultable \cite{Packer2023}. En el caso de POO, esta memoria simbólica se materializa como un conjunto de instancias de clases que representan \textbf{el estado actual del mundo}. El LLM puede consultar el estado de estos objetos (por ejemplo, las propiedades de un personaje o las conexiones entre ubicaciones) y generar actualizaciones estructuradas que modifiquen sus atributos o creen nuevas instancias, asegurando la consistencia diegética incluso cuando la información específica sale de su ventana de contexto.

Esta bidireccionalidad-donde el LLM tanto consulta como actualiza el estado simbólico-es clave para mantener mundos narrativos coherentes y evolutivos a lo largo de interacciones prolongadas \cite{Skrlj2025}.




\section{Sistemas Neurosimbólicos para Generación de Mundos}

Habiendo explorado los fundamentos de la narrativa interactiva y las capacidades de los modelos de lenguaje, ahora examinamos cómo estos dos paradigmas pueden integrarse para crear sistemas híbridos que aprovechen tanto la precisión del razonamiento simbólico como la fluidez de la generación neural.

\subsection{Integración entre planificación simbólica y generación neural}

La investigación contemporánea en narrativa interactiva se encuentra en un punto de inflexión entre dos tradiciones aparentemente opuestas: los sistemas de planificación simbólica, que garantizan coherencia mediante razonamiento formal pero producen narraciones rígidas, y los modelos de lenguaje neurales, que generan texto fluido y creativo pero carecen de mecanismos robustos para mantener la consistencia del mundo a largo plazo \cite{Riedl2015}. La pregunta fundamental que motiva el diseño de sistemas neurosimbólicos es: ¿cómo podemos obtener lo mejor de ambos mundos?

La respuesta está en un paradigma que combine el poder expresivo de las redes neuronales con la capacidad de razonamiento estructurado de los sistemas simbólicos, o sea, una arquitectura neurosimbólica \cite{Sarker2021}. Este enfoque híbrido se fundamenta en la observación de que las redes neuronales sobresalen en tareas de percepción y generación de patrones, mientras que los sistemas simbólicos son superiores para el razonamiento lógico, la planificación y el mantenimiento de restricciones. En el contexto de la narrativa interactiva, esto se traduce en sistemas donde el componente simbólico mantiene un modelo explícito del estado del mundo mientras que el componente neural genera el lenguaje natural que comunica ese estado al jugador.

Un ejemplo paradigmático de esta integración lo encontramos en el trabajo de Kreminski y Mateas \cite{Kreminski2022}, quienes proponen un sistema que extrae dominios de planificación formales (expresados en PDDL) a partir de narrativas generadas por LLMs. Su enfoque invierte la relación tradicional: en lugar de usar un planner para generar historias, utilizan historias para construir planners. El sistema emplea un LLM para generar eventos narrativos y luego infiere las precondiciones y efectos de esos eventos, construyendo así un modelo simbólico que puede ser utilizado posteriormente para garantizar la coherencia. Este proceso bidireccional entre representación simbólica y generación neural ilustra cómo ambos paradigmas pueden enriquecerse mutuamente.

La integración neurosimbólica también aborda uno de los desafíos centrales de la narrativa colaborativa: cómo evaluar si una secuencia de eventos es coherente \cite{Ammanabrolu2024}. Ammanabrolu et al. desarrollaron un sistema que combina un marco de planificación inspirado en PDDL con LLMs para evaluar episodios narrativos en tres dimensiones: explicabilidad (si los eventos tienen justificación causal), alineación narrativa (si los eventos sirven a los arcos de los personajes), y coherencia episódica (si los eventos son internamente consistentes). Su sistema mantiene un grafo de eventos donde cada nodo representa un acontecimiento y las aristas representan relaciones causales inferidas por el LLM. Esta estructura simbólica permite validar que las acciones propuestas por el jugador sean compatibles con el estado actual del mundo, rechazando aquellas que violarían la coherencia diegética.

La separación de responsabilidades entre componentes simbólicos y neurales puede manifestarse de diversas formas arquitectónicas. Una estrategia común es emplear múltiples modelos especializados, cada uno enfocado en una tarea específica \cite{Wu2025}. Por ejemplo, un sistema puede utilizar un modelo para razonamiento lógico (detectar cambios en el estado del mundo, validar precondiciones de acciones) y otro diferente para generación narrativa (producir descripciones evocativas de esos cambios). Esta división refleja la distinción entre los sistemas cognitivos humanos de Tipo 1 (rápido, intuitivo, asociativo) y Tipo 2 (lento, deliberativo, lógico) propuesta por Kahneman \cite{Kahneman2011}: el modelo de razonamiento opera en modo Tipo 2, analizando sistemáticamente las implicaciones de una acción, mientras que el modelo narrativo opera en modo Tipo 1, generando descripciones fluidas basándose en patrones aprendidos.

La representación del estado del mundo constituye otro aspecto crítico de la integración neurosimbólica. Los sistemas clásicos de ficción interactiva modelaban el mundo mediante estructuras de datos simples: habitaciones conectadas por pasajes, objetos con propiedades booleanas, y un inventario del jugador \cite{Montfort2003}. Los enfoques contemporáneos han evolucionado hacia representaciones más sofisticadas. Li et al. \cite{Li2025} proponen un sistema que construye mapas estructurados del entorno durante el juego, manteniendo un grafo donde los nodos representan locaciones y las aristas representan conexiones navegables. Este mapa no es estático, sino que se construye dinámicamente conforme el jugador explora, permitiendo que el LLM infiera la topología del mundo a partir de las descripciones que genera. De manera similar, sistemas como Friends \& Fables \cite{FriendsFables2024} mantienen un estado estructurado que incluye las estadísticas del personaje del jugador, su inventario, y el contexto de la misión actual, permitiendo que las decisiones tengan consecuencias mecánicas verificables más allá de la pura narrativa textual.

La arquitectura orientada a objetos emerge como una representación natural para mundos narrativos \cite{Adams2014}. En este paradigma, los elementos del mundo (personajes, ubicaciones, objetos) se modelan como instancias de clases con propiedades y métodos bien definidos. Esta representación ofrece varias ventajas: encapsulación de la lógica asociada a cada entidad, herencia para compartir comportamiento entre entidades similares, y polimorfismo para tratar diferentes tipos de entidades de manera uniforme. Para un LLM, esta estructura proporciona un modelo mental claro del mundo que puede consultar (¿qué objetos están en esta ubicación?) y modificar (mover un objeto de una ubicación a otra) mediante instrucciones estructuradas.

El flujo de información entre el componente simbólico y el neural típicamente involucra dos operaciones complementarias: la lectura del estado actual para contextualizar la generación, y la escritura de actualizaciones al estado basándose en la interpretación de las acciones del jugador. Para que esta comunicación sea fiable, es esencial emplear técnicas de prompting que guíen al LLM a producir salidas estructuradas y parseables \cite{Liu2024}. El few-shot prompting resulta particularmente efectivo para esta tarea: al incluir ejemplos concretos de cómo debe estructurarse la salida, el modelo puede inferir el patrón deseado y generalizarlo a nuevas situaciones \cite{Brown2020}. En tareas que requieren razonamiento complejo sobre las consecuencias de una acción, el chain-of-thought prompting permite al modelo descomponer el problema en pasos intermedios, mejorando significativamente su capacidad para detectar todos los cambios necesarios en el estado del mundo \cite{Wei2022}.

Sin embargo, la mera instrucción mediante prompts no garantiza que la salida del LLM sea sintácticamente correcta o semánticamente válida. Esta limitación ha motivado el desarrollo de técnicas de extracción y validación de información estructurada. Los enfoques van desde parseo mediante expresiones regulares (simples pero frágiles ante variaciones en el formato) hasta \textit{constrained generation} mediante gramáticas formales (robustas pero con mayor overhead computacional) \cite{Geng2023}. Herramientas como Outlines, Guidance, y BAML implementan diferentes estrategias para este propósito \cite{Willard2023}. Algunos sistemas emplean finite state machines que filtran los tokens generados en tiempo real, permitiendo únicamente aquellos que respetan el esquema definido \cite{BeurerKellner2024}. Otros prefieren un enfoque post-hoc, donde el LLM genera texto libre y luego un parser especializado extrae la información relevante, potencialmente invocando al LLM nuevamente para corregir outputs malformados \cite{LangChain2024}.

La elección entre estas estrategias implica trade-offs fundamentales: la constrained generation garantiza sintaxis válida pero reduce la flexibilidad expresiva del modelo y añade latencia, mientras que el parseo post-hoc permite mayor libertad creativa pero requiere manejo robusto de errores y potencialmente múltiples reintentos. Para sistemas de narrativa interactiva, donde la latencia de respuesta impacta directamente la experiencia del usuario, estos trade-offs adquieren particular importancia.

Finalmente, cabe señalar que la integración neurosimbólica no elimina completamente el problema de las alucinaciones o inconsistencias del LLM, pero sí lo mitiga significativamente al proporcionar un marco de referencia externo contra el cual validar las generaciones \cite{Ji2023}. En lugar de confiar ciegamente en la memoria implícita del modelo, el sistema puede consultar explícitamente el estado simbólico del mundo, reduciendo la probabilidad de que el modelo invente información inconsistente con la historia previa. Esta combinación de flexibilidad neural y restricción simbólica constituye la promesa central de los sistemas neurosimbólicos para narrativa interactiva.


\subsection{Arquitecturas de Referencia para Interactive Storytelling con LLMs}

Para comprender el espacio de diseño de los sistemas de narrativa interactiva con LLMs, resulta instructivo examinar las arquitecturas existentes y situarlas en un espectro que va desde enfoques puramente neurales hasta sistemas altamente estructurados. Esta perspectiva comparativa permite identificar tanto las capacidades como las limitaciones de cada aproximación, iluminando las decisiones arquitectónicas que enfrenta el diseño de un nuevo sistema.

En un extremo del espectro encontramos los sistemas puramente neurales, ejemplificados por AI Dungeon \cite{Trapova2021}. Lanzado en 2019 y construido inicialmente sobre GPT-2, AI Dungeon permitió por primera vez que millones de usuarios experimentaran narrativas interactivas generadas enteramente por un LLM sin estructuras de planificación subyacentes. El sistema operaba mediante un loop simple: el jugador ingresa una acción en lenguaje natural, esta se concatena con el historial previo de la aventura, y el LLM genera la continuación de la historia. Con la migración a GPT-3, AI Dungeon alcanzó una fluidez narrativa impresionante, generando 18.5 millones de aventuras y atrayendo más de un millón de usuarios mensuales en su apogeo \cite{PublishersWeekly2020}.

Sin embargo, esta arquitectura minimalista reveló limitaciones fundamentales. Los usuarios reportaron problemas recurrentes de repetición y ``looping'', donde el modelo reutiliza frases o situaciones de manera cíclica \cite{CuckooAI2025}. Más crítico aún, el sistema carecía de memoria estructurada: cuando el contexto de la conversación excedía la ventana del modelo, este comenzaba a ``olvidar'' elementos cruciales de la historia, generando inconsistencias diegéticas. Un personaje podía aparecer en una habitación sin justificación, objetos previamente destruidos reaparecían, y promesas o alianzas establecidas en turnos anteriores se desvanecían de la narrativa \cite{CuckooAI2025}.

Como respuesta a estas limitaciones, surgieron sistemas que incorporaban mecanismos de memoria semi-estructurada. NovelAI introdujo el concepto de ``Lorebooks'' (libros de tradición), una base de datos que el usuario puede poblar con información sobre el mundo, los personajes, las facciones y la mitología del universo narrativo \cite{TechpointAfrica2024}. Cuando ciertos keywords aparecen en la narrativa, el sistema recupera automáticamente las entradas relevantes del Lorebook e las inyecta en el contexto del LLM. Este mecanismo, conceptualmente similar a RAG \cite{Lewis2020}, permite anclar la generación a una fuente de verdad externa mantenida por el usuario. NovelAI también ofrece los campos ``Memory'' (información global siempre presente en el contexto) y ``Author's Note'' (instrucciones de estilo que guían la generación), proporcionando al usuario mayor control sobre la voz narrativa \cite{TechpointAfrica2024}.

Estos mecanismos de memoria textual representan un paso intermedio hacia sistemas más estructurados, pero aún confían en que el LLM interprete correctamente la información recuperada y mantenga la coherencia sin validación externa. La ausencia de un estado del mundo verificable significa que el sistema no puede rechazar acciones imposibles ni garantizar que las consecuencias de una acción se reflejen consistentemente en turnos futuros.

En el otro extremo del espectro se sitúan los sistemas basados en planificación simbólica, herederos de décadas de investigación en automated storytelling. Los planificadores narrativos basados en STRIPS (Stanford Research Institute Problem Solver) y HTN (Hierarchical Task Networks) construyen historias mediante búsqueda en un espacio de estados, donde cada acción tiene precondiciones formalmente especificadas y efectos sobre el mundo \cite{Riedl2015}. Por ejemplo, el sistema TALE-SPIN de Meehan (1977) generaba fábulas mediante planificación basada en goals: cada personaje tenía objetivos propios y el sistema planeaba secuencias de acciones para alcanzarlos, generando conflictos cuando los planes de diferentes personajes colisionaban \cite{Meehan1977}.

Estos sistemas ofrecen garantías formales de coherencia: cada evento en la historia es causalmente justificable y el estado del mundo se actualiza de manera determinista. Sin embargo, adolecen de rigidez expresiva. Las historias generadas, aunque coherentes, suelen ser repetitivas y predecibles, limitadas por la explosión combinatoria del espacio de búsqueda y la dificultad de codificar manualmente dominios narrativos suficientemente ricos \cite{Riedl2015}. Más aún, la generación del lenguaje natural es típicamente superficial, basada en templates que producen texto funcional pero carente de la riqueza estilística que caracteriza a la buena narrativa.

Los sistemas neurosimbólicos contemporáneos buscan ocupar el punto medio de este espectro, combinando la fluidez de los LLMs con la confiabilidad de las representaciones simbólicas. Friends \& Fables \cite{FriendsFables2024} ejemplifica esta tendencia al implementar un sistema que mantiene estado estructurado basado en las reglas de Dungeons \& Dragons 5e. El sistema rastrea las estadísticas del personaje (puntos de vida, recursos de habilidades especiales), el inventario, y el contexto de la misión actual. Cuando el jugador realiza una acción, el LLM no solo genera la descripción narrativa, sino que también emite instrucciones estructuradas para actualizar este estado. Por ejemplo, si el jugador lanza un hechizo que consume un spell slot, el sistema decrementa el contador correspondiente y el LLM subsecuente es consciente de esta limitación, pudiendo informar al jugador si intenta usar un recurso agotado.

Mientras que en AI Dungeon el LLM podría asumir que el jugador tiene cierta poción o habilidad basándose únicamente en su memoria contextual (potencialmente incorrecta), en Friends \& Fables el sistema consulta explícitamente el inventario verificable del personaje. Las decisiones tienen peso mecánico, no solo narrativo. Esta arquitectura reduce en gran parte la probabilidad de inconsistencias diegéticas, pero al costo de mayor complejidad implementacional y la necesidad de diseñar cuidadosamente la interfaz entre el LLM y el sistema de reglas.

Los sistemas puramente neurales maximizan la flexibilidad y diversidad narrativa, pero sacrifican garantías de coherencia y carecen de mecanismos para que las acciones tengan consecuencias persistentes y verificables. Los sistemas puramente simbólicos garantizan coherencia y causalidad, pero producen narrativas rígidas y predecibles, limitadas por dominios manualmente codificados. Los sistemas neurosimbólicos buscan el equilibrio, pero introducen complejidad: ahora tenemos que diseñar la interfaz entre el componente simbólico y el neural, decidir qué información se representa simbólicamente y qué se deja a la memoria del LLM, y manejar los casos donde el LLM y el sistema simbólico entran en conflicto.

Esta taxonomía de enfoques proporciona el marco conceptual necesario para posicionar y evaluar nuevas propuestas en el espacio de diseño. Un sistema como PAYADOR, que mantiene representaciones orientadas a objetos del mundo mientras delega la generación narrativa a LLMs, se sitúa claramente en la tradición neurosimbólica, heredando tanto sus ventajas (coherencia verificable, persistencia de estado) como sus desafíos (complejidad arquitectónica, necesidad de comunicación fiable entre componentes).

\subsection{El Desafío del Grounding: Anclar LLMs a Estados del Mundo}

El problema fundamental que motiva el desarrollo de sistemas neurosimbólicos para narrativa interactiva puede formularse de manera precisa: ¿cómo podemos aprovechar la capacidad de los LLMs para generar lenguaje fluido y contextualmente apropiado sin sucumbir a su tendencia a ``alucinar'' información inconsistente con la historia previa? Esta cuestión nos conduce directamente al concepto de grounding, el proceso de anclar las representaciones y generaciones de un modelo de lenguaje a un conjunto verificable de hechos externos \cite{Ji2023}.

Los LLMs almacenan conocimiento de manera implícita en los pesos de su red neuronal, aprendido durante el entrenamiento sobre vastas cantidades de texto \cite{Coplu2024}. Este conocimiento es inherentemente probabilístico: el modelo no ``sabe'' hechos en el sentido de mantener una base de datos consultable, sino que ha internalizado patrones estadísticos sobre qué palabras tienden a aparecer en qué contextos. Cuando generamos texto, el modelo simplemente predice el token más probable dado el contexto previo, sin acceso a una fuente de verdad externa que valide si lo que está generando es factualmente correcto o consistente con información previamente establecida \cite{Ji2023}.

Esta naturaleza probabilística tiene consecuencias directas para la narrativa interactiva. Consideremos un escenario simple: en el turno 5, el jugador coloca una llave dorada en un cofre dentro de su habitación. En el turno 25, el jugador abre el cofre. ¿Contendrá la llave dorada? Si dependemos únicamente de la memoria contextual del LLM, la respuesta es incierta. Si los turnos 5 y 25 ambos caen dentro de la ventana de contexto del modelo (típicamente 8K-128K tokens dependiendo del modelo), existe una alta probabilidad de que el LLM recuerde la llave y la mencione. Pero si el turno 5 ha salido de la ventana de contexto, el modelo no tiene forma de ``recordar'' ese hecho, y podría generar una descripción del cofre vacío, o peor aún, inventar contenidos diferentes \cite{Zhou2024}.

El fenómeno de la alucinación en LLMs ha sido extensamente documentado \cite{Ji2023}. Se distinguen dos tipos: alucinaciones intrínsecas, donde el modelo genera contenido que contradice directamente la información en su contexto inmediato, y alucinaciones extrínsecas, donde el modelo genera información que no puede verificarse con el contexto proporcionado pero que el modelo presenta como factual. En narrativa interactiva, las alucinaciones extrínsecas son particularmente problemáticas porque el modelo puede inventar que un personaje tiene cierta habilidad o que el jugador posee cierto objeto sin que estos hechos hayan sido establecidos previamente, lo que rompe la coherencia diegética.

Además, reducir la temperatura de generación a cero (lo que hace que el modelo sea completamente determinista, siempre seleccionando el token más probable) no elimina las alucinaciones \cite{GDELTProject2024}. Incluso cuando se proporciona al modelo un documento fuente con información precisa y se le solicita resumirlo, el modelo puede inventar detalles específicos que no aparecen en el texto original. Esto sugiere que las alucinaciones no son meramente un producto de la aleatoriedad en la generación, sino una característica inherente de cómo los LLMs comprimen y reconstruyen información.

El grounding emerge como la estrategia fundamental para mitigar estas limitaciones. Weng \cite{Weng2024} identifica dos enfoques principales: data grounding, donde el modelo se ancla a documentos o bases de datos externas mediante técnicas como RAG, y contextual grounding, donde el modelo se ancla a un contexto estructurado específico del dominio o tarea. Para narrativa interactiva, ambos tipos de grounding son relevantes. El data grounding permite recuperar información histórica de la aventura (descripciones previas de una ubicación, diálogos pasados con personajes), mientras que el contextual grounding ancla el modelo al estado actual verificable del mundo.

Igualmente, el grounding no es una solución mágica. Pan et al. \cite{Pan2024} documentan que incluso cuando los LLMs tienen acceso a knowledge graphs estructurados, persisten desafíos en razonamiento multi-hop (conectar múltiples hechos para inferir conclusiones), manejo de información contradictoria, y actualización dinámica del conocimiento. Un knowledge graph puede representar que ``la llave dorada está en el cofre'' y que ``el cofre está en la habitación'', pero inferir que ``la llave dorada está en la habitación'' requiere razonamiento transitivo que el LLM debe realizar explícitamente.

La representación del estado simbólico puede tomar diversas formas. Los knowledge graphs representan entidades y relaciones como nodos y aristas, permitiendo consultas basadas en grafos y razonamiento sobre conectividad \cite{Pan2024}. Las bases de datos relacionales almacenan información en tablas estructuradas, donde el LLM puede generar consultas SQL para extraer información precisa \cite{ChatDB}. La programación orientada a objetos modela entidades como instancias de clases con propiedades y métodos, una representación particularmente natural para mundos narrativos donde personajes, ubicaciones y objetos tienen atributos y comportamientos bien definidos \cite{Adams2014}.

Cada representación tiene trade-offs. Los knowledge graphs son excelentes para modelar relaciones complejas y realizar inferencias basadas en la estructura del grafo, pero pueden ser computacionalmente costosos para consultas complejas. Las bases de datos relacionales son eficientes para búsquedas precisas pero menos flexibles para representar jerarquías o relaciones muchos-a-muchos complejas. La POO ofrece encapsulación y una metáfora intuitiva (objetos en el mundo \leftrightarrow objetos en el código), pero requiere que el LLM genere instrucciones estructuradas para manipular instancias en lugar de simplemente describir cambios en lenguaje natural.

Un aspecto crítico del grounding simbólico es la bidireccionalidad: el LLM debe poder tanto leer el estado actual (para contextualizar su generación) como escribir actualizaciones al estado (para reflejar las consecuencias de las acciones del jugador) \cite{Packer2023}. Esta interacción bidireccional introduce complejidad: ahora debemos diseñar protocolos de comunicación entre el modelo neural y el sistema simbólico, lo que típicamente involucra generación de salida estructurada por parte del LLM.

La fiabilidad de esta comunicación es fundamental y un problema en sí mismo. Si el LLM produce una instrucción de actualización malformada o semánticamente inválida, el sistema debe detectar el error y manejarlo apropiadamente, ya sea solicitando regeneración, aplicando correcciones heurísticas, o rechazando la actualización \cite{LangChain2024}. Esta necesidad de validación y manejo de errores añade una capa adicional de complejidad al sistema, pero es esencial para mantener la integridad del estado del mundo.

Finalmente, cabe enfatizar que el grounding reduce pero no elimina completamente el problema de las alucinaciones. El LLM aún puede generar descripciones que, aunque consistentes con el estado simbólico consultado, introducen detalles superfluos o interpretaciones cuestionables \cite{Ji2023}. El grounding simbólico, entonces, no es un mecanismo que transforma a los LLMs en sistemas perfectamente confiables, sino una estrategia arquitectónica que desplaza el equilibrio entre flexibilidad creativa y confiabilidad factual hacia un punto más favorable para aplicaciones que requieren coherencia a largo plazo.

\subsection{PAYADOR: Un Enfoque Neurosimbólico Minimalista para Narrativa Interactiva}

Los conceptos teóricos discutidos en las secciones anteriores encuentran una implementación concreta en PAYADOR (presentado por Góngora et al. en ICCC 2024 \cite{gongora2024payador}), un sistema que ejemplifica el paradigma neurosimbólico para narrativa interactiva mediante un diseño minimalista, y que es la base de este proyecto. PAYADOR se posiciona como un enfoque para anclar modelos de lenguaje a datos estructurados, buscando equilibrar la coherencia garantizada por representaciones simbólicas con la fluidez narrativa característica de los LLMs.

\subsubsection{Arquitectura del Sistema}

La arquitectura de PAYADOR se fundamenta en tres pilares: un modelo simbólico orientado a objetos del mundo ficticio, un pipeline de procesamiento basado en dos LLMs especializados, y un conjunto de estrategias de prompting que median la comunicación entre ambos componentes.

El \textbf{modelo del mundo} implementa una representación orientada a objetos con cuatro tipos de componentes primitivos, todos heredando de una clase base \texttt{Component}: \texttt{Item} (objetos que pueden ser recogidos o manipulados), \texttt{Location} (lugares navegables conectados entre sí), \texttt{Character} (personajes con inventario y ubicación) y \texttt{Puzzle} (acertijos que bloquean el acceso a ciertas ubicaciones). La clase \texttt{Component} define dos atributos fundamentales que todos los componentes heredan: un nombre único que identifica al componente dentro del mundo, y una lista de descripciones en lenguaje natural (\texttt{descriptions}) que lo caracterizan desde múltiples perspectivas. Esto hace que cada clase esté pensada para ser narrada al jugador, por lo que las descripciones no son meramente metadatos, sino el material narrativo que el LLM utilizará para generar las escenas. Al proporcionar múltiples descripciones para cada componente, el sistema permite variabilidad en cómo se presenta la misma entidad en diferentes momentos, lo que reduce la repetición a la vez que enriquece la experiencia narrativa.

Las relaciones espaciales se modelan explícitamente: cada \texttt{Location} mantiene una lista de ubicaciones conectadas (\texttt{connecting\_locations}) y un diccionario de pasajes bloqueados (\texttt{blocked\_locations}), donde cada bloqueo especifica el obstáculo que lo causa (un \texttt{Item} o un \texttt{Puzzle}) y si el desbloqueo es simétrico. Los personajes tienen inventarios distribuidos y pueden intercambiar objetos entre sí o con las ubicaciones. Esta representación es suficientemente expresiva para modelar aventuras tipo \textit{point-and-click} o \textit{escape room}, donde el jugador debe recolectar objetos y resolver puzzles para progresar.

El \textbf{pipeline de procesamiento} implementa una arquitectura de dos modelos inspirada en la distinción entre razonamiento y generación. El \textit{reasoning model} es responsable de interpretar la acción del jugador en lenguaje natural y determinar qué cambios válidos debe tener el estado del mundo. Recibe como entrada el estado actual renderizado (en lenguaje natural simple) junto con la acción del jugador, y produce como salida un formato estructurado que especifica tres categorías de transformaciones: objetos movidos (entre inventarios o ubicaciones), pasajes desbloqueados (ubicaciones ahora accesibles), y cambio de ubicación del jugador. El \textit{narrative model}, por su parte, genera las descripciones del resultado de una acción de la escena actual, recibiendo el estado del mundo y el historial de narraciones previas de esa ubicación para evitar repeticiones.

Para la actualización del mundo, PAYADOR emplea \textit{few-shot prompting} con diez ejemplos detallados que ilustran cómo mapear acciones del jugador a transformaciones estructuradas. Cada ejemplo incluye tanto la sintaxis esperada (formato de las tres categorías de cambios) como casos límite: acciones que intentan algo imposible, múltiples transformaciones simultáneas, o interacciones con NPCs. El prompt incluye también instrucciones metacognitivas explícitas: ``No asumas que lo que dice el jugador siempre tiene sentido; quizás esas acciones intentan hacer algo que el mundo no permite''.

Para la narración de escenas, el sistema distingue tres contextos: escena inicial (donde debe introducirse al personaje del jugador), primera visita a una ubicación (donde debe describirse exhaustivamente), y visitas subsecuentes (donde se proporciona el historial de descripciones previas para evitar repetición). En todos los casos, el prompt enfatiza el uso de oraciones simples y la descripción de lo que el personaje puede ``sentir o ver'', manteniendo la perspectiva en segunda persona característica de la ficción interactiva clásica.

\subsubsection{Flujo de Interacción y Mecanismos de Coherencia}

El ciclo de interacción en PAYADOR sigue una secuencia determinista que garantiza la primacía del estado simbólico sobre las generaciones del LLM. Ante una acción del jugador: (1) el estado actual se renderiza a lenguaje natural simple mediante templates; (2) este rendering junto con la acción se envía al reasoning model; (3) la respuesta del modelo se parsea mediante expresiones regulares para extraer las transformaciones estructuradas; (4) cada transformación se valida contra las reglas del mundo implementadas en Python (por ejemplo, verificar que un objeto sea \texttt{gettable} antes de permitir que se guarde en el inventario); (5) las transformaciones válidas se aplican al estado simbólico; (6) si el jugador cambió de ubicación, se invoca al narrative model para describir la nueva escena; caso contrario, se extrae del output del reasoning model la narración encapsulada entre símbolos \texttt{\#}.

Esta arquitectura implementa lo que podríamos llamar \textit{grounding duro} porque el estado simbólico es la única fuente de verdad, y el LLM no puede contradecir las reglas codificadas. Si el \textit{reasoning model} sugiere una transformación inválida (por ejemplo, mover a una ubicación no conectada), el código captura la excepción y simplemente no aplica el cambio.

El renderizado del estado a lenguaje natural actúa como la interfaz que permite al LLM ``ver'' el mundo simbólico. PAYADOR genera dos niveles de descripción. El nivel básico enumera en oraciones simples y sin ambigüedad: la ubicación actual del jugador, las ubicaciones accesibles desde ahí, los pasajes bloqueados y sus obstáculos, el inventario del jugador, los objetos visibles, y los personajes presentes. El nivel detallado añade las descripciones narrativas de cada componente en la escena.

\subsubsection{Limitaciones y Espacio para Extensión}

Una limitación estructural más fundamental es que PAYADOR solo permite jugar en mundos predefinidos manualmente. Cada mundo---con sus ubicaciones, objetos, personajes y puzzles---debe ser codificado explícitamente en Python antes de iniciar la partida. Esto contrasta con el potencial de los LLMs para generar contenido dinámicamente. Una extensión natural del sistema sería la capacidad de generar mundos procedimentalmente, ya sea de manera completamente aleatoria (respetando ciertas restricciones de jugabilidad) o basándose en una semilla narrativa proporcionada por el usuario (por ejemplo, ``genera un mundo inspirado en El Señor de los Anillos''). De manera similar, los puzzles en PAYADOR son estáticos (acertijos con respuesta predefinida); un sistema generativo podría crear puzzles de diferentes tipos (lógicos, de observación, basados en combinación de objetos) adaptados dinámicamente a la progresión del jugador.

El mecanismo de parsing mediante expresiones regulares, aunque determinista y eficiente, es inherentemente frágil. Si el reasoning model produce una salida que se desvía mínimamente del formato esperado---por ejemplo, usando paréntesis en lugar de corchetes angulares, o añadiendo una coma extra---el parser fallará silenciosamente y la transformación no se aplicará. Esta fragilidad motiva la exploración de enfoques de \textit{constrained generation} que garanticen sintaxis válida mediante gramáticas formales, aunque al costo de mayor complejidad y potencial aumento de latencia.

La escalabilidad del renderizado del estado también presenta desafíos. En mundos pequeños (5-10 ubicaciones, 10-15 objetos), renderizar el estado completo en cada turno es factible. Pero en mundos más grandes, el rendering podría exceder la ventana de contexto, lo que reduciría el espacio disponible para el historial de la conversación. Esto sugiere dos direcciones complementarias: estrategias de renderizado selectivo, donde solo se describan los componentes relevantes para la ubicación actual y las adyacentes, y la incorporación de mecanismos de RAG que permitan recuperar información histórica de eventos pasados sin mantenerla constantemente en el contexto. Este último enfoque sería particularmente valioso para narrativas largas donde eventos tempranos deben recordarse decenas de turnos más tarde cuando se vuelven relevantes.

A pesar de estas limitaciones, PAYADOR demuestra que un sistema neurosimbólico funcional para narrativa interactiva puede implementarse con relativa simplicidad, y que el grounding simbólico, incluso en su forma más básica, mitiga efectivamente los problemas de coherencia que aquejan a sistemas puramente neurales. Esta arquitectura constituye el punto de partida conceptual y técnico sobre el cual se desarrolló este proyecto, que es, en esencia, una evolución de PAYADOR.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% parte central
\chapter{Parte Central} \label{cap:central}
Este capítulo detalla el proceso completo de diseño, implementación y validación del sistema de generación automática de mundos interactivos desarrollado como extensión de Payador. El desarrollo abordó un desafío técnico complejo: permitir que modelos de lenguaje generen mundos narrativos coherentes, estructuralmente válidos y jugables, intentando mantener o mejorar la experiencia de juego que ofrece el sistema actual.

\section{Visión General del Sistema}
El sistema que desarrollamos extiende Payador transformándolo de un motor de juegos con mundos predefinidos a una plataforma capaz de generar mundos interactivos de forma automática. La arquitectura resultante integra varios componentes que trabajan en conjunto para resolver los desafíos técnicos y de diseño que surgieron durante el desarrollo.

\textbf{Motor de generación basado en LLM}: Utiliza un pipeline incremental de cinco etapas que descompone la creación del mundo en tareas específicas. Este enfoque surgió como solución a problemas críticos observados en aproximaciones más directas, como veremos en detalle en la sección \ref{sec:pipeline_incremental}. El motor puede generar mundos con responsabilidad creativa total o guiados por semillas (\textit{seeds}) proporcionadas por el usuario.

\textbf{Sistema de representación estructurada}: Define esquemas de datos mediante Pydantic que garantizan la validez estructural de los mundos generados. Desarrollamos taxonomías completas tanto para objetivos como para puzzles, cada una con consideraciones específicas de implementación. Particularmente, el tipo de objetivo \verb|SOLVE_MYSTERY| requirió un tratamiento especial que se detalla en la sección \ref{subsec:objetivos_misterio}, mientras que los siete tipos de puzzles definidos se analizan en la sección \ref{subsec:puzzles} referente a este tema.

% XX: no estoy seguro. es la subsec:puzzles?
\textbf{Sistema de asistencia adaptativo}: Implementamos un mecanismo dinámico de pistas (\textit{hints}) que adapta las sugerencias según la situación inmediata del jugador. Si el jugador está en una ubicación sin puzzles, el sistema ofrece pistas relacionadas con el objetivo principal. Si hay un puzzle en la ubicación pero no ha sido presentado, las pistas sugieren explorar e interactuar con elementos del entorno (``mira y observa'', ``intenta hablar con el personaje''). Una vez que el puzzle ha sido propuesto y el jugador no lo ha resuelto, las pistas cambian automáticamente a las específicas de ese puzzle, proporcionando ayuda progresiva. Este mecanismo, detallado en la sección XX, fue crucial para mejorar la experiencia de usuario sin comprometer el desafío.

\textbf{Integración con MongoDB}: La persistencia de mundos generados mediante MongoDB resultó ser más que una simple funcionalidad de almacenamiento. Este componente proporcionó capacidades de reproducibilidad que fueron fundamentales tanto para el modo \textbf{Replay} (permitiendo a usuarios rejugar mundos propios o ajenos) como para el proceso de debugging y validación durante el desarrollo. La capacidad de recuperar mundos exactos con problemas específicos aceleró significativamente la identificación y corrección de errores en el pipeline de generación, como se describe en la sección \ref{subsec:mongodb}.

\textbf{Interfaz de juego mejorada}: Esta nueva interfaz, usando \textit{Streamlit}, nos permite elegir entre cinco modos de juego (Preset, Generate, Inspiration, Tutorial, Replay), además de la posibilidad de tener herramientas de depuración para análisis de mundos, sistema de acciones rápidas, visualización estructurada del objetivo, y soporte multilingüe completo. Los detalles de diseño de la interfaz y las decisiones de experiencia de usuario se presentan en la sección XX.

\textbf{Sistema de validación multinivel}: Implementamos capas de validación que verifican la jugabilidad de los mundos generados, desde consistencia referencial hasta accesibilidad de objetivos. Estas validaciones, que se ejecutan entre etapas del pipeline de generación, se describen en profundidad en la sección XX.

La Figura \ref{fig:flujo_general} muestra el flujo general del sistema, ilustrando cómo estos componentes interactúan desde la configuración inicial hasta la interacción del jugador con el mundo generado, incluyendo el ciclo de persistencia y recuperación desde MongoDB.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figs/generation-pipeline.png}
    \caption{Flujo general del sistema}
    \label{fig:flujo_general}
\end{figure}



\section{Arquitectura del Sistema}

\subsection{Pipeline de Generación Incremental} \label{sec:pipeline_incremental}

La generación de mundos mediante un único llamado al LLM (estrategia \textit{one-shot}) presentó problemas significativos durante las pruebas iniciales: sobrecarga cognitiva del modelo, inconsistencias narrativas y desconexión entre elementos del mundo. Para resolver estos problemas, diseñamos una \textbf{Estrategia de Generación Incremental y Guiada} que divide la creación en cinco etapas secuenciales, cada una con una responsabilidad específica.

\paragraph{Motivación del diseño por etapas} La estrategia \textit{one-shot} requiere que el LLM genere simultáneamente la historia, objetivos, elementos del mundo, personajes y sus interrelaciones, lo cual excede la capacidad de procesamiento coherente del modelo en una única invocación. Durante la experimentación con este enfoque, observamos problemas recurrentes que comprometían la jugabilidad:

\begin{itemize}
    \item \textbf{Objetos críticos sin ubicación}: El LLM frecuentemente olvidaba colocar objetos necesarios para completar el objetivo en ubicaciones específicas del mundo, dejándolos ``flotando'' sin una posición definida o directamente omitiéndolos de la estructura del mundo.
    \item \textbf{NPCs sin contexto espacial}: Personajes importantes para la narrativa se generaban sin asignación a ninguna ubicación, imposibilitando la interacción con ellos.
    \item \textbf{Desconexión entre narrativa y estructura}: El trasfondo mencionaba elementos que luego no existían en el mundo jugable, o viceversa.
    \item \textbf{Límites de longitud de prompt}: Al intentar mitigar estos problemas agregando instrucciones más detalladas y explícitas al prompt, alcanzábamos repetidamente el límite de caracteres permitido por las APIs de los LLMs, sin que esto garantizara mejoras en la consistencia.
\end{itemize}

Para investigar estos problemas, realizamos un experimento controlado: en lugar de solicitar al LLM que generara todo el mundo de una vez, le proporcionamos manualmente una descripción narrativa (\textit{backstory}) completa y detallada, inspirada en uno de los mundos originales de Payador (el mundo de la tortuga). A partir de esta descripción en lenguaje natural, solicitamos al LLM que construyera la estructura del mundo. \textbf{Los resultados fueron significativamente superiores}: el LLM logró crear un mundo considerablemente más consistente, con la mayoría de los elementos correctamente ubicados y conectados lógicamente. Si bien el enfoque incremental no elimina completamente los errores de generación (particularmente en mundos de alta complejidad donde el LLM ocasionalmente puedesi omitir elementos o crear inconstencias) la frecuencia y severidad de estos problemas se redujo drásticamente en comparación con el enfoque \textit{one-shot}.

Este resultado reveló que el problema principal no era la capacidad del LLM para estructurar mundos coherentes, sino la carga cognitiva de tener que inventar y estructurar simultáneamente. La solución evidente era \textbf{dividir la creación en pasos incrementales}, permitiendo que:

\begin{itemize}
    \item Cada etapa se enfoque en un aspecto específico del mundo
    \item Los prompts puedan ser más explícitos sin exceder límites de longitud
    \item Las salidas validadas de etapas anteriores sirvan como contexto para etapas posteriores
    \item El LLM mantenga mejor coherencia al trabajar con tareas más acotadas
    \item Se permita intervención y validación entre pasos
\end{itemize}


\subsubsection{Paso 1: El Núcleo de la Aventura}
Esta etapa establece los fundamentos narrativos del mundo. El LLM recibe como entrada una idea del usuario (en modo \textit{Inspiration}) o genera una propuesta original (modo \textit{Generate}), produciendo:

\begin{itemize}
    \item \textbf{Título}: Nombre identificativo de la aventura
    \item \textbf{Trasfondo} (\textit{backstory}): Contexto narrativo que motiva la acción
    \item \textbf{Concepto del jugador}: Perfil del protagonista
    \item \textbf{Objetivo principal}: Meta estructurada según \verb|ObjectiveType|
\end{itemize}

Esta etapa es análoga al experimento exitoso que realizamos con la descripción narrativa manual: se crea primero el ``porqué'' antes que el ``qué'' y el ``cómo''.

El prompt de esta etapa difiere significativamente según el modo seleccionado, reflejando las diferentes necesidades de cada aproximación:

\paragraph{Modo Generate - Responsabilidad Creativa Total}
En este modo, el prompt enfatiza la autonomía completa del LLM. Le indicamos explícitamente que tiene libertad para inventar cualquier tipo de historia, ambientación (medieval, ciencia ficción, moderna, fantástica), personajes únicos con personalidades interesantes, y objetivos desafiantes. También le sugerimos categorías temáticas amplias como inspiración (misterio, aventura, supervivencia, social, exploración) que puede elegir o combinar libremente, pero sin imponer restricciones. El énfasis está en la creatividad sin límites y en la generación de conceptos originales.

\paragraph{Modo Inspiration - Adherencia Temática Estricta}
Durante las pruebas iniciales con el modo \textit{Inspiration}, observamos un problema recurrente: aunque mencionábamos el tema proporcionado por el usuario al inicio del prompt, el LLM tendía a generar mundos donde solo la ambientación general guardaba relación con la temática. Los NPCs, puzzles y especialmente el objetivo principal frecuentemente se desviaban hacia elementos genéricos sin conexión clara con el tema especificado. Por ejemplo, en un mundo con tema ``piratas del Caribe'', podríamos obtener una ambientación pirata pero con un objetivo de resolver un acertijo matemático abstracto, o NPCs con motivaciones completamente desvinculadas del contexto pirata.

Para resolver este problema, diseñamos una estrategia de \textbf{reiteración temática constante} en el prompt. En lugar de mencionar el tema una sola vez, lo reforzamos en múltiples secciones del prompt, estableciendo que:

\begin{itemize}
    \item El tema proporcionado debe ser la base fundamental de TODO el concepto del mundo
    \item Cada ubicación, personaje, objeto y especialmente el objetivo principal deben ser manifestaciones directas del tema
    \item El LLM no debe inventar elementos desconectados del tema
    \item Los personajes deben encarnar diferentes facetas del tema
    \item El objetivo principal debe estar intrínsecamente relacionado con la temática
    \item Los puzzles que se imaginen para etapas posteriores deben surgir naturalmente del tema
\end{itemize}
Esta reiteración constante resultó ser clave. Al enfatizar la obligación temática en cada sección relevante del prompt (no solo al principio), logramos que el LLM mantuviera la coherencia temática no únicamente en la ambientación superficial, sino en todos los elementos estructurales del mundo, especialmente en aquellos que afectan directamente la jugabilidad como el objetivo, los puzzles futuros y las motivaciones de los NPCs.

%Aca hablar de la salida estructurada del paso 1, mencionar que se hablara mas a detalle en la seccion de Salida Estructurada

\subsubsection{Paso 2: El Esqueleto del Mundo}

Tomando como entrada el núcleo narrativo del Paso 1, esta etapa identifica las entidades principales necesarias para completar el objetivo. El LLM determina:
\begin{itemize}
    \item Ubicaciones clave en la ruta crítica
    \item Personajes relevantes para la narrativa
    \item Objetos necesarios para completar el objetivo
    \item Relaciones preliminares entre entidades
\end{itemize}
En esta etapa se utilizan los \textbf{parámetros de configuración} especificados por el usuario (o valores por defecto), permitiendo controlar explícitamente el tamaño y complejidad del mundo:
\begin{itemize}
    \item \textbf{Número de ubicaciones}: Define la extensión espacial del mundo
    \item \textbf{Cantidad de NPCs}: Determina cuántos personajes pueblan el mundo
    \item \textbf{Cantidad de items}: Especifica el número de objetos interactuables
    \item \textbf{Número de puzzles}: Establece cuántos desafíos incluir
\end{itemize}
Incorporamos estos parámetros al prompt del LLM de manera explícita, garantizando que el esqueleto generado respete las restricciones de tamaño. Por ejemplo, si el usuario especifica 5 ubicaciones y 2-4 (dos a cuatro) puzzles, el LLM debe generar exactamente esa cantidad de elementos en su propuesta, sea el número especifico o un número en el rango especificado.


\paragraph{Conexión con el objetivo principal} Algo interesante a notar, es que durante las pruebas iniciales, observamos que el LLM tendía a generar entidades (ubicaciones, NPCs, objetos) que, aunque temáticamente coherentes, carecían de conexión funcional con el objetivo principal. Esto resultaba en mundos donde el jugador podía encontrarse con elementos interesantes pero irrelevantes para completar la aventura. Para mitigar este problema, establecimos reglas explícitas en el prompt de esta etapa:

\begin{itemize}
    \item \textbf{Conexiones claras con el objetivo}: Cada entidad generada debe tener una relación identificable con el camino hacia el objetivo. No basta con que sean temáticamente apropiadas; deben tener un propósito dentro de la progresión del juego.
    \item \textbf{Ruta lógica hacia el objetivo}: Debe existir una secuencia clara de eventos, ubicaciones y acciones que permitan al jugador avanzar desde el punto de partida hasta la consecución del objetivo. Esta ruta no necesariamente debe ser lineal, pero sí debe ser identificable y coherente.
\end{itemize}

Sin embargo, como se detallará en el capítulo de evaluación (Capítulo 5), las pruebas posteriores revelaron que esto no fue completamente suficiente. En varios mundos generados seguimos encontrando puzzles, items o NPCs que no tenían un propósito real para alcanzar el objetivo. Esta característica puede interpretarse de dos maneras: como una limitación del sistema que genera contenido irrelevante, o como un elemento de ambientación con contenido exploratorio opcional y de ``accesorio''. La valoración de esta característica depende en última instancia de las expectativas y preferencias del jugador: algunos usuarios pueden apreciar la profundidad adicional y la sensación de un mundo más ``vivido'', mientras que otros pueden preferir experiencias más optimizadas donde cada elemento tenga un propósito claro en la resolución del objetivo.

La \textbf{salida} de esta etapa es una lista de entidades sin detalles exhaustivos, funcionando como un \textit{esqueleto} que será completado en etapas posteriores, pero ya con las cantidades definidas que guiarán el resto del pipeline. Este esqueleto incluye nombres de ubicaciones, listado de NPCs, inventario de objetos, y cantidad de puzzles a crear, sin aún especificar descripciones detalladas, diálogos, o mecánicas específicas de los desafíos.

\subsubsection{Paso 3: El Mundo Casi-Completo}
Esta etapa materializa el esqueleto agregando detalles descriptivos y funcionales:

\begin{itemize}
    \item Descripciones textuales de ubicaciones
    \item Atributos de personajes (diálogos, motivaciones)
    \item Propiedades de objetos (portabilidad, usabilidad)
    \item Conexiones entre ubicaciones
\end{itemize}
Con el esqueleto ya definido en el Paso 2, diseñamos el prompt de esta etapa para ser significativamente más específico sobre los requisitos de cada elemento, evitando las omisiones observadas en el enfoque one-shot.

\paragraph{Asignación de ubicaciones y resolución de elementos flotantes} En esta etapa se asignan explícitamente ubicaciones a todos los objetos y personajes, resolviendo el problema de elementos ``flotantes'' que observamos en el enfoque one-shot. El prompt especifica que cada personaje debe estar ubicado en un lugar que existe en el mundo, y cada objeto debe tener una ubicación inicial definida o estar en el inventario de algún personaje.

\paragraph{Restricciones de tamaño y conectividad} Como el tamaño del mundo se fija en el paso anterior, en esta etapa se le indica claramente al LLM que no debe agregar ubicaciones ni elementos nuevos que no formen parte del esqueleto existente (generado en el Paso 2). Esta medida surgió como respuesta a un patrón observado en las pruebas iniciales, donde el modelo tendía a ``expandirse creativamente'' y a incluir contenido fuera del alcance definido.

Además de las especificaciones anteriores, establecimos reglas obligatorias de conexión entre ubicaciones:

\begin{itemize}
    \item \textbf{Bidireccionalidad}: Si la ubicación A conecta con B, entonces B debe conectar con A. Esta regla evita conexiones unidireccionales accidentales que podrían atrapar al jugador.
    \item \textbf{Conectividad global}: Todas las ubicaciones deben ser accesibles desde cualquier punto del mundo. No puede haber ubicaciones aisladas o grupos de ubicaciones desconectadas del resto. Esto garantiza que el jugador siempre pueda explorar todo el mundo.
    \item \textbf{Alcanzabilidad del objetivo}: El objetivo debe ser completable con los elementos creados, existiendo al menos una ruta lógica desde el estado inicial hasta la consecución del objetivo.
\end{itemize}

\paragraph{Validación de elementos funcionales} Diseñamos un conjunto de reglas destinadas a garantizar la consistencia funcional de los personajes y objetos del mundo. En el caso de los personajes, si poseen capacidad de interacción deben contar con texto de interacción definido, y todo objeto incluido en su inventario debe existir también en la lista global de objetos para evitar referencias inexistentes que comprometan la jugabilidad. En cuanto a los objetos, aquellos necesarios para cumplir el objetivo principal deben ser obtenibles por el jugador (\textit{gettable: true}), mientras que los objetos meramente decorativos pueden no serlo. Cada objeto debe tener una justificación clara dentro del mundo, ya sea funcional —como parte de un puzzle o requisito del objetivo— o atmosférica, contribuyendo a la ambientación general.

\paragraph{Reglas para la definición de objetivos} Durante esta etapa establecimos reglas destinadas a garantizar la coherencia y la claridad en la definición de los objetivos del mundo. Cada tipo de objetivo presenta particularidades en su estructura y en la forma en que el jugador debe alcanzarlo, por lo que debimos incorporar criterios generales para mantener su foco y evitar confusión. En especial, limitamos el número de componentes principales de cada objetivo para asegurar que la meta final estuviera claramente delimitada y no se mezclara con los medios o herramientas necesarias para alcanzarla. Ademas de esto, agregamos elementos narrativos y de apoyo, como la descripción de completitud al finalizar el objetivo y un conjunto de ``ayudas'' progresivas que el jugador puede consultar durante la exploración.
En particular, consideramos un tratamiento especial para los objetivos de tipo misterio, los cuales requieren una estructura narrativa más compleja y la introducción de pistas dentro del mundo. El desarrollo completo de los objetivos se abordará en la sección siguiente, dedicada al análisis detallado de las distintas clases, en particular los diferentes tipos de objetivo.

Finalmente, incorporamos en el prompt una lista de verificación mental que el LLM debe ejecutar antes de finalizar la generación. Esta verificación incluye comprobar que todas las ubicaciones sean accesibles desde la ubicación inicial, que el jugador pueda completar el objetivo con los elementos disponibles y que exista al menos una ruta de solución posible desde el estado inicial. También se exige que todos los elementos referenciados existan efectivamente dentro del mundo, y en el caso de los objetivos de tipo misterio, que cada pista esté correctamente asociada a un objeto físico existente.

El resultado es una estructura \verb|GeneratedWorld| funcional pero lineal, enfocada exclusivamente en la ruta principal hacia el objetivo. El mundo en este punto es jugable y completable, aunque aún carece de los puzzles y pasajes bloqueados que añadirán complejidad en la siguiente etapa. Las interacciones de personajes son directas y simples pero completas, proporcionando la base para una experiencia narrativa coherente.

\textbf{Paso 4: Los Desafíos}

Con el mundo base establecido, esta etapa introduce complejidad mediante:

\begin{itemize}
    \item Pasajes bloqueados: Conexiones entre ubicaciones que requieren condiciones específicas para desbloquearse
    \item Puzzles: Desafíos clasificados según \verb|PuzzleType| que obstaculizan el progreso
\end{itemize}
El LLM analiza el mapa generado e identifica puntos estratégicos donde insertar estos obstáculos, asegurando que existan soluciones viables y coherentes con la narrativa.

\paragraph{Enfoque de cadenas de dependencia} Inicialmente, diseñamos esta etapa con la ambición de crear \textbf{cadenas de dependencias complejas} (\textit{dependency chains}): secuencias lógicas de tareas interdependientes donde completar un paso desbloquea el siguiente. La visión era que, por ejemplo, para obtener el objetivo final, el jugador primero necesitaría la Llave A, que solo obtendría del Personaje B, quien la entregaría a cambio del Objeto C, que a su vez requeriría resolver el Puzzle D en la Ubicación E, y así sucesivamente.
El concepto incluía:
\begin{itemize}
    \item Cadenas principales de 3-6 pasos interdependientes hacia el objetivo
    \item Subcadenas para cada paso principal
    \item Múltiples rutas opcionales cuando fuera posible
    \item Diversidad de desafíos: intercambios, puzzles, exploración, interacciones sociales
\end{itemize}

% XX: creo que ambas XX se refieren a la misma Sección 3.2.2. Estructura de clases
Sin embargo, durante las etapas tempranas de testing, esta estructura demostró ser problemática. El LLM fallaba consistentemente al generar estas cadenas, produciendo mundos con errores estructurales graves: dependencias circulares imposibles de resolver (A requiere B, B requiere C, C requiere A), referencias a objetos que no existían en los inventarios correctos, o simplemente generaciones sin sentido donde las relaciones de dependencia no tenían lógica coherente.
Al analizar estos fallos, comprendimos que el problema radicaba en la \textbf{complejidad creciente del esquema del mundo}. Con cada característica que añadíamos (cadenas de dependencias, múltiples tipos de puzzles, diversos tipos de objetivos, validaciones cruzadas), el modelo de datos se volvía más intrincado y las restricciones más numerosas. El LLM simplemente no podía mantener toda esta información en contexto mientras generaba salidas estructuradas válidas. Esto nos obligó a tomar decisiones difíciles de diseño. Descartamos la implementación formal de estructuras de cadenas de dependencias; sin embargo, este no fue el único recorte. Como se detallará más adelante en las secciones XX y XX, también tuvimos que reducir la cantidad de tipos de objetivos y tipos de puzzles que inicialmente habíamos planificado. La complejidad del esquema era el cuello de botella fundamental del sistema, y solo mediante simplificación estratégica pudimos lograr generaciones consistentes y jugables.

Aunque descartamos la implementación formal de cadenas de dependencias, decidimos mantener esa filosofía dentro del prompt. Explicar al LLM la generación de puzzles como un ``hilo conductor lógico'' donde cada desafío está motivado por el anterior resultó mucho más efectivo que simplemente pedirle ``añadir puzzles al mundo'': los resultados eran más coherentes, mejor integrados narrativamente y con una progresión más natural. En esta misma línea, el prompt enfatiza la conexión entre cada puzzle y un pasaje bloqueado o recurso esencial para avanzar, evitando así la aparición de desafíos ``flotantes'' sin consecuencias mecánicas claras. Para reforzar esta coherencia, se establecieron reglas específicas: todo pasaje bloqueado debe tener un obstáculo definido y un requisito concreto para desbloquearlo; los obstáculos y sus soluciones deben estar físicamente separados (por ejemplo, no colocar la llave junto a la puerta que abre); y las soluciones deben poder descubrirse a través de la exploración.

\paragraph{Sistmea de pistas para puzzles} Durante las primeras pruebas observamos puzzles excesivamente complejos, donde el jugador podía quedar bloqueado sin una vía clara de avance. Para resolverlo, se implementó un \textbf{sistema obligatorio de pistas} asociado a cada puzzle, compuesto por entre tres y cinco pistas progresivas (\textit{puzzle\_hints}) que van desde una orientación general hasta una ayuda casi explícita. La efectividad de este sistema motivó la creación de \textbf{pistas para los objetivos} (explicadas ya en la sección XX), con el fin de mantener una coherencia en la asistencia ofrecida al jugador. Más adelante, surgió la idea de extender este enfoque a situaciones en las que el jugador se encontrara en una ubicación con un puzzle aún no iniciado. Así nació la \textbf{pista de interacción} (\textit{interaction\_hint}), una sugerencia breve que orienta al jugador sobre cómo comenzar la acción (por ejemplo, ``intenta hablar con [personaje]'', ``examina [objeto]'' o ``busca pistas en esta ubicación''). Este enfoque consolidó un sistema de ayuda más orgánico y adaptativo, que se integra con el mecanismo general descrito en la sección \ref{sec:logica_juego}.

En esta etapa se mantuvieron las mismas \textbf{restricciones técnicas} definidas en el paso anterior, que limitan la capacidad del LLM para alterar la estructura del mundo: no se permite crear nuevas ubicaciones, deben preservarse las rutas de conectividad global entre ellas y se prohíben mecánicas de combinación o transformación de objetos, dado que el motor del juego no admite funciones de \textit{crafting}. Además, si un puzzle otorgado por un personaje incluye una recompensa física, el objeto correspondiente debe existir previamente y encontrarse en el inventario de dicho personaje. Sobre esta base, el LLM cuenta con cierta libertad para realizar una \textbf{redistribución estratégica} de los objetos del mundo, con el fin de ajustar la dificultad y el equilibrio narrativo. Esto implica poder mover elementos relevantes a ubicaciones menos accesibles o asignarlos a personajes que los entreguen mediante intercambio, siempre que la modificación mantenga coherencia lógica y motivación narrativa dentro del contexto del mundo.

El resultado de esta etapa es un mundo con obstáculos estratégicamente distribuidos que transforman la experiencia de lineal a desafiante. Aunque no implementamos cadenas de dependencias formales, los puzzles generados mantienen coherencia narrativa y progresión lógica gracias a la filosofía de diseño preservada en el prompt.

\subsubsection{Paso 5: Expansión del Mundo (Opcional)}

La etapa final enriquece el mundo con contenido extra que incrementa la inmersión:
\begin{itemize}
    \item Ubicaciones secundarias no críticas
    \item Personajes complementarios con narrativas propias
    \item Objetos decorativos o de utilidad marginal
    \item Rutas alternativas y exploración lateral
\end{itemize}
Esta expansión se realiza respetando la coherencia lógica y espacial del mundo establecido en las etapas anteriores.

Este quinto paso es \textbf{opcional}. Durante la etapa de testing, comentamos este paso del pipeline para garantizar que los mundos generados cumplieran exactamente con los parámetros de tamaño especificados en la configuración inicial. La inclusión de este paso puede resultar en mundos que excedan las cantidades configuradas, lo cual puede ser deseable para aumentar la riqueza del contenido, pero puede no ser adecuado cuando se requiere control preciso sobre las dimensiones del mundo (por ejemplo, en evaluaciones comparativas o estudios de rendimiento). La decisión de incluir o excluir esta etapa debe tomarse en función de los objetivos específicos de cada caso de uso: mayor control y predictibilidad (sin expansión) versus mayor profundidad y contenido exploratorio (con expansión).


\subsection{Estructura de clases}
\subsubsection{World: Estructura Goal-Oriented}

La clase \verb|World| constituye el contenedor principal de todos los elementos del juego y encapsula la filosofía de diseño fundamental del sistema: un mundo \textbf{story-driven, goal-oriented} donde cada elemento está conectado lógica y semánticamente al objetivo principal y la narrativa.

Durante las etapas tempranas del desarrollo, nos enfrentamos a un problema crítico en la generación de mundos. Los primeros intentos produjeron mundos donde los elementos estaban ``sueltos'': puzzles que no contribuían a ningún progreso, ubicaciones que no servían para nada, personajes sin propósito narrativo. Esta desconexión hacía extremadamente difícil probar el sistema y resultaba en experiencias de juego frustrantes e incoherentes.

Este problema motivó una pausa estratégica en el desarrollo para replantear fundamentalmente la arquitectura del mundo. La idea central que surgió fue: \textbf{todo debe estar lógica y semánticamente conectado en torno al objetivo y la historia}. No queríamos mundos que fueran simplemente colecciones de elementos temáticamente coherentes; queríamos mundos donde cada elemento tuviera un propósito funcional claro en la progresión hacia el objetivo.

Para implementar esta visión, diseñamos la estructura \verb|GeneratedWorld| con \textbf{conexiones y referencias explícitas} entre todos sus componentes. Esto implicó cambios significativos en la clase \verb|World| heredada: antes, las relaciones entre elementos eran implícitas, por ejemplo, una ubicación podía listar ítems por nombre, pero no había validación estructural de que realmente existieran en el mundo. Las condiciones para avanzar estaban codificadas en la lógica del motor del juego, no en la definición del mundo mismo.


La nueva arquitectura modela explícitamente:
\begin{itemize}
    \item \textbf{Personajes con propósito}: Cada NPC relacionado con la historia tiene algo útil para el jugador (información, objetos) y establece condiciones claras para obtenerlo (resolver un puzzle, entregar un ítem, completar una tarea).
    \item \textbf{Puzzles con consecuencias}: Los puzzles no ``están por ahí'' sin más; su resolución produce efectos tangibles modelados directamente en su definición: entregar ítems específicos, desbloquear pasajes concretos, revelar información necesaria para el objetivo.
    \item \textbf{Ítems funcionales}: Los objetos del mundo tienen roles definidos en la progresión narrativa, ya sea como requisitos para puzzles, moneda de intercambio con personajes, o componentes directos del objetivo o temática.
    \item \textbf{Ubicaciones con significado}: Las ubicaciones no son simplemente escenarios decorativos; contienen elementos críticos para el avance o sirven como puntos de conexión en la red de dependencias del mundo.
\end{itemize}

Este diseño goal-oriented ofrece ventajas cruciales tanto para el LLM como para el sistema:
\begin{itemize}
    \item \textbf{Guía para la generación}: Al tener que generar mundos de cero, el LLM ahora recibe una estructura clara que define qué elementos debe crear y cómo deben relacionarse. Las conexiones explícitas reducen la ambigüedad y orientan la creatividad del modelo hacia resultados funcionales.
    \item \textbf{Validación automática}: Las referencias cruzadas (por ejemplo, ``este personaje da un ítem que debe existir'') son coherentes y pueden validarse estructuralmente. Si un puzzle referencia un objeto como recompensa, ese objeto debe existir en el inventario del personaje o ubicación correspondiente.
    \item \textbf{Jugabilidad garantizada}: Al forzar conexiones explícitas con el objetivo, minimizamos la generación de contenido irrelevante o decorativo puro. De esta manera, la mayoría de los elementos tendrán, en principio, un propósito en la experiencia del jugador.
\end{itemize}

La validación y coherencia son desafiantes incluso con esta estructura de código explícita; sin ella, con definiciones implícitas, sería prácticamente imposible que el LLM generara mundos funcionales. El enfoque goal-oriented no es meramente una decisión de diseño; constituye una necesidad técnica fundamental para hacer viable la generación automática de mundos jugables y coherentes.

La clase \verb|World| encapsula los siguientes elementos estructurales:
\begin{itemize}
    \item \textbf{Metadatos narrativos}: Título, backstory, concepto del jugador
    \item \textbf{Objetivo principal}: Instancia de \verb|Objective| que define la meta del mundo
    \item \textbf{Ubicaciones}: Lista de \verb|Location| con sus conexiones bidireccionales
    \item \textbf{Personajes}: Lista de \verb|Character| con sus inventarios y condiciones de interacción
    \item \textbf{Ítems}: Catálogo global de \verb|Item| con sus propiedades y ubicaciones
    \item \textbf{Puzzles}: Conjunto de \verb|Puzzle| con sus recompensas y requisitos
    \item \textbf{Estado inicial}: Ubicación de inicio y configuración inicial del jugador
\end{itemize}

La Figura \ref{fig:world-class-diagram} muestra la estructura de clases completa y las relaciones entre World y sus componentes.

Esta estructura garantiza que todos los elementos del mundo estén explícitamente definidos y conectados, permitiendo tanto al LLM generarlos coherentemente como al motor del juego validarlos y ejecutarlos correctamente.


   \begin{figure}[h]
       \centering
       \includegraphics[width=0.9\textwidth]{figs/diagramaWorld.png}
       \caption{Diagrama de clases: World y sus componentes}
       \label{fig:world-class-diagram}
   \end{figure}


\subsubsection{Location: Conectividad y Accesibilidad}

La clase \verb|Location| representa los espacios físicos del mundo donde transcurre la acción. Cada ubicación hereda de \verb|Component| los atributos básicos de nombre y descripciones, y añade funcionalidad específica para la navegación espacial. En términos de atributos y componentes, esta clase se mantuvo prácticamente igual a la implementación original de Payador; nuestra contribución principal se centró en las validaciones de conectividad que garantizan la generación de mundos jugables.

\paragraph{Atributos principales}
\begin{itemize}
    \item \textbf{items}: Lista de objetos presentes en la ubicación
    \item \textbf{connecting\_locations}: Lista de ubicaciones directamente accesibles
    \item \textbf{blocked\_locations}: Diccionario de pasajes bloqueados por obstáculos (ítems o puzzles)
    \item \textbf{visited}: Indicador de si el jugador ha visitado previamente la ubicación. Este atributo se envía al LLM como parte del contexto del mundo, permitiendo que adapte la narrativa: ubicaciones visitadas por primera vez reciben descripciones más elaboradas y detalladas, mientras que ubicaciones ya conocidas generan narraciones más breves y enfocadas en cambios relevantes.

\end{itemize}

\paragraph{Validaciones de conectividad}
Para garantizar la jugabilidad del mundo generado, implementamos validaciones estrictas sobre la topología de ubicaciones durante el Paso 3 del pipeline. Estas validaciones son críticas porque previenen la generación de mundos imposibles de completar:

\begin{itemize}
    \item \textbf{Bidireccionalidad}: Si la ubicación A conecta con B, entonces B debe conectar con A. Esta regla evita conexiones unidireccionales accidentales que podrían atrapar al jugador.
    \item \textbf{Conectividad global}: Todas las ubicaciones deben ser accesibles desde cualquier punto del mundo. No puede haber ubicaciones aisladas o grupos de ubicaciones desconectadas del resto.
    \item \textbf{Alcanzabilidad del objetivo}: El objetivo debe ser completable considerando la topología del mundo y los elementos disponibles. Debe existir al menos una ruta válida desde el estado inicial hasta la consecución del objetivo.
\end{itemize}

Estas reglas se especifican explícitamente en el prompt del Paso 3, guiando al LLM a generar estructuras espaciales coherentes y navegables. Sin embargo, dado que el LLM puede fallar en mantener estas restricciones, implementamos una \textbf{verificación automática post-generación} que valida la conectividad mediante búsqueda en profundidad (DFS). Esta función construye un grafo de adyacencia considerando tanto conexiones normales como pasajes bloqueados (que siguen siendo conexiones topológicas, solo temporalmente inaccesibles), y verifica que todas las ubicaciones sean alcanzables desde cualquier punto de partida. Si la validación falla, el sistema reporta qué ubicaciones quedaron aisladas, permitiendo detectar y corregir mundos con topologías inválidas antes de que lleguen al jugador. La validación de estas propiedades era impráctica en el enfoque one-shot, donde el LLM tendía a olvidar estas restricciones al generar simultáneamente todos los aspectos del mundo.

\subsubsection{Item: Funcionalidad y Portabilidad}

La clase \verb|Item| representa los objetos interactuables del mundo. Al igual que Location, hereda de \verb|Component| los atributos de nombre y descripciones. Esta clase se mantuvo idéntica a la implementación de Payador en términos de estructura: los atributos de nombre, descripciones y \verb|gettable| no sufrieron modificaciones. Nuestra contribución se centró en las validaciones que garantizan el uso coherente de estos atributos durante la generación automática.

El único atributo específico de Item es \verb|gettable| (booleano), que determina si el objeto puede ser tomado por el jugador y añadido a su inventario. Esta propiedad simple tiene implicaciones profundas para el diseño del mundo y el contexto narrativo (debería ser imposible para un humano cargar con un tanque de agua, por ejemplo):

\paragraph{Validaciones durante la generación}
En el Paso 3 del pipeline, establecimos reglas explícitas sobre el uso de \verb|gettable|:
\begin{itemize}
    \item Todo objeto necesario para completar el objetivo principal debe ser \verb|gettable=True|, garantizando que el jugador pueda obtenerlo.
    \item Los objetos que bloquean pasajes pueden ser \verb|gettable=True| (se desbloquea al tomarlos) o \verb|gettable=False| (requieren otra solución, como un puzzle).
    \item Cada objeto debe tener una justificación clara dentro del mundo: funcional (parte de la progresión) o atmosférica (ambientación).
\end{itemize}

Esta distinción permite al LLM crear mundos donde no todos los objetos mencionados en las descripciones necesitan ser manipulables, evitando inconsistencias donde elementos puramente narrativos pudieran confundirse con items funcionales del gameplay.

\paragraph{Desafío técnico: Referencias únicas vs. duplicación}
Durante el desarrollo enfrentamos un problema crítico relacionado con el manejo de referencias de objetos. Cuando el jugador intentaba tomar un ítem, particularmente aquellos otorgados como recompensa de puzzles, el sistema duplicaba el objeto en lugar de mover la referencia existente. La causa raíz era que el LLM frecuentemente no creaba los ítems de recompensa especificados en los puzzles, y nuestra solución inicial fue crear el ítem automáticamente si no existía. Sin embargo, esto causaba duplicación cuando el ítem sí existía pero la lógica de búsqueda fallaba en encontrarlo en las ubicaciones esperadas (inventarios de personajes o ítems en ubicaciones).

La solución definitiva fue dual:
\begin{itemize}
    \item \textbf{Prevención en generación}: Implementamos una validación exhaustiva de recompensas de puzzles (detallada en la subsección de Puzzle) que verifica y crea los ítems faltantes durante la generación del mundo, no durante el gameplay.
    \item \textbf{Corrección en transferencia}: Refactorizamos la lógica de transferencia de ítems para buscar la referencia exacta del objeto en todos los contenedores posibles (inventarios de personajes, ítems en ubicaciones, y obstáculos bloqueando pasajes), moviendo la referencia en lugar de crear copias, y reportando errores explícitos si el objeto no se encuentra en ningún contenedor.
\end{itemize}

Este bug evidenció la importancia de mantener referencias únicas a los objetos del mundo y validar exhaustivamente su ubicación antes de cualquier operación de transferencia. La complejidad surge porque los ítems pueden existir en múltiples contextos: como elementos libres en ubicaciones, en inventarios de personajes, o actuando como obstáculos que bloquean pasajes. 

Sin embargo, como se discutirá en detalle en el Capítulo 4 (\ref{sec:interaccion_llm_jugador}) de evaluación, este problema reaparece en casos límite específicos: cuando el LLM intenta mover un objeto al inventario del jugador pero la búsqueda de su ubicación actual falla (debido a problemas de comparación de identidad de objetos), el sistema interpreta incorrectamente la operación como un ``drop item'', añadiendo el objeto a la ubicación actual sin removerlo de su posición original, resultando en duplicación. Este comportamiento revela la fragilidad de la lógica de control de flujo cuando se combina con la búsqueda flexible de objetos y las múltiples ramificaciones condicionales del sistema de actualización del mundo.

\subsubsection{Character: Agentes en el Mundo}

La clase \verb|Character| representa tanto al jugador como a los personajes no jugadores (NPCs) del mundo. Al igual que las clases anteriores, hereda de \verb|Component| y se mantuvo estructuralmente similar a la implementación de Payador, con ajustes menores para soportar las necesidades del sistema de generación.

\paragraph{Atributos principales}
\begin{itemize}
    \item \textbf{inventory}: Lista de ítems que posee el personaje
    \item \textbf{location}: Referencia a la ubicación actual donde se encuentra
    \item \textbf{visited\_locations}: Diccionario que registra las ubicaciones visitadas y sus descripciones sucesivas
    \item \textbf{interaction}: Datos estructurados de interacción provenientes del proceso de generación, que incluyen información sobre puzzles propuestos y condiciones de intercambio
\end{itemize}

\paragraph{Validaciones para NPCs generados}
Durante el Paso 3 del pipeline, establecimos reglas para garantizar que los NPCs generados sean funcionalmente coherentes:
\begin{itemize}
    \item Si un personaje tiene capacidad de interacción, debe contar con texto de interacción definido.
    \item Todo objeto en el inventario de un personaje debe existir en la lista global de objetos del mundo, evitando referencias inexistentes.
    \item Los personajes deben estar asignados a una ubicación válida del mundo, resolviendo el problema de NPCs ``flotantes'' observado en el enfoque one-shot.
\end{itemize}

Estas validaciones aseguran que los NPCs no solo sean temáticamente apropiados sino también funcionalmente integrados en la mecánica del juego, permitiendo intercambios de ítems, proposición de puzzles, y progresión narrativa coherente.

\subsubsection{Puzzle: Desafíos y Progresión} \label{subsec:puzzles}

La clase \verb|Puzzle| representa los desafíos que obstaculizan el progreso del jugador hacia el objetivo. A diferencia de las clases anteriores, Puzzle experimentó modificaciones y extensiones significativas respecto a la implementación base de Payador, impulsadas por los problemas observados durante el testing y las necesidades del sistema de generación automática.

\paragraph{Atributos estructurales}
\begin{itemize}
    \item \textbf{problem}: El enunciado del desafío que debe resolver el jugador
    \item \textbf{answer}: La respuesta esperada (oculta al jugador)
    \item \textbf{puzzle\_type}: Categorización del tipo de puzzle (riddle, logic, sequence, etc.)
    \item \textbf{proposed\_by\_character}: Nombre del personaje que propone el puzzle, o None si es ambiental
    \item \textbf{proposed\_by\_location}: Nombre de la ubicación cuya investigación propone el puzzle (ambientales), None si es propuesto por un personaje
    \item \textbf{rewards}: Recompensa dada al resolver el puzzle (ítems, pasajes desbloqueados)
    \item \textbf{relevance\_to\_objective}: Explicación de cómo resolver este puzzle contribuye al objetivo principal
    \item \textbf{puzzle\_hints}: Lista de pistas progresivas para ayudar al jugador
    \item \textbf{interaction\_hint}: Sugerencia breve sobre cómo iniciar la interacción con el puzzle
\end{itemize}

\paragraph{Tipología de puzzles}
Uno de los primeros cambios implementados fue la introducción de tipos explícitos de puzzles. Sin esta categorización, el LLM quedaba ``a la deriva'' al momento de crear desafíos, generando puzzles inconsistentes o mal estructurados. Los tipos permitidos son:

\begin{itemize}
    \item \textbf{Riddle}: Adivinanzas que requieren razonamiento lateral o conocimiento general
    \item \textbf{Logic}: Problemas lógicos que requieren deducción o razonamiento estructurado
    \item \textbf{Wordplay}: Juegos de palabras, anagramas, o puzzles lingüísticos
    \item \textbf{Observation}: Observar detalles del entorno para encontrar la solución
    \item \textbf{Sequence}: Ordenar elementos o realizar acciones en una secuencia específica
    \item \textbf{Code}: Descifrar códigos o patrones
    \item \textbf{Memory}: Recordar información presentada previamente en la narrativa
\end{itemize}

Inicialmente habíamos incluido un tipo \textit{Information} donde resolver el puzzle otorgaba información relevante para el objetivo. Sin embargo, este tipo fue descartado porque los puzzles de este tipo frecuentemente no se presentaban correctamente o, cuando se resolvían, entregaban información irrelevante u obvia, dejando al jugador con la sensación de haber perdido el tiempo. La recompensa tangible (ítems, pasajes desbloqueados o directamente cumplir el objetivo) resultó más satisfactoria y funcionalmente clara que las recompensas informacionales.

\paragraph{Problema 1: Puzzles invisibles}
Uno de los problemas más persistentes fue que el LLM creaba puzzles que nunca eran presentados al jugador durante la partida. Inicialmente intentamos resolver esto mediante prompting, agregando \verb|interaction_hints| y especificando si el puzzle era \verb|proposed_by_character| o \verb|proposed_by_location| para que el LLM supiera cuándo narrarlo. Sin embargo, el LLM frecuentemente ``se olvidaba'': aunque el jugador hablara con el personaje que tenía un puzzle, el LLM muchas veces no lo narraba. Dado esto, decidimos que no podíamos confiar en el LLM para esta tarea crítica. La solución a la que llegamos fue \textbf{una intervención directa del sistema}: si el input del usuario menciona a un personaje que propone un puzzle, no solicitamos narración al LLM; en su lugar, el sistema narra directamente la proposición del puzzle utilizando el \verb|interaction_text| previamente generado. Esta intervención garantiza que un gran porcentaje de puzzles sean efectivamente presentados al usuario. Luego de ser presentado se le da un atributo de \verb|given: True| al puzzle, asi si vuelve a interactuar con el personaje, no se lo vuelve a presentar.

\paragraph{Problema 2: Puzzles falsos (alucinación)}
Otro problema recurrente fue que el LLM alucinaba puzzles inexistentes. Si el jugador hablaba con un NPC y le pedía algo que este tenía, había ocasiones en que el LLM narraba algo como ``resuelve este puzzle y te lo daré'' aunque el NPC no tuviera ningún puzzle asociado. Este problema era particularmente insidioso porque no era evidente durante el juego; solo al inspeccionar los archivos JSON del mundo podíamos detectar que el jugador estaba intentando resolver un puzzle que no existía en la estructura del mundo.

La solución requirió ser más explícitos en el prompt de narración, especificando que si no hay un puzzle presente en la estructura del mundo, el LLM no debe inventar puzzles. Las validaciones estructurales del JSON del mundo fueron fundamentales para detectar este tipo de inconsistencias.

\paragraph{Problema 3: Puzzles excesivamente difíciles}
Durante el testing observamos puzzles tan creativos y difíciles que resultaban imposibles de resolver sin ayuda externa. En múltiples ocasiones tuvimos que ``hacer trampa'' consultando directamente la respuesta en el JSON del mundo, ya que podíamos pasar muchos minutos intentando razonar el puzzle sin siquiera acercarnos a la solución.

Este problema motivó la implementación del \textbf{sistema de pistas progresivas} (\verb|puzzle_hints|). Las pistas están ordenadas en cantidad ascendente de información: la primera puede orientar al jugador, pero la tercera prácticamente revela la respuesta, reconociendo que el jugador está atascado. Como se discutió en la sección del pipeline, esta idea resultó tan efectiva que la expandimos a pistas para objetivos y pistas de exploración general. Las evaluaciones con usuarios confirmaron la utilidad de este sistema: muchos solicitaron las tres pistas para los puzzles, indicando que se habrían atascado de no existir.

\paragraph{Problema 4: NPCs codiciosos}
Cuando un puzzle era propuesto por un NPC y su recompensa era un ítem en el inventario del personaje, observamos que el NPC no entregaba el objeto tras resolver el puzzle correctamente. El problema radicaba en que el LLM no sugería el cambio necesario de \verb|moved_object| del inventario del NPC al jugador.

La solución nuevamente requirió intervención del sistema: cuando el usuario resuelve un puzzle, se llama a una función que verifica las recompensas, busca el ítem correspondiente y lo mueve automáticamente al inventario del usuario, sin depender de que el LLM genere esta acción en su narración.

\paragraph{Problema 5: Recompensas inexistentes}
En varios mundos generados, las recompensas de puzzles (especificadas como \verb|ItemReward|) no existían en el esqueleto del mundo. Cuando el usuario resolvía el puzzle, no ocurría nada porque no había ítem que mover. Este problema se detectó durante validaciones post-generación y se resolvió mediante una función de verificación que:

\begin{itemize}
    \item Verifica que todos los ítems de recompensa existan en \verb|world.items|
    \item Si un ítem de recompensa no existe, lo crea automáticamente
    \item Asigna el ítem creado al inventario del personaje que propone el puzzle, o a la ubicación del puzzle si es ambiental
    \item Registra todas las correcciones aplicadas para debugging
\end{itemize}

\paragraph{Problema 6: Validación de respuestas}
La verificación de respuestas correctas presentó múltiples desafíos. Inicialmente, diferencias menores como puntuación o mayúsculas causaban que respuestas correctas fueran rechazadas (e.g., ``a map'' vs ``A map.''). Implementamos normalización de respuestas que:

\begin{itemize}
    \item Convierte todo a minúsculas
    \item Elimina puntuación al inicio y final
    \item Normaliza espacios en blanco
    \item Remueve artículos iniciales (a, an, the)
\end{itemize}

Sin embargo, persisten limitaciones con sinónimos y respuestas semánticamente equivalentes. Por ejemplo, en la etapa de evaluación nos topamos con el acertijo ``What walks on four legs in the morning, two in the afternoon, and three in the evening?'', la respuesta esperada era ``man'' pero un evaluador respondió ``humans'' dos veces diferentes, siendo marcado como incorrecto en ambas ocasiones. El evaluador se frustró y abandonó el puzzle sin resolverlo. Este problema evidencia las limitaciones de la validación basada en comparación de strings normalizada: aunque empleamos el LLM para determinar la correctitud de la respuesta de puzzles, el prompt prioriza coincidencia exacta con la respuesta esperada. Podríamos ajustar el prompt para que acepte sinónimos más liberalmente, pero esto introduciría riesgos significativos de falsos positivos donde respuestas incorrectas sean aceptadas por similitud superficial.

\subsubsection{Objective: Meta y Cierre Narrativo}

La clase \verb|Objective| experimentó cambios sustanciales respecto a la implementación de Payador, evolucionando desde un sistema simple de tuplas a una estructura compleja con múltiples tipos, validaciones exhaustivas y elementos narrativos. Esta clase define la meta que el jugador debe alcanzar y proporciona el cierre narrativo de la aventura.

\paragraph{Estructura del objetivo}
Un objetivo estructurado (\verb|GeneratedObjective|) contiene:
\begin{itemize}
    \item \textbf{type}: Tipo de objetivo (reach\_location, get\_item, deliver\_an\_item, find\_character, solve\_mystery)
    \item \textbf{components}: Lista de componentes involucrados (ítems, personajes, ubicaciones). Todos los componentes referenciados deben existir en el mundo
    \item \textbf{description}: Descripción clara de lo que el jugador debe lograr
    \item \textbf{success\_conditions}: Condiciones específicas que deben cumplirse para completar el objetivo
    \item \textbf{completion\_narration}: Descripción narrativa de lo que sucede tras completar el objetivo (no usado en solve\_mystery)
    \item \textbf{objective\_hints}: Pistas progresivas para avanzar hacia el objetivo (3 pistas para dar en orden de más general a más específica)
    \item \textbf{mystery\_clues}: Lista de pistas para objetivos de misterio (solo tipo solve\_mystery)
    \item \textbf{mystery\_solution}: Solución del misterio (solo tipo solve\_mystery)
\end{itemize}

\paragraph{Tipología de objetivos}
Se definieron cinco tipos de objetivos, algunos inspirados en los mundos existentes en Payador y otros completamente nuevos:

\begin{itemize}
    \item \textbf{REACH\_LOCATION}: El jugador debe llegar a una ubicación específica
    \item \textbf{GET\_ITEM}: El jugador debe obtener uno o más objetos específicos
    \item \textbf{DELIVER\_AN\_ITEM}: El jugador debe entregar un objeto a un personaje o ubicación
    \item \textbf{FIND\_CHARACTER}: El jugador debe encontrar a un personaje específico
    \item \textbf{SOLVE\_MYSTERY}: El jugador debe descubrir todas las pistas asociadas a un misterio
\end{itemize}

\paragraph{Problema fundamental: Objetivos imposibles}
El primer problema crítico que enfrentamos fue que el LLM generaba objetivos imposibles de completar: pedía conseguir objetos que no había creado, llegar a lugares inexistentes, o encontrar personajes no ubicados en el mundo. Este fue uno de los primeros problemas que motivó la implementación de validaciones exhaustivas.

Desarrollamos una función de verificación (\verb|verify_objective_completability|) que valida para cada tipo de objetivo:
\begin{itemize}
    \item \textbf{REACH\_LOCATION}: La ubicación objetivo existe y es alcanzable desde la ubicación inicial
    \item \textbf{GET\_ITEM}: El ítem objetivo existe, está ubicado en algún lugar accesible (ubicación o inventario de personaje), y tiene \verb|gettable=True|
    \item \textbf{DELIVER\_AN\_ITEM}: Tanto el ítem como el destino (ubicación o personaje) existen y son accesibles
    \item \textbf{FIND\_CHARACTER}: El personaje objetivo existe y está ubicado en una localización válida
    \item \textbf{SOLVE\_MYSTERY}: Todas las pistas del misterio están asociadas con ítems que existen en el mundo
\end{itemize}

\paragraph{Problema: Objetivos compuestos y mecánicas no soportadas}
En las primeras generaciones, el LLM frecuentemente creaba objetivos compuestos del estilo ``encuentra las 3 reliquias y únelas para armar la llave'' o ``consigue los 4 cristales elementales para activar el portal''. Estos objetivos presentaban dos problemas fundamentales:

\begin{itemize}
    \item El código no estaba preparado para manejar objetivos de múltiples elementos como una sola unidad cohesiva
    \item Las mecánicas de ``fusión'' o ``combinación'' de objetos no existían en el motor del juego (no hay sistema de \textit{crafting})
\end{itemize}

Consideramos implementar un tipo \verb|get_items| que se completara progresivamente (e.g., 33\% al obtener el primer ítem, 66\% al obtener el segundo, 100\% al obtener el tercero). Sin embargo, esto generó múltiples problemas y confusiones tanto en la implementación como en la experiencia del jugador. La solución más simple y robusta fue establecer reglas explícitas en el prompt que limitaran la complejidad de los objetivos:

\begin{itemize}
    \item \verb|GET_ITEM|: SOLO UN ítem objetivo (no colecciones múltiples)
    \item \verb|REACH_LOCATION|: SOLO UNA ubicación de destino
    \item \verb|FIND_CHARACTER|: SOLO UN personaje objetivo
    \item \verb|DELIVER_AN_ITEM|: UN ítem y UN destino
\end{itemize}

Esta restricción simplificó dramáticamente la verificación de completitud del objetivo y eliminó la ambigüedad sobre qué elementos eran requeridos versus opcionales.

\paragraph{Problema de narración: Objetivos mal comunicados}
Otro problema recurrente ocurría al narrar el objetivo al inicio de la aventura. En lugar de describir el objetivo, el LLM a veces respondía meta-comentarios como ``Perfecto! Narraré el objetivo entre símbolos'', lo cual claramente no era útil para el jugador. Intentamos mitigar esto con instrucciones más explícitas en el prompt y usando marcadores especiales (\verb|#objetivo#|) para extraer solo la parte relevante, pero el problema persistía ocasionalmente.

La solución definitiva fue dual: (1) mantener los intentos de corrección en el prompt para mejorar la narración inicial, y (2) crear un \textbf{quick action} que muestra el objetivo directamente desde la estructura del mundo (\verb|objective.description|), sin depender del LLM para su narración. Esta segunda solución no solo resuelve el bug de meta-comentarios sino que también permite a los usuarios consultar el objetivo en cualquier momento sin tener que hacer scroll hasta la narración inicial, mejorando significativamente la experiencia de usuario.


\paragraph{Cierre narrativo: Completion Narration}
La implementación del objetivo tipo \verb|solve_mystery| (que se discutirá a continuación) incluyó una narración de cierre al completar el objetivo (\verb|mystery_solution|). Esta característica resultó tan satisfactoria que decidimos extenderla a todos los tipos de objetivos mediante \verb|completion_narration|, que proporciona un desenlace narrativo al completar la aventura.

Sin embargo, en las evaluaciones con usuarios observamos que la narración de cierre ocasionalmente causaba confusión. Un evaluador completó un objetivo de tipo \verb|solve_mystery| con una sola pista, recibió la narración de cierre, pero interpretó que el juego continuaba y siguió jugando durante una hora adicional. Aunque el evaluador reportó haberse divertido, esto evidenció la necesidad de comunicar más explícitamente que el juego ha terminado, particularmente cuando los objetivos se completan más rápidamente de lo esperado.

\paragraph{Objetivos de Misterio: Diseño y Desafíos} \label{subsec:objetivos_misterio}
El tipo de objetivo \verb|solve_mystery| requirió el diseño más complejo y recibió mayor atención durante el desarrollo. A diferencia de los demás tipos de objetivos que se verifican mediante condiciones directas (posesión de un ítem, presencia en una ubicación), los objetivos de misterio se completan cuando el jugador descubre todas las pistas asociadas.

La mecánica funciona de la siguiente manera:
\begin{itemize}
    \item Cada pista (\verb|MysteryClue|) está asociada con un ítem físico del mundo
    \item Cuando el jugador interactúa con un ítem que tiene una pista asociada, el sistema (no el LLM) detecta la interacción y marca la pista como descubierta
    \item Se muestra al jugador un mensaje especial con el nombre de la pista, su descripción, su relevancia al misterio, y el progreso actual (X/N pistas descubiertas)
    \item Al descubrir todas las pistas, el objetivo se completa y se revela el \verb|mystery_solution|
\end{itemize}

Las reglas especiales en el prompt para objetivos de misterio incluyen:
\begin{itemize}
    \item Cada pista debe estar asociada ÚNICAMENTE con un objeto/ítem físico que existe en el mundo, NUNCA con personajes o ubicaciones
    \item El \verb|associated_item| debe ser exactamente el nombre de un objeto que aparece en la lista de ítems del mundo
    \item El objetivo debe incluir \verb|mystery_clues| (lista detallada de pistas) y \verb|mystery_solution| (solución completa del misterio)
    \item NO se usa \verb|completion_narration| para este tipo; en su lugar se usa \verb|mystery_solution|
\end{itemize}

\paragraph{Validación de pistas: Creación vs. Eliminación}
Similar al problema de recompensas inexistentes en puzzles, enfrentamos situaciones donde las pistas de misterio referenciaban ítems que no existían en el mundo. Sin embargo, adoptamos una estrategia opuesta a la usada con puzzles: en lugar de crear los ítems faltantes, eliminamos las pistas inválidas. Esta decisión se tomó porque crear ítems automáticamente para pistas podía resultar en objetos desconectados de la narrativa, mientras que eliminar pistas simplemente reducía el número de pistas a descubrir, manteniendo la coherencia del mundo.

Esta diferencia en el enfoque de validación (crear elementos faltantes para puzzles, eliminar elementos inválidos para pistas) refleja las diferentes prioridades: los puzzles son obstáculos activos que bloquean progresión y deben funcionar correctamente, mientras que las pistas son elementos opcionales de descubrimiento que pueden ajustarse en cantidad sin comprometer la jugabilidad fundamental.

Sin embargo, esta estrategia de eliminación ocasionalmente resultó en objetivos de misterio con muy pocas pistas (incluso una sola), lo cual contribuyó al problema mencionado anteriormente donde un evaluador completó el objetivo más rápidamente de lo anticipado. En retrospectiva, quizás hubiera sido preferible seguir la misma lógica que los puzzles: crear los ítems faltantes y ubicarlos coherentemente en el mundo.

\subsection{World Builder y Validación de Consistencia}

El \textit{World Builder} actúa como el eje central del proceso de generación, coordinando la ejecución secuencial de los cinco pasos y aplicando validaciones a los resultados de cada etapa. Esta arquitectura de validación por etapas resultó fundamental para detectar y corregir inconsistencias que el LLM introduce durante la generación, garantizando que los mundos finales sean estructuralmente válidos y jugables.

\paragraph{Orquestación y sistema de reintentos}
La función \verb|create_world_incrementally()| ejecuta el pipeline completo, manteniendo una única instancia del modelo de lenguaje y solicitando estructuras Pydantic en cada paso. Implementamos un sistema de reintentos con máximo 3 intentos por paso, ejecutando validaciones específicas según la etapa:

\begin{itemize}
    \item \textbf{Paso 2}: Esquema Pydantic + verificación de tamaños configurados
    \item \textbf{Paso 3}: Esquema Pydantic + conectividad de ubicaciones (DFS) + completabilidad del objetivo
    \item \textbf{Paso 4}: Esquema Pydantic + recompensas de puzzles + re-validación de conectividad y completabilidad
\end{itemize}

Si cualquier validación falla, se descarta la generación y se reintenta el paso. Tras 3 intentos fallidos, el pipeline completo falla con excepción descriptiva.

\paragraph{Diferencia crítica: Corrección vs. Rechazo}
Las recompensas faltantes en puzzles se \textbf{corrigen automáticamente} dentro del intento actual, permitiendo salvar mundos con olvidos menores. Los objetivos imposibles \textbf{causan rechazo y reintento completo} del paso. Esta asimetría refleja criticidad relativa: puzzles son problemas localizados corregibles; objetivos imposibles invalidan la jugabilidad completa.

Sin embargo, esta estrategia de rechazo para objetivos presenta una limitación fundamental: si el LLM es consistentemente inconsistente (generando repetidamente objetivos con ítems que no incluye en la lista de elementos del mundo) los 3 reintentos fallarán y el pipeline colapsará. La validación \verb|verify_objective_completability()| detecta correctamente estos problemas, pero no puede corregirlos automáticamente como sí hace \verb|verify_puzzle_rewards_and_fix()| con los puzzles. El LLM se puede ``olvidar'' de incluir un ítem importante del objetivo en \verb|world.items| aunque se referencien en \verb|objective.components|, y las instrucciones del prompt no siempre son suficientes para prevenir esta inconsistencia.

Como se discutirá en el Capítulo 5, esta fragilidad resultó en algunos mundos que, tras agotar los reintentos, pasaron las validaciones pero presentaron problemas sutiles durante gameplay real, evidenciando que la validación post-generación no puede compensar completamente la inconsistencia inherente del LLM durante la generación.

\paragraph{Debugging mediante JSON estructurado}
Implementamos serialización completa del estado usando jsonpickle, guardando el mundo en turno 0 con todas las referencias de objetos. Este JSON detectó inconsistencias no evidentes durante gameplay (puzzles existentes pero no presentados, recompensas mencionadas pero no estructuradas). Por ejemplo, el ``Rescue Net'' faltaba en \verb|world.items| pese a estar en \verb|objective.components|—invisible en gameplay pero inmediato en JSON.

\paragraph{Validación final}
Tras el Paso 4, se verifica tamaño del mundo, conectividad y completabilidad del objetivo. Si fallan, se emiten advertencias pero no se rechaza el mundo (reintentos agotados). En práctica, estas validaciones rara vez fallan si las intermedias fueron exitosas.

\subsection{Lógica de Juego y Ciclo de Interacción} \label{sec:logica_juego}

La lógica de juego implementa un ciclo que combina generación narrativa del LLM con intervenciones determinísticas del sistema. Este enfoque busca generar un equilibrio, y así aprovechar la capacidad creativa del LLM para generar narrativas ricas y responder a acciones impredecibles del jugador, pero sin dejarlo completamente responsable de las mecánicas críticas del juego que, como observamos durante el desarrollo, frecuentemente olvida o ejecuta incorrectamente.

\paragraph{Ciclo básico de interacción}
El \verb|game_loop| procesa cada acción mediante: (1) detección de comandos especiales, (2) procesamiento estructurado generando \verb|WorldUpdate|, (3) aplicación de cambios vía \verb|world.update_from_structured()|, (4) generación narrativa con segundo LLM, (5) verificación de completitud del objetivo, (6) presentación con estado formateado del mundo.

\paragraph{Quick Actions}
Implementamos acciones que responden sin invocar al LLM:
\begin{itemize}
    \item \textbf{Ver objetivo}: Muestra \verb|objective.description| directamente, con progreso de pistas para misterios
    \item \textbf{Solicitar ayuda}: Activa sistema de hints adaptativo
    \item \textbf{Debug} (desarrollo): Inspeccionar mundo (estadísticas, grafo, puzzles) y resumen (ubicaciones, conexiones, inventarios)
\end{itemize}

\paragraph{Sistema de hints adaptativo}
Implementado vía \verb|world.update_hints()|, adapta sugerencias según situación: sin puzzle ofrece \verb|objective_hints|; puzzle no iniciado usa \verb|interaction_hint|; puzzle presentado cambia a \verb|puzzle_hints|. Pistas en orden ascendente de especificidad (típicamente 3), rastreando entregadas vía atributo \verb|given|. Se actualiza al cambiar ubicación, proponer puzzle o resolverlo.

\paragraph{Intervenciones del sistema}
Implementamos intervenciones determinísticas para mecánicas críticas:
\begin{itemize}
    \item Proposición forzada de puzzles (intercepta menciones a NPCs)
    \item Entrega automática de recompensas (\verb|_apply_puzzle_rewards|)
    \item Desbloqueo automático de pasajes resueltos
    \item Descubrimiento de pistas de misterio (análisis de narración + marcado automático)
\end{itemize}

Estas reflejan una lección fundamental: el LLM maneja creatividad narrativa e interpretación de intenciones; el sistema maneja mecánicas determinísticas y validaciones.

\paragraph{Verificación de completitud}
\verb|check_objective_completion| evalúa cada turno con verificaciones específicas por tipo (inventario para GET\_ITEM, ubicación para REACH\_LOCATION, etc.). Al completarse, presenta narración de cierre y registra éxito en log.



\section{Integración con LLMs}

\subsection{Modelos estructurados con Pydantic}

La integración con modelos de lenguaje es uno de los desafíos centrales del enfoque neurosimbólico, y en particular con la nueva versión de PAYADOR. Necesitamos que el LLM genere mundos jugables, pero la salida en lenguaje natural no garantiza la coherencia estructural requerida por el motor del juego, o por lo menos implica una dificultad extra no menor. Resolvimos esto mediante un sistema de modelos estructurados con Pydantic que actúa como contrato entre el LLM y el motor.

\paragraph{Motivación y diseño} 
Los LLMs modernos pueden generar salidas estructuradas en JSON cuando se les solicita explícitamente en el prompt, pero sin validación automática esto resulta fragil, como se comentó anteriormente: el modelo puede omitir campos, usar tipos incorrectos, etc. Implementamos modelos Pydantic que definen esquemas tipados con validaciones embebidas, permitiendo rechazar salidas malformadas antes de que lleguen al motor.

La arquitectura de modelos sigue la jerarquía del mundo de juego. En el nivel superior tenemos \verb|GeneratedWorld|, que encapsula:
\begin{itemize}
    \item \texttt{locations: List[GeneratedLocation]} - Ubicaciones con descripciones, conexiones y pasajes bloqueados
    \item \texttt{items: List[GeneratedItem]} - Objetos con tipo de acción mecánica (\texttt{ItemActionType})
    \item \texttt{puzzles: List[GeneratedPuzzle]} - Acertijos con respuestas, pistas y recompensas
    \item \texttt{player: GeneratedCharacter} - Personaje del jugador con ubicación inicial
    \item \texttt{objective: GeneratedObjective} - Objetivo principal con componentes y condiciones
\end{itemize}

\paragraph{Enums y restricciones de dominio}
Definimos enumeraciones para tipos de entidades críticas, forzando al LLM a usar valores válidos. Por ejemplo, \verb|ItemActionType| restringe las acciones de objetos a cuatro categorías que el motor puede procesar: \verb|UNLOCK_PASSAGE| para llaves, \verb|SOLVE_PUZZLE| para pistas, \verb|GIVE_TO_CHARACTER| para entregas y \verb|LORE| para elementos decorativos. Esto elimina la ambigüedad que observamos en iteraciones tempranas donde el modelo generaba acciones inventadas que el motor no reconocía.

Similarmente, \verb|ObjectiveType| restringe los objetivos a cinco tipos implementados: \verb|GET_ITEM|, \verb|REACH_LOCATION|, \verb|FIND_CHARACTER|, \verb|DELIVER_AN_ITEM| y \verb|SOLVE_MYSTERY|. Cada tipo tiene lógica de verificación específica en el motor, y el uso de enums garantiza que no se generen objetivos no soportados.

\paragraph{Reglas de consistencia embebidas}
Los modelos incorporan reglas de coherencia mediante descripciones de campos que actúan como especificación para el LLM. Por ejemplo, \verb|GeneratedItem| tiene el campo:
\begin{verbatim}
is_objective_target: bool = Field(
    default=False, 
    description="Whether this item is required to complete the 
                 main objective. Note: objective targets must 
                 always be gettable=True"
)
\end{verbatim}

Esta descripción instruye al modelo sobre la relación entre \verb|is_objective_target| y \verb|gettable|. Esto es útil tanto para el modelo como para nosotros. Además, observamos que incluir estas anotaciones explícitas en las descripciones reduce significativamente errores de coherencia interna en la salida del LLM. Funcionan como reglas extra por fuera del prompt.

Un caso más complejo es \verb|GeneratedLocation.items|, cuya descripción advierte: \textit{``An item required to unlock a passage CANNOT be placed in the location behind that very passage or any location only accessible through it''}. Esta regla previene configuraciones imposibles donde la llave está del otro lado de la puerta que debe abrir.

\paragraph{Modelos jerárquicos de recompensas}
Para puzzles implementamos un sistema de recompensas tipadas mediante herencia de Pydantic. \verb|PuzzleReward| es la clase base con \verb|reward_type: RewardType|, y las subclases especializan el comportamiento:

\begin{itemize}
    \item \verb|PassageReward| - Desbloquea un pasaje entre dos ubicaciones existentes
    \item \verb|ItemReward| - Otorga un objeto del mundo al inventario del jugador
    \item \verb|ObjectiveReward| - Marca el objetivo principal como completado
\end{itemize}

Esta jerarquía le permite al motor aplicar la recompensa correcta automáticamente mediante polimorfismo, y al LLM generar recompensas válidas sin necesidad de lógica condicional compleja en los prompts.

\paragraph{Validación de referencias cruzadas}
Los esquemas documentan explícitamente las restricciones de referencia mediante anotaciones en las descripciones. Por ejemplo, \verb|GeneratedPuzzle.proposed_by_character| especifica: \textit{``Note: if specified, this character must exist in the world''}. Si bien Pydantic no valida estas referencias automáticamente (requeriría acceso al contexto del mundo completo durante el parsing), estas anotaciones cumplen dos funciones: (1) instruyen al LLM sobre la restricción durante la generación, y (2) documentan las validaciones que luego ejecutamos explícitamente en el pipeline de generación.

Estas validaciones post-parsing incluyen verificar conectividad bidireccional de ubicaciones, existencia de items referenciados en inventarios, y validez de cadenas de dependencias. Las implementamos en funciones especializadas como \verb|verify_location_connectivity()| y \verb|verify_objective_completability()| que rechazan mundos con referencias rotas.

\paragraph{Modelos para el pipeline incremental}
Para soportar la generación en etapas implementamos modelos intermedios ligeros. \verb|WorldConcept| captura solo el concepto inicial (título, historia de fondo, concepto del jugador, objetivo general), y \verb|WorldSkeleton| define las entidades clave mediante \verb|KeyEntity| (nombre + propósito) sin detalles completos. Esto permite que cada paso del pipeline genere y valide su salida independientemente antes de pasar al siguiente.

\paragraph{Integración con el motor}
El módulo \verb|world_builder.py| traduce instancias de \verb|GeneratedWorld| a objetos del motor (\verb|World|, \verb|Location|, \verb|Item|, etc.). Este proceso incluye resolución de nombres a referencias de objetos, establecimiento de conexiones bidireccionales y validación de la jugabilidad del mundo resultante. La separación entre modelos de generación (Pydantic) y modelos del motor (clases Python tradicionales, es decir, el estado simbólico) mantiene las responsabilidades claras: Pydantic valida la estructura de la salida del LLM, el motor implementa la lógica de juego.



\subsection{Memoria persistente con RAG y ChromaDB}

Los LLMs son fundamentalmente sin estado: cada invocación recibe solo el contexto del prompt actual y olvida interacciones previas. Para narrativas interactivas largas esto representa un problema crítico, el jugador puede resolver un puzzle, hablar con un personaje o descubrir información importante en el turno 5, pero para el turno 20 el LLM no tiene acceso a ese contexto a menos que lo incluyamos explícitamente en el prompt. Implementamos un sistema RAG (Retrieval-Augmented Generation) con memoria episódica que transforma PAYADOR de un generador de mundos en un narrador con memoria persistente.

\paragraph{Arquitectura del sistema de memoria}
El sistema se compone de cuatro componentes que trabajan coordinadamente: \verb|AtomicMemory| como unidad básica de memoria, \verb|EmbeddingService| para generar representaciones vectoriales, \verb|MemoryStore| como base de datos vectorial persistente, y \verb|IntelligentMemorySystem| que coordina la ingestión y recuperación. La figura \ref{fig:rag_overview} ilustra de forma simple el proceso.

\begin{figure}
    \centering
    \includegraphics[width=0.75\linewidth]{figs/rag-overview.png}
    \caption{Vista general del sistema de recuperación de recuerdos relevantes para la acción del jugador}
    \label{fig:rag_overview}
\end{figure}

\verb|AtomicMemory| encapsula la información de un turno de juego: número de turno, acción del jugador, narración resultante, resumen del estado del mundo y timestamp. Cada memoria puede serializarse a texto mediante \verb|to_text()| para generar embeddings, o a diccionario mediante \verb|to_dict()| para el almacenamiento en ChromaDB. La serialización a diccionario aplana metadatos a tipos primitivos (strings, ints, floats, bools) porque ChromaDB no soporta estructuras anidadas complejas en sus metadatos.

\paragraph{Embeddings semánticos con Gemini}
\verb|EmbeddingService| genera representaciones vectoriales densas usando el modelo \verb|gemini-embedding-001| de Google. Configuramos el servicio con \verb|task_type="RETRIEVAL_DOCUMENT"| y \texttt{output\_dimensionality=768}, obteniendo embeddings de 768 dimensiones que capturan el significado semántico del texto. Aplicamos normalización L2 a los vectores resultantes como recomienda la documentación de Gemini, lo que mejora la calidad de las búsquedas por similitud coseno.

La elección de embeddings sobre búsqueda léxica tradicional (palabras clave, BM25) permite recuperar memorias conceptualmente relevantes aunque no compartan términos exactos. El beneficio principal que observamos es relativo a la narración, donde se nota que el sistema recuerda eventos pasados y elabora narraciones acorde a lo que se está intentando hacer en el momento y lo que se hizo en el pasado.

\paragraph{Almacenamiento vectorial con ChromaDB}
\verb|MemoryStore| maneja la persistencia mediante ChromaDB, una base de datos vectorial diseñada para aplicaciones de embeddings. Creamos un \verb|PersistentClient| que escribe en disco (directorio \verb|gamelogs/memory_db|) para que las memorias persistan entre sesiones. Cada mundo de juego tiene su propia colección identificada por \verb|world_id|.

El método \verb|add_memory()| almacena tres elementos por cada memoria: el embedding vectorial para búsquedas de similitud, el documento de texto para recuperación legible, y los metadatos estructurados para filtrado y reconstrucción. Cada memoria recibe un ID único basado en turno y timestamp (\verb|turn_{turn_number}_{timestamp}|).

\verb|search_memories()| ejecuta búsquedas por similitud coseno usando un query embedding como entrada y devolviendo las top-k memorias más relevantes. ChromaDB ordena los resultados por score de similitud automáticamente priorizando memorias semánticamente cercanas a la acción actual.

\paragraph{Sistema coordinador}
\verb|IntelligentMemorySystem| orquesta el flujo completo de ingestión y recuperación. Durante la ingestión (\verb|ingest_memory()|), el sistema: (1) crea un \verb|AtomicMemory| con los datos del turno, (2) genera su representación textual, (3) computa el embedding mediante \verb|EmbeddingService|, (4) almacena en \verb|MemoryStore| con el vector y metadatos, y (5) actualiza el contador de último turno procesado.

La recuperación (\verb|retrieve_relevant_memories()|) funciona inversamente: (1) recibe la acción actual del jugador, (2) genera su embedding, (3) busca en ChromaDB las memorias más similares, (4) retorna objetos \verb|AtomicMemory| reconstruidos desde los metadatos almacenados. El método \verb|format_memories_for_prompt()| transforma estas memorias en texto estructurado para inyección en el prompt del LLM.

\paragraph{Resúmenes contextuales enriquecidos}
Para mejorar la calidad de los embeddings implementamos \verb|create_world_state_summary()| en \verb|world_utils.py|, que genera resúmenes ricos del estado del mundo en cada turno. En lugar de almacenar solo ``el jugador tomó la llave'', capturamos: ubicación actual, descripción del lugar (truncada a 100 caracteres), objetos visibles, personajes presentes, inventario del jugador, objeto clave mencionado en la acción y la acción textual completa. Este contexto adicional mejora la recuperación posterior: si el jugador pregunta sobre un personaje, el embedding de la memoria incluye información de dónde estaba ese personaje y qué objetos tenía disponibles, por ejemplo.

\paragraph{Integración con el bucle de juego}
Integramos el sistema RAG en dos puntos del ciclo de turno en \verb|game_logic.py|. Antes de procesar la acción del jugador, llamamos a \verb|retrieve_relevant_memories()| con el input actual, obtenemos las top-3 memorias más relevantes y las formateamos para inclusión en el prompt mediante \verb|format_memories_for_prompt()|. El prompt \verb|prompt_world_update_structured()| incluye una sección ``Recuerdos Relevantes del Pasado'' o ``Relevant Past Memories'' que precede al estado actual del mundo, con instrucciones explícitas al LLM de considerar esos eventos pasados al generar la respuesta.

Después de procesar exitosamente el turno, ejecutamos \verb|ingest_memory()| con el número de turno, acción del jugador, narración generada y resumen del estado del mundo. Esta ingestión post-turno asegura que cada memoria refleja el resultado final después de aplicar cambios estructurados al mundo, no predicciones intermedias.

\paragraph{Carga de memorias desde MongoDB}
El método \verb|load_memories_from_db()| permite ``rehidratar'' memorias desde trazas persistidas en MongoDB. Este proceso es útil para cuando un jugador retoma una partida guardada: iteramos sobre los turnos almacenados en la traza, deserializamos el estado del mundo usando \verb|jsonpickle.decode()|, regeneramos el resumen contextual con \verb|create_world_state_summary()|, y reingestamos cada memoria en ChromaDB. Esta rehidratación reconstruye completamente la base vectorial, lo que permite que el sistema de memoria funcione como si el juego nunca se hubiera interrumpido.

La deserialización con jsonpickle es fundamental aquí porque en lugar de trabajar con JSON plano que requeriría reconstrucción manual del mundo, obtenemos directamente instancias completas de \verb|World| con todos sus objetos, métodos y relaciones intactas. Esto nos permite llamar a \verb|create_world_state_summary()| con el objeto \verb|World| real de ese turno histórico para generar resúmenes idénticos a los que se habrían creado durante el juego original.

\paragraph{Observaciones sobre rendimiento}
El sistema tiene dos puntos de latencia: generación de embeddings (llamadas a la API de Gemini) y búsquedas en ChromaDB. Los embeddings agregan aproximadamente menos de un segundo por turno, pero esto es aceptable porque sucede post-turno de forma asíncrona al jugador (ya vio la narración). Las búsquedas vectoriales en ChromaDB son rápidas incluso con cientos de memorias (< 50ms típicamente) porque usa índices optimizados para similitud coseno. Deshabilitamos telemetría de ChromaDB mediante \verb|ANONYMIZED_TELEMETRY=False| para reducir overhead de red.

Un problema recurrente durante el desarrollo y evaluación fue el manejo de errores en la API de embeddings: si Gemini está temporalmente no disponible, el sistema genera un vector cero como fallback. Esto degrada la calidad de búsquedas pero permite que el juego continúe. Una mejora futura podría ser implementar reintentos con \textit{exponential backoff} para la generación de embeddings.



\subsubsection{Persistencia de trazas con MongoDB} \label{subsec:mongodb}

El sistema de memoria RAG mantiene contexto semántico, pero para recuperación completa de partidas necesitamos persistir el estado exacto del mundo en cada turno. Implementamos un sistema de trazas con MongoDB que serializa toda la sesión de juego, permitiendo replay completo, debugging de comportamiento del LLM y análisis post partidas.

\paragraph{Arquitectura singleton del handler}
\verb|MongoHandler| implementa el patrón singleton para tener una única instancia de conexión a la base de datos compartida por todo el sistema. En la construcción, cargamos configuración desde \verb|config.ini| y variables de entorno (\verb|MONGO_URI|), creamos el cliente de PyMongo, seleccionamos database y colección, y ejecutamos \verb|client.admin.command('ping')| para validar conectividad. Si la conexión falla, la instancia se deja como \verb|None| y se imprime el error, permitiendo que el sistema continúe sin persistencia.

\paragraph{Estructura de documentos de traza}
Cada partida se almacena como un documento MongoDB con la siguiente estructura:

\begin{itemize}
    \item \verb|world_id|: Identificador único generado como \verb|"generated_{timestamp}"| al inicio de la sesión
    \item \verb|nickname|: Nombre del jugador (opcional, para organización)
    \item \verb|language|: Idioma de la partida (español/inglés)
    \item \verb|narrative_model_name|: Nombre del modelo LLM usado para narración
    \item \verb|reasoning_model_name|: Nombre del modelo LLM usado para razonamiento
    \item \verb|inspiration|: Tema o frase inspiradora si se usó modo inspiration (vacío en otros modos)
    \item \verb|created_at|: Timestamp de creación de la partida
    \item \verb|turns|: Objeto anidado con turnos indexados numéricamente (0, 1, 2, ...)
\end{itemize}

Cada entrada en \verb|turns| es un subdocumento que captura el estado completo de ese turno: fecha/hora, input del usuario, estado simbólico del mundo pre-turno (serializado con jsonpickle), estado renderizado del mundo pre-turno (texto legible), predicciones del LLM, cambios estructurados aplicados y narración resultante.

\paragraph{Inicialización de trazas}
\verb|initialize_trace()| inserta el documento base cuando comienza una nueva partida. Invocado desde \verb|create_game_loop()| después de generar el mundo, el método recibe un diccionario con metadatos de sesión y el turno 0 que contiene el estado inicial del mundo. Usamos \verb|collection.insert_one()| y retornamos el \verb|inserted_id| de MongoDB, aunque este ID rara vez se usa posteriormente (preferimos buscar por \verb|world_id| semántico).

El turno 0 es especial: captura \verb|initial_symbolic_world_state| (mundo completo con \verb|jsonpickle.encode(world, unpicklable=True)|), \verb|initial_rendered_world_state| (representación textual para humanos) y opcionalmente \verb|starting_narration| (primera descripción de la escena). Este turno 0 permite recrear el mundo exactamente como estaba al inicio de la partida.

\paragraph{Adición incremental de turnos}
\verb|add_turn_to_trace()| agrega turnos subsecuentes usando el operador \verb|$set| de MongoDB. En lugar de recuperar el documento completo, modificarlo en memoria y reescribirlo, usamos \verb|update_one()| con \verb|{"$set": {f"turns.{turn_number}": turn_data}}|. Esta notación con dot notation de MongoDB (\verb|turns.5|) actualiza solo el subdocumento del turno específico, minimizando tráfico de red y previniendo race conditions si múltiples procesos escribieran simultáneamente (aunque PAYADOR es single-player y esto no sucede actualmente).

Invocamos \verb|add_turn_to_trace()| al final de cada ciclo del game loop en \verb|save_game_log()|, después de que la narración final está lista. Los datos del turno incluyen \verb|user_input| (acción del jugador), \verb|previous_symbolic_world_state| (mundo serializado pre-acción con \verb|unpicklable=False| para compatibilidad), \verb|predicted_outcomes| (lo que el LLM predijo que sucedería), \verb|structured_update| (cambios validados aplicados) y \verb|narration| (texto narrativo final).

\paragraph{Serialización con jsonpickle}
Usamos jsonpickle en lugar de JSON estándar para serializar el objeto \verb|World|. Python pickle puede serializar objetos arbitrarios con referencias circulares y métodos, pero no es legible ni compatible con MongoDB. jsonpickle convierte objetos Python a JSON agregando metadatos de tipo (\verb|"py/object"|) que permiten deserialización precisa.

Configuramos dos modos: \verb|unpicklable=True| en el turno 0 incluye toda la información necesaria para reconstruir el objeto completo con métodos, usado por \verb|create_world_from_trace()| para cargar partidas guardadas. \verb|unpicklable=False| en turnos subsecuentes genera JSON más limpio sin metadatos de reconstrucción, suficiente para análisis y visualización pero no para ejecución.

\paragraph{Recuperación de trazas}
\verb|get_trace_by_world_id()| recupera el documento completo de una partida mediante \verb|find_one({"world_id": world_id})|. Retorna el documento como diccionario Python con toda la estructura anidada de turnos. Este método es fundamental para el modo replay de la UI: permite al jugador ingresar un \verb|world_id| de partida previa y volver a jugarla, o, para nosotros como desarrolladores, analizar el mundo.

\verb|trace_exists()| verifica existencia sin transferir todo el documento, usando \verb|count_documents()| que retorna 0 o 1. Útil para validación antes de intentar cargar, evitando errores si el usuario ingresa un \verb|world_id| inexistente.

\paragraph{Rehidratación para replay}
El sistema de memoria RAG usa \verb|load_memories_from_db()| que consume estas trazas: itera sobre \verb|turns|, deserializa cada \verb|previous_symbolic_world_state| con \verb|jsonpickle.decode()|, regenera el resumen contextual y reingesta en ChromaDB. Esta integración entre MongoDB (almacenamiento estructurado completo) y ChromaDB (índice semántico) lo que permite es que el replay no solo restaure el estado del mundo sino también el contexto conversacional.

\paragraph{Consideraciones de diseño}
La estructura anidada con \verb|turns| como objeto (no array) facilita acceso directo: \verb|turns.5| recupera el turno 5 sin iterar. Esto es eficiente para MongoDB pero requiere conversión a lista ordenada cuando procesamos turnos cronológicamente. La decisión de usar \verb|$set| incremental versus reescribir documento completo prioriza performance sobre atomicidad: si \verb|add_turn_to_trace()| falla, ese turno se pierde pero turnos previos permanecen intactos.

Un desafío observado fue debugging de partidas problemáticas: inicialmente se serializaba solo el estado renderizado (texto), insuficiente para reproducir bugs. Agregar serialización simbólica completa con jsonpickle nos permitió cargar el mundo exacto para encontrar donde ocurrió cierto error y debuggear interactivamente, crítico para diagnosticar comportamiento inesperado del LLM o el motor. En definitiva, esto nos ofrece algo clave para el testing: la reproducibilidad, aunque un error que cometimos es tardar en tener esta feature.


\subsection{Estrategias de prompting y manejo de errores}

La interacción con LLMs mediante prompts representa tanto el punto de mayor flexibilidad como el de mayor fragilidad del sistema. Un prompt mal diseñado puede resultar en salidas incoherentes, incompletas o incompatibles con el motor de juego. Desarrollamos estrategias de prompting y manejo de errores que evolucionaron iterativamente a través de múltiples ciclos de prueba y refinamiento.

\paragraph{Jerarquía de prompts especializados}
Implementamos una librería de prompts diferenciados por función y fase del pipeline. Los prompts de generación incremental (\verb|PROMPT_STEP_1_CONCEPT|, \verb|PROMPT_STEP_2_SKELETON|, \verb|PROMPT_STEP_3_DETAILS|, \verb|PROMPT_STEP_4_PUZZLES|) construyen el mundo en etapas, cada uno con restricciones específicas. Los prompts de juego (\verb|prompt_world_update_structured|, \verb|prompt_narrate_current_scene|) manejan la interacción dinámica con el jugador. Los prompts de utilidad (\verb|prompt_describe_objective|) generan descripciones alternativas de elementos del juego.

Esta separación tiene como objetivo poder ajustar cada prompt independientemente según su contexto de uso. Por ejemplo, \verb|prompt_narrate_current_scene| incluye lógica condicional para la primera visita a una ubicación versus revisitas, modificando las instrucciones para evitar repetir descripciones que el jugador ya conoce.

\paragraph{Reglas embebidas en prompts}
Los prompts de generación incluyen secciones explícitas de reglas que actúan como especificación ejecutable para el LLM. \verb|PROMPT_STEP_3_DETAILS| contiene bloques de ``RESTRICCIONES TÉCNICAS OBLIGATORIAS'' que detallan:
\begin{itemize}
    \item \textbf{Conectividad global}: ``TODAS las ubicaciones deben ser accesibles desde cualquier punto del mundo - NO puede haber ubicaciones aisladas''
    \item \textbf{Bidireccionalidad}: ``Si A conecta con B, entonces B DEBE conectar con A''
    \item \textbf{Completabilidad}: ``El objetivo DEBE ser completable con los elementos que crees''
    \item \textbf{Consistencia de referencias}: ``Todo objeto en inventarios de personajes DEBE existir en la lista de objetos del mundo''
\end{itemize}

Estas reglas son redundantes con las validaciones posteriores en código, pero observamos que incluirlas en el prompt reduce la cantidad de mundos rechazados en validación. El LLM tiende a seguir instrucciones explícitas cuando están claramente enumeradas y destacadas tipográficamente.

\paragraph{Ejemplos inline y formato esperado}
Para guiar la salida estructurada incluimos ejemplos concretos directamente en los prompts. Por ejemplo, el prompt para objetivos de misterio muestra:
\begin{verbatim}
**EJEMPLO DE PISTAS DE MISTERIO CORRECTAS:**
{
  "name": "Huellas fangosas",
  "description": "Hay huellas fangosas que conducen...",
  "associated_item": "Botas de jardín",
  "item_location": "Cobertizo del jardín",
  ...
}
\end{verbatim}
Este ejemplo inline especifica tanto el formato JSON esperado como el tipo de contenido semántico apropiado. Observamos que los LLMs entienden mejor con ejemplos que con descripciones abstractas, particularmente para estructuras anidadas complejas como las que elaboramos.

\paragraph{Instrucciones multilingües consistentes}
Todos los prompts principales tienen versiones en español e inglés mantenidas en paralelo. Implementamos funciones dispatcher (\verb|prompt_world_update_structured()|, \verb|prompt_narrate_current_scene()|) que seleccionan la versión correcta según el parámetro \verb|language|. Esta arquitectura facilita mantener coherencia entre idiomas aunque sería complicado agregar soporte más aparte de español e inglés.

Un aspecto crítico es la instrucción de idioma al final de cada prompt: ``La respuesta DEBE estar íntegramente en español. Todos los valores de texto deben ser generados en español. Las claves del JSON deben permanecer en inglés para coincidir con el esquema''.  Tuvimos que agregar esta regla al final de los prompts en español porque las claves de los esquemas están en inglés y el modelo no logra entender, en ocasiones, que el contenido generado debe estar en español.

\paragraph{Validación por capas con reintentos}
El pipeline de generación implementa validación multicapa después de cada paso, con reintentos automáticos en caso de fallo. Por ejemplo, en \verb|run_step_3_details()| ejecutamos tres validaciones secuenciales:

\begin{enumerate}
    \item \verb|verify_pydantic_model()| - Valida estructura JSON y tipos
    \item \verb|verify_location_connectivity()| - Verifica conectividad global mediante DFS
    \item \verb|verify_objective_completability()| - Valida existencia y accesibilidad de componentes del objetivo
\end{enumerate}

Si cualquier validación falla, imprimimos el error específico, incrementamos el contador de intentos y regeneramos desde el LLM. Configuramos un máximo de 3 intentos por defecto, lanzando \verb|ValueError| si se agotan. Esto tiene como objetivo permitir recuperación automática de errores transitorios del LLM a la vez que previene loops infinitos.

\paragraph{Verificación de conectividad con DFS}
\verb|verify_location_connectivity()| implementa búsqueda en profundidad sobre el grafo de ubicaciones para detectar particiones. Construimos un diccionario de adyacencia que incluye tanto conexiones normales como pasajes bloqueados (que son conexiones temporalmente inaccesibles pero estructuralmente presentes), ejecutamos DFS desde la primera ubicación y comparamos el conjunto de nodos visitados contra el conjunto total de ubicaciones. Si detectamos ubicaciones no alcanzables, imprimimos debug detallado con la lista de ubicaciones aisladas y el mapa de adyacencia completo para facilitar el diagnóstico.

\paragraph{Reparación automática de recompensas}
\verb|verify_puzzle_rewards_and_fix()| implementa una estrategia de reparación además de validación. Si un puzzle otorga como recompensa un objeto que no existe en el mundo, el sistema lo crea automáticamente y lo coloca en el inventario del personaje que propone el puzzle (o en la ubicación del puzzle si es ambiental). Esta heurística refleja una observación del desarrollo: cuando el LLM menciona un objeto recompensa inexistente, generalmente es un olvido coherente con la narrativa, no un error conceptual. Crear el objeto permite continuar la generación en lugar de rechazar todo el mundo.

\paragraph{Manejo de errores de API}
Los wrappers de modelos (\verb|GeminiModel|, \verb|OpenAIModel|,) implementan manejo robusto de errores de red. Detectamos errores 503 (servicio sobrecargado) y aplicamos reintentos con delay fijo (2 segundos por defecto). Para OpenAI también manejamos rate limiting (error 429) con exponential backoff: el delay se duplica en cada reintento ($2^{attempt}$ segundos).

\verb|prompt_model_structured()| en \verb|GeminiModel| maneja casos especiales de JSON malformado. Si la respuesta incluye marcadores markdown (\verb|```json|), los removemos automáticamente. Implementamos \verb|_is_json_complete()| que valida heurísticamente la completitud del JSON contando llaves y corchetes, detectando respuestas truncadas por límites de tokens. Si detectamos JSON incompleto, reintentamos la generación completa.

\paragraph{Fallbacks y respuestas vacías}
Cuando se agotan los reintentos, los métodos \verb|prompt_model()| retornan mensajes de error legibles para el usuario (``El modelo está sobrecargado o no respondió''), mientras que \verb|prompt_model_structured()| retorna estructuras vacías válidas mediante \verb|_get_empty_response_for_schema()|. Este método inspecciona el esquema esperado e intenta instanciar un objeto mínimo compatible, priorizando que el sistema continúe funcionando sobre generar contenido rico pero arriesgando crashes.

\paragraph{Detección de JSON truncado}
Una observación crítica del desarrollo fue que los LLMs ocasionalmente truncan respuestas JSON cuando se aproximan al límite de tokens de salida (\verb|max_output_tokens=8192| para Gemini). Implementamos \verb|_is_json_complete()| que verifica: (1) la respuesta no está vacía, (2) cuenta de llaves de apertura/cierre coincide, (3) cuenta de corchetes de apertura/cierre coincide, y (4) la respuesta termina en llave de cierre. Si detectamos truncamiento, reintentamos con la esperanza de que el LLM genere una versión más concisa que quepa en el límite.

\paragraph{Logging estructurado para debugging}
Todos los pasos del pipeline imprimen mensajes de progreso y debug con prefijos identificables: \verb|[DEBUG]|, \verb|[WARNING]|, \verb|[ERROR]|. Durante la generación incremental, cada callback de progreso reporta el paso actual y resultados parciales (``Concepto de mundo generado exitosamente'', ``Conectividad de ubicaciones falló en intento 2''). Este logging nos permitió diagnosticar fallos de generación revisando logs de consola sin necesidad de debugger interactivo, algo importante para entender el comportamiento de los modelos en producción.




\section{Interfaz de usuario}

La interfaz de usuario determina cómo los jugadores interactúan con el sistema y experimentan la narrativa generada. Implementamos una interfaz web con Streamlit que balancea accesibilidad para usuarios no técnicos con funcionalidades avanzadas que nos resultaron de utilidad para desarrollo y testing. La figura \ref{fig:interfaz} muestra un vistazo genral a la nueva interfaz de PAYADOR.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figs/interfaz.png}
    \caption{Nueva interfaz de PAYADOR en Streamlit}
    \label{fig:interfaz}
\end{figure}

\subsection{Modos de juego (Preset, Generate, Inspiration)}

Diseñamos tres modos de generación de mundos que ofrecen diferentes niveles de control y previsibilidad, permitiendo que el sistema sirva tanto a jugadores casuales como a testers y desarrolladores.

\paragraph{Modo Inspiration}
El modo \verb|inspiration| permite al usuario proporcionar una frase o temática que inspira la generación del mundo. Implementamos un campo de texto donde el usuario ingresa conceptos como ``el misterio sobre el robo del cuadro'' o ``exploración espacial en una estación abandonada''. Este input se pasa directamente como parámetro \verb|theme| a \verb|run_step_1_concept()|, iniciando el pipeline incremental.

Agregamos sugerencias populares pre-definidas como botones clickeables: tres categorías temáticas que al hacer click rellenan automáticamente el campo de texto con descripciones más detalladas. Esta funcionalidad reduce la barrera de entrada para usuarios que no saben qué escribir, guiándolos con ejemplos concretos.

La generación desde inspiración ejecuta los cuatro pasos del pipeline de forma secuencial con feedback visual: cada paso muestra su mensaje de progreso (``Paso 1: Generando concepto del mundo...''), actualiza una barra de progreso (20\%, 50\%, 70\%, 90\%) y muestra mensajes de confirmación con detalles (``Concepto creado: 'La Mansión Blackwood'''). Este feedback reduce la ansiedad del usuario durante los 30-60 segundos que toma la generación completa.

\paragraph{Modo Generate}
El modo \verb|generate| crea mundos completamente aleatorios sin input del usuario. Implementado mediante \verb|create_world_incrementally_generate()|, este modo llama al pipeline con un prompt genérico que solicita al LLM inventar un tema original. Observamos durante el desarrollo que este modo produce mundos variados e inesperados, aunque el ``set de herramientas'' del LLM es ajustado, porque notamos repetición de conceptos, personajes o lugares. Probablemente esto esté relacionado al caching del propio modelo.

Este modo es particularmente útil para testing del sistema: podemos generar decenas de mundos rápidamente para evaluar robustez del pipeline, detectar configuraciones problemáticas y validar que las validaciones de conectividad y completabilidad funcionan correctamente. El botón único ``Generate Random World'' minimiza la fricción, ideal para iteración rápida durante desarrollo.

\paragraph{Modo Preset}
El modo \verb|preset| carga mundos preconstruidos manualmente desde \verb|example_worlds.py|. Implementamos una interfaz de selección con botones para cada mundo disponible, mostrando título y descripción breve. Los mundos preset son fundamentales durante desarrollo: como están completamente controlados, permiten testear funcionalidad del motor de juego (resolución de puzzles, desbloqueo de pasajes, verificación de objetivos) sin la variabilidad introducida por generación con LLM. 

% Santi: este "fallback" no me suena, es cierto?
Mantenemos mundos preset en ambos idiomas (español e inglés) mediante diccionarios paralelos, asegurando que la experiencia de testing sea consistente independientemente del idioma seleccionado. Los preset también sirven como fallback: si la generación con LLM falla después de agotar reintentos, el sistema carga automáticamente un mundo preset en lugar de crashear, garantizando que el usuario siempre pueda jugar.

\paragraph{Modos adicionales}
Implementamos dos modos auxiliares: \verb|tutorial| carga un mundo diseñado específicamente para enseñar mecánicas (mundo pequeño con ejemplos de cada tipo de interacción), y \verb|replay| permite cargar partidas guardadas desde MongoDB mediante \verb|world_id|. El modo replay rehidrata el mundo completo usando \verb|jsonpickle.decode()|, permitiéndole al jugador volver a jugar el mundo si quiere tomar otras decisiones. Además, este modo permite ver la partida jugada (el histórico del chat), también útil para la etapa de evaluación, o los detalles del mismo: el objetivo, las ubicaciones que había, un diagrama visual del mundo, etc.


\subsection{UI en Gradio/Streamlit}

Migramos la interfaz de Gradio a Streamlit durante el desarrollo, priorizando mejor integración con el ciclo de desarrollo Python y mayor control sobre layout y componentes personalizados.

\paragraph{Arquitectura de sesión con Streamlit}
Streamlit usa un modelo de ejecución stateless donde cada interacción re-ejecuta el script completo. Manejamos estado persistente mediante \verb|st.session_state|, un diccionario que sobrevive entre ejecuciones. Almacenamos allí el objeto \verb|World|, el \verb|game_loop|, el historial de chat, ubicaciones visitadas, configuración de idioma y modo de generación. Esta arquitectura requiere cuidado: toda modificación de estado debe hacerse vía \verb|session_state| o se perderá en la siguiente interacción.

Implementamos inicialización condicional al inicio del script: verificamos existencia de cada clave en \verb|session_state| antes de crear valores default. Por ejemplo, \verb|if 'world' not in st.session_state: st.session_state.world = None|. Esta inicialización lazy previene resetear estado cuando el usuario interactúa con otros widgets.

\paragraph{Interfaz de chat conversacional}
El núcleo de la UI es una interfaz de chat implementada con \verb|st.chat_message()| y \verb|st.chat_input()|. Mantenemos \verb|chat_history| como lista de diccionarios con estructura \verb|\{``role'': ``user''|``assistant'', ``content'': texto\}|. Cada turno agrega dos entradas: una para el input del usuario y otra para la narración generada.

Renderizamos el historial completo en cada ejecución iterando sobre \verb|chat_history|: esto permite scroll infinito natural donde el usuario puede revisar toda la conversación previa. La entrada de chat se posiciona fija en la parte inferior mediante configuración CSS, y automáticamente hace scroll al último mensaje cuando se envía input nuevo.

\paragraph{Quick Actions como UI heurística}
Implementamos botones de Quick Actions que simulan comandos textuales comunes: ``Objetivo'' envía ``objetivo'' al game loop, ``Ayuda'' envía ``ayuda''. Estos botones reducen fricción para acciones frecuentes.

En modo debug activamos Quick Actions adicionales: ``Inspeccionar'' envía ``inspeccionar mundo'' mostrando estadísticas del grafo de ubicaciones y puzzles, ``Resumen'' muestra todas las ubicaciones con sus conexiones e inventarios. Estas acciones de debugging son esenciales durante desarrollo para validar estado interno sin recurrir a prints en consola.

\paragraph{Visualización del grafo con Mermaid.js}
Generamos visualizaciones del mundo como diagramas de grafo usando sintaxis Mermaid. El módulo \verb|world_visualizer.py| exporta el mundo a formato Mermaid, y la función \verb|render_mermaid()| en la UI lo renderiza mediante una página HTML embebida con Mermaid.js desde CDN. Implementamos controles de zoom (botones + / - / reset) y pan (arrastrar con mouse) en JavaScript dentro del iframe, permitiendo navegar mundos grandes con muchas ubicaciones.

\paragraph{Sidebar de configuración}
Implementamos un sidebar persistente con \verb|st.sidebar| que contiene controles de configuración global: selector de idioma (español/inglés), selector de modo de generación (Inspiration/Generate/Preset/Tutorial/Replay), campo de nickname del jugador y toggle de modo debug. Bloqueamos estos controles durante juego activo (\verb|disabled=game_active|) para prevenir cambios de configuración que corrompan el estado del mundo a mitad de partida.

El nickname se almacena en \verb|session_state| y se puede usar para personalización futura, aunque en un principio sólo nos sirvió para identificar a los evaluadores. El toggle de modo debug habilita Quick Actions adicionales y muestra información técnica extra en la UI, útil para desarrollo aunque podría ser confuso para usuarios finales.

% Trabajo a futuro: mejor manejo de idiomas
\subsection{Experiencia de usuario multilingüe}
Soportar múltiples idiomas no es solo traducir strings, sino garantizar coherencia narrativa completa en cada idioma sin mixing de lenguajes.

\paragraph{Arquitectura de internacionalización}
Centralizamos todos los textos de UI en \verb|ui_components.py| mediante funciones \verb|get_ui_texts(language)| y \verb|get_progress_messages(language)| que retornan diccionarios de strings. Cada string tiene una clave invariante (ej. \verb|'GENERATE_WORLD'|) y valores específicos por idioma. La UI consulta estos diccionarios en cada render, seleccionando el idioma desde \verb|st.session_state.language|.

Este patrón centralizado es útil y simple, pero dificulta agregar nuevos idiomas, pues requiere extender los diccionarios con nuevas entradas y manejar la lógica de condicionales, lo que no es práctico. También permite detectar strings faltantes: si una clave no existe en un idioma, Python lanza \verb|KeyError| inmediatamente en lugar de fallar silenciosamente con texto en idioma incorrecto.

\paragraph{Propagación de idioma al pipeline}
El parámetro \verb|language| se propaga a través de toda la cadena de generación: desde la UI hasta los prompts del LLM. Cada función del pipeline (\verb|run_step_1_concept()|, \verb|run_step_2_skeleton()|, etc.) recibe \verb|language| como parámetro y selecciona el prompt apropiado. Los prompts en \verb|prompts.py| tienen versiones paralelas (funciones con sufijos \verb|_spanish| y \verb|_english|), y funciones dispatcher que seleccionan la versión correcta.

Esta propagación garantiza que todo el contenido generado (nombres de ubicaciones, descripciones de objetos, diálogos de personajes) esté en el idioma seleccionado. Incluimos instrucciones explícitas en los prompts, como se mencionó anteriormente.

\paragraph{Consistencia en memoria y narración}
El sistema RAG mantiene consistencia de idioma almacenando el parámetro \verb|language| en metadatos de trazas MongoDB. Al cargar memorias con \verb|load_memories_from_db()|, usamos el idioma original de la traza para regenerar resúmenes de estado del mundo, garantizando que las memorias recuperadas estén en el mismo idioma que el juego actual.

Los prompts de narración y actualización de mundo también reciben \verb|language|, asegurando que las respuestas del LLM durante gameplay mantengan el idioma consistentemente. Observamos durante testing que sin esta propagación explícita, los LLMs ocasionalmente cambian de idioma a mitad de narración (ej. nombres propios en inglés dentro de narración española), rompiendo la inmersión.

% Santi: a que te referis aca?
Un desafío observado fue mantener sincronización entre versiones: si agregamos un objeto a la versión española, debemos recordar agregarlo a la inglesa. Implementamos validaciones básicas que verifican estructura paralela (mismo número de ubicaciones, objetos, personajes) entre versiones, aunque no pueden verificar equivalencia semántica de contenidos.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Experimentación} \label{cap:experimentacion}

La evaluación de esta tesis se diseñó para medir tanto la calidad técnica de la generación de mundos como la experiencia del usuario durante el gameplay. Dados los múltiples componentes del sistema (generación incremental, validaciones automáticas, arquitectura goal-oriented, sistema de hints, e intervenciones determinísticas) resultaba crítico evaluar no solo si los mundos eran estructuralmente válidos, sino también si resultaban jugables, coherentes y entretenidos en la práctica.

\section{Diseño Experimental}

\subsection{Objetivos de la Evaluación}

La evaluación se estructuró en torno a tres ejes o dimensiones principales:

\begin{enumerate}
    \item \textbf{Generación y representación del mundo}: Evaluar si el pipeline de generación incremental produce mundos estructuralmente válidos, temáticamente coherentes, y que cumplan con los parámetros de configuración especificados. Esto incluye verificar que todos los elementos del mundo (ubicaciones, NPCs, ítems, puzzles) existan donde deben existir, estén correctamente conectados, y respeten las restricciones del objetivo goal-oriented.
    
    \item \textbf{Conexión LLM-Jugador}: Evaluar la efectividad de la comunicación bidireccional entre el LLM y el jugador. Es decir, por un lado, qué tan bien el LLM transmite el estado del mundo y las consecuencias de las acciones del jugador mediante narrativa, y por otro, qué tan bien el LLM interpreta las intenciones del jugador expresadas en lenguaje natural, incluyendo la capacidad de manejar variaciones lingüísticas, ambigüedad, y expresiones coloquiales.
    
    \item \textbf{Experiencia del usuario}: Evaluar aspectos cualitativos del gameplay: si el juego es entretenido y mantiene el interés del jugador, si los puzzles tienen sentido lógico y dificultad apropiada, si el sistema de hints es útil, y si el jugador logra completar el objetivo o se frustra en el proceso.
\end{enumerate}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figs/eval-dimensiones.png}
    \caption{Dimensiones relevantes a considerar en la evaluación}
    \label{fig:eval_dimensiones}
\end{figure}

\subsection{Configuración del Entorno de Pruebas}

Las pruebas se desplegaron en Hugging Face Spaces, proporcionando una interfaz web accesible sin requerir instalación local. Esta decisión facilitó la participación de evaluadores no técnicos y permitió un entorno controlado y consistente para todos los participantes.

\paragraph{Modelos de lenguaje}
Evaluamos dos proveedores de LLMs:
\begin{itemize}
    \item \textbf{Google Gemini}: Accedido mediante API gratuita. Debido a las limitaciones de uso de la versión gratuita, fue necesario crear múltiples cuentas de Google con sus respectivas API keys para distribuir la carga y evitar alcanzar los límites de tasa durante las pruebas. A pesar de estas precauciones, ocurrió una sobrecarga irrecuperable durante una de las evaluaciones (discutido en Sección~\ref{sec:sobrecarga}).
    
    \item \textbf{OpenAI (GPT-4o-mini)}: Accedido mediante API de pago. La elección del modelo mini sobre el completo se debió a consideraciones de costo, dado que cada partida requiere múltiples invocaciones al LLM (generación del mundo, narración de cada turno, interpretación de acciones). Pruebas preliminares demostraron que la versión mini era suficiente para generar mundos coherentes y narrativa de calidad, justificando la elección del modelo más económico.
\end{itemize}

Ambos son modelos privados. En este caso, no nos pareció relevante probar con una alternativa abierta. Si bien sería interesante probar y evaluar el rendimiento, decidimos no hacerlo. Primero, porque no formaba parte de los objetivos principales, y por otro lado, porque no contamos con el hardware necesario para correr los que son realmente capaces de llevar a cabo las tareas de generación del mundo; en particular lo relacionado a la salida estructurada. Los modelos abiertos que son potentes, como Deepseek, requieren unas capacidades de computación demasiado exigentes. Fue principalmente por eso que los descartamos para las pruebas.

\paragraph{Configuración del mundo}
Para garantizar comparabilidad entre todas las pruebas, fijamos los parámetros de tamaño del mundo:
\begin{itemize}
    \item \textbf{Ubicaciones}: 4
    \item \textbf{Objetos}: 4
    \item \textbf{NPCs}: 2
    \item \textbf{Puzzles}: 1
\end{itemize}

Esta configuración representa mundos pequeños pero completos. La elección de estos parámetros equilibra dos necesidades: por un lado, son suficientemente complejos para evaluar todas las mecánicas del sistema (generación incremental, validaciones, puzzles, objetivo goal-oriented); por otro lado, dado que el énfasis del juego está en la exploración y el disfrute de la narrativa, mundos demasiado pequeños habrían resultado en partidas excesivamente breves que podrían no capturar adecuadamente la experiencia de juego ni permitir evaluar el mantenimiento del interés del jugador a lo largo del tiempo.


\paragraph{Configuración del entorno y protocolo secuencial}
La configuración de cada sesión de prueba presentó desafíos logísticos importantes. Mientras que el idioma se selecciona mediante la interfaz de usuario, los otros dos parámetros críticos, es decir, el modelo de lenguaje (Gemini o OpenAI) y la habilitación del sistema RAG, deben configurarse en el archivo \verb|config.ini| del deployment de Hugging Face. Esto requirió modificar manualmente la configuración aproximadamente 15 minutos antes de cada sesión de prueba programada.

Esta restricción técnica, combinada con las limitaciones de tasa de las APIs, nos llevó a establecer un protocolo estricto: no asignar dos evaluadores simultáneamente. Este enfoque secuencial tuvo un beneficio adicional no anticipado: nos permitió monitorear los logs de Hugging Face en tiempo real durante cada partida, tomando notas preliminares sobre el comportamiento del sistema, errores emergentes, y patrones de interacción del jugador que luego informaron el análisis detallado.

\subsection{Participantes y Metodología}

Reclutamos 8 evaluadores con diversos niveles de experiencia en videojuegos de aventura textual. La muestra se distribuyó equitativamente según dos variables experimentales:

\begin{itemize}
    \item \textbf{Idioma}: 4 evaluadores en español, 4 en inglés
    \item \textbf{Sistema RAG}: 4 evaluadores con memoria habilitada, 4 sin memoria
    \item \textbf{Modelo LLM}: Dentro de cada grupo de idioma/RAG, la mitad usó Gemini y la mitad OpenAI
\end{itemize}

Esta distribución factorial nos permitió evaluar el impacto de tres factores: idioma de generación, presencia de memoria contextual, y elección del modelo de lenguaje.

Cada evaluador completó tres sesiones de juego en secuencia:
\begin{enumerate}
    \item \textbf{Tutorial}: Mundo pre-diseñado simple para familiarizarse con la interfaz, comandos básicos (moverse, tomar objetos, hablar con NPCs), y mecánicas del juego (hints, objetivos, puzzles). Esta sesión no se evaluó formalmente.
    
    \item \textbf{Generate Mode}: El sistema genera un mundo completamente original sin restricciones temáticas. El LLM tiene libertad creativa total para inventar la historia, ambientación, personajes y objetivo.
    
    \item \textbf{Inspiration Mode}: El sistema genera un mundo basado un texto. Se instruyó a los evaluadores escribir exactamente: `Un mundo basado en la película [X]' (o `A world based on the movie [X]' en inglés), donde [X] debía ser su película favorita registrada en IMDB. Esta restricción tuvo dos propósitos: primero, asegurar que el tema fuera reconocible por los LLMs (evitando referencias oscuras o muy personales); segundo, y más importante, establecer un marco común de comparación entre evaluadores. Si hubiéramos permitido libertad absoluta en el tipo de inspiración, algunos evaluadores podrían haber elegido conceptos inherentemente más interesantes o ricos narrativamente (e.g., `un mundo de piratas espaciales') mientras que otros podrían haber optado por temas más básicos o limitados (e.g., `una librería', `un cuento clásico'). Al restringir la inspiración a películas—obras con narrativas completas, personajes establecidos, y mundos desarrollados—garantizamos cierta equidad en la complejidad temática de partida, permitiendo evaluar más directamente la capacidad del sistema para traducir esa inspiración en un mundo jugable, independientemente de la riqueza intrínseca del material fuente.
\end{enumerate}

A los evaluadores se les proporcionó un manual de pruebas detallado que especificaba el flujo exacto a seguir, incluyendo la verificación del idioma correcto, desactivación del modo debug, ingreso de nickname identificatorio, y el orden de los modos de juego. Se les instruyó jugar cada partida hasta completar el objetivo o hasta quedar irremediablemente atascados, y luego completar un formulario de evaluación para cada modo (Generate e Inspiration).

\paragraph{Consideraciones éticas}
Se solicitó a los evaluadores que, tras completar ambas partidas evaluadas, no continuaran jugando hasta finalizar el período de pruebas, para evitar contaminación de datos. Se les ofreció la posibilidad de jugar libremente una vez concluido el estudio. Asimismo, se les indicó reportar cualquier error técnico mediante capturas de pantalla.

\subsection{Métricas de Evaluación}

El formulario de evaluación post-partida (incluido como Anexo X) capturó tanto métricas cuantitativas mediante escalas Likert de 5 puntos como datos cualitativos mediante preguntas abiertas. Las preguntas se organizaron en cinco categorías alineadas con los objetivos de evaluación: (A) Puzzles, (B) Objetivo del mundo, (C) Coherencia del mundo, (D) Experiencia general, y (E) Comentarios cualitativos. El formulario de Inspiration Mode incluyó preguntas adicionales sobre la fidelidad temática a la inspiración proporcionada.

Las opciones de respuesta para las preguntas cuantitativas fueron: Sí / Mayoritariamente / A veces / Casi nunca / Nunca. Aunque varias preguntas podrían parecer inherentemente binarias (por ejemplo, `Pude cumplir el objetivo del mundo'), la escala de 5 puntos se justifica por la naturaleza matizada de la experiencia de juego. Consideremos dos casos reales que ilustran esta necesidad:

\begin{itemize}
    \item Un evaluador con objetivo tipo \verb|GET_ITEM| obtuvo exitosamente el ítem objetivo, pero el sistema nunca presentó la narración de cierre indicando la completitud del objetivo. Técnicamente el objetivo se completó, pero la experiencia fue incompleta. La respuesta apropiada en este caso no sería `Sí' ni `No'.
    
    \item Otro evaluador experimentó una discrepancia entre completitud técnica y percepción del jugador en un mundo con objetivo \verb|SOLVE_MYSTERY|. El sistema presentó correctamente la narración de completitud en el turno 10, sin embargo, la descripción del objetivo sugería tareas adicionales más complejas. Esto llevó al evaluador a continuar jugando por más de una hora intentando resolver contenido que no existía (caso analizado en detalle en Sección~\ref{sec:mystery-one-clue}).
\end{itemize}

Estos ejemplos demuestran que completar un objetivo técnicamente no es lo mismo que la percepción del usuario sobre si verdaderamente lo cumplió. La escala de 5 puntos nos permite capturar estas diferencias entre lo que el sistema registra como `objetivo cumplido' y lo que el jugador realmente experimentó, dándonos información más rica para entender qué funcionó y qué no desde la perspectiva del usuario. Además, solicitamos explícitamente a los evaluadores que explicaran estas discrepancias y situaciones ambiguas en las preguntas de texto abierto, permitiéndonos contextualizar las respuestas cuantitativas con las experiencias narrativas específicas de cada partida.

\section{Resultados}

\subsection{Resumen General de las Evaluaciones}

La Tabla~\ref{tab:evaluadores} presenta un resumen de los 8 evaluadores, su configuración experimental, y el resultado de completitud del objetivo de cada modo de juego.

\begin{table}[h]
\centering
\caption{Resumen de evaluadores y resultados}
\label{tab:evaluadores}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Tester} & \textbf{Modelo} & \textbf{RAG} & \textbf{Idioma} & \textbf{Generate} & \textbf{Inspiration} \\
\hline
Tester 1 & OpenAI & Sí & ES & \checkmark & \checkmark \\
Tester 2 & OpenAI & Sí & EN & \checkmark & $\times$ \\
Tester 3 & Gemini & Sí & ES & \checkmark & \checkmark \\
Tester 4 & OpenAI & No & ES & \checkmark & \checkmark \\
Tester 5 & Gemini & No & ES & \checkmark & $\times$* \\
Tester 6 & OpenAI & No & EN & \checkmark & $\times$ \\
Tester 7 & Gemini & Sí & EN & \checkmark & \checkmark \\
Tester 8 & Gemini & No & EN & \checkmark & $\times$ \\
\hline
\end{tabular}
\begin{tablenotes}
\item[*] * Partida interrumpida por sobrecarga del modelo (ver Sección~\ref{sec:sobrecarga})
\end{tablenotes}
\end{table}

La tasa de completitud fue notablemente diferente entre modos:
\begin{itemize}
    \item \textbf{Generate Mode}: 8/8 mundos completados (100\%)
    \item \textbf{Inspiration Mode}: 4/8 mundos completados (50\%)
\end{itemize}

Esta diferencia significativa merece análisis detallado, las 4 fallas en Inspiration Mode:
\begin{itemize}
    \item \textbf{2 casos} fueron objetivos técnicamente imposibles que pasaron las validaciones (Testers 2 y 6)
    \item \textbf{1 caso} fue una sobrecarga irrecuperable del modelo Gemini (gratuito) durante gameplay (Tester 5)
    \item \textbf{1 caso} fue un objetivo técnicamente completable pero con NPCs que no cooperaban (Tester 8)
\end{itemize}

Es importante notar que aunque técnicamente 8/8 jugadores completaron Generate Mode, uno de ellos (Tester 8) reportó no haberse dado cuenta de que había cumplido el objetivo, un problema que analizaremos en detalle más adelante.

\subsection{Generación y Coherencia de Mundos}

\subsubsection{Cumplimiento de Parámetros de Configuración}

El sistema demostró un cumplimiento mixto de los parámetros de tamaño solicitados (4 ubicaciones, 4 objetos, 2 NPCs, 1 puzzle). De los 16 mundos generados:

\begin{itemize}
    \item \textbf{13 mundos (81.25\%)} respetaron exactamente los parámetros configurados
    \item \textbf{3 mundos (18.75\%)} excedieron los límites:
    \begin{itemize}
        \item Tester 2 Generate (OpenAI, RAG, EN): 5 ubicaciones, 6 objetos, 3 NPCs, 2 puzzles
        \item Tester 7 Inspiration (Gemini, RAG, EN): 5 NPCs, 7 objetos
        \item Tester 8 Generate (Gemini, sin RAG, EN): 6 objetos, 3 puzzles
    \end{itemize}
\end{itemize}

Los tres casos donde se vieron excedidos los parámetros, todos ocurrieron en evaluaciones en inglés, aunque con diferentes modelos (dos con Gemini, uno con OpenAI, RAG no afecta en el generado del mundo). Dado el tamaño limitado de la muestra (8 evaluadores), no es posible determinar si el idioma inglés es realmente un factor causante o si se trata de una coincidencia. Potencialmente, los LLMs podrían generar contenido más elaborado en inglés debido a su mayor presencia en los datos de entrenamiento, pero esta hipótesis requeriría evaluaciones adicionales con una muestra significativamente mayor para ser validada.

Las validaciones de Pydantic en el Paso 2 del pipeline verifican tipos de datos pero no imponen límites estrictos de cantidad, permitiendo que el LLM ocasionalmente genere mundos más complejos de lo solicitado. Adicionalmente, el sistema de corrección automática de puzzles descrito en el Capítulo 3 XX puede contribuir a este exceso: cuando un puzzle referencia una recompensa inexistente, el sistema crea automáticamente ese ítem faltante, incrementando el conteo total de objetos más allá del límite configurado. Esto no comprometió la jugabilidad de estos mundos, pero sí introduce variabilidad en la complejidad entre evaluadores.

\subsubsection{Validación de Objetivos y Casos de Imposibilidad}

Como se describió también en el Capítulo 3, el sistema incluye una validación crítica \verb|verify_objective_completability()| que verifica que todos los componentes referenciados en el \textbf{objetivo} existan y sean accesibles. Sin embargo, a diferencia de los puzzles donde el sistema corrige automáticamente recompensas faltantes, los objetivos con componentes inaccesibles causan el rechazo del mundo completo y fuerzan un reintento. A pesar de esta validación más estricta, detectamos dos casos donde objetivos imposibles pasaron las validaciones y fueron presentados a los jugadores:

\paragraph{Caso 1: Rescue Net sin ubicación (Tester 2, Inspiration - Finding Nemo)}
El mundo generó correctamente un objetivo tipo \verb|DELIVER_AN_ITEM| que requería entregar un ítem llamado ``Rescue Net'' a un NPC. El ítem existía en \verb|world.items|, satisfaciendo la primera condición de la validación. Sin embargo, el LLM nunca asignó este ítem ni a una ubicación (\verb|location=None|) ni al inventario de ningún NPC (\verb|inventory=[]|). Esto representa una falla lógica en el proceso de generación: el LLM creó el objeto conceptualmente pero olvidó ubicarlo físicamente en el mundo.

La validación \verb|verify_objective_completability()| verifica la existencia del ítem en el registro global pero no valida que tenga una ubicación accesible. Este caso expone una brecha en la lógica de validación: no basta con que un ítem exista como objeto Python, debe estar presente en el espacio jugable. 

En este caso particular, el pipeline de generación falló dos veces antes de producir exitosamente un mundo. Sin embargo, el mundo finalmente generado aún contenía el error: el ítem objetivo ``Rescue Net'' carecía de ubicación asignada, resultando en un objetivo técnicamente imposible de completar.

\paragraph{Caso 2: The Button Cutter inaccesible (Tester 6, Inspiration - Coraline)}
Similar al caso anterior, el objetivo \verb|GET_ITEM| requería obtener un ítem llamado ``The Button Cutter''. El ítem existía en \verb|world.items| pero no tenía ubicación ni estaba en inventario de NPCs. 

Estos dos casos revelan un problema fundamental en el manejo de objetivos inválidos: a diferencia de los puzzles, donde el sistema corrige automáticamente recompensas faltantes, los objetivos con componentes inaccesibles simplemente causan el rechazo del mundo completo y fuerzan la regeneración desde cero. Sin embargo, observamos que en ocasiones el sistema acepta mundos con objetivos imposibles, sugiriendo que la validación \verb|verify_objective_completability()| no detecta todos los casos problemáticos. 

Una mejora evidente sería implementar una corrección automática similar a la que existe para puzzles: si un ítem referenciado en el objetivo no tiene ubicación asignada, el sistema podría colocarlo automáticamente en una ubicación aleatoria válida, en lugar de rechazar el mundo completo o, peor aún, aceptar un mundo con un objetivo imposible de completar.

\subsubsection{Conectividad y Coherencia Espacial}

Las validaciones de conectividad implementadas en el Paso 3 (DFS para verificar alcanzabilidad desde ubicación inicial) funcionaron correctamente en todos los casos. No se registraron instancias donde el jugador quedara atrapado en una región del mundo sin poder alcanzar ubicaciones necesarias para el objetivo. Las validaciones de bidireccionalidad de pasajes también operaron sin problemas, y no se reportaron casos de pasajes unidireccionales no intencionales.

Un aspecto positivo consistente en el feedback cualitativo fue la coherencia espacial de los mundos. Múltiples evaluadores comentaron que las transiciones entre ubicaciones tenían sentido lógico y que las descripciones reforzaban la geografía del mundo (Tester 6: ``\textit{la transición entre lugares era correcta y la narración describió muy bien los alrededores}'').

\subsection{Interacción LLM-Jugador} \label{sec:interaccion_llm_jugador}

\subsubsection{Efectividad del Sistema de Puzzles y Pistas}

% XX: Esta puede quedar por ahora
La experiencia con puzzles fue marcadamente variable según el evaluador y el mundo específico. Analizando las respuestas del formulario (ver Anexo XX para datos completos), aproximadamente 75\% de los evaluadores encontraron los puzzles lógicos y las pistas útiles en Generate Mode. Sin embargo, el 25\% restante reportó experiencias significativamente negativas, particularmente en cuanto a dificultad percibida.

Dos casos demuestran los extremos de esta experiencia:

\textbf{Caso de puzzle excesivamente críptico (Tester 5, Generate):}
El puzzle presentaba el siguiente acertijo:
\begin{quote}
    \textit{``Soy la unión de dos opuestos, el fuego que no quema y el agua que no moja. Contengo la clave para despertar el amanecer. ¿Qué soy?''}
    
    Respuesta esperada: \textbf{catalizador}
\end{quote}

Las tres pistas progresivas fueron:
\begin{enumerate}
    \item ``Piensa en los elementos que son esenciales para la alquimia, pero que pueden ser paradójicos.''
    \item ``Considera qué elemento es necesario para activar o acelerar una reacción alquímica.''
    \item ``La respuesta está relacionada con un componente esencial para el Elixir del Amanecer.''
\end{enumerate}

El evaluador reportó: ``\textit{El puzzle o era demasiado difícil o directamente no tenía solución}''. Este caso ejemplifica un problema recurrente: el LLM ocasionalmente genera puzzles que requieren conocimiento especializado (en este caso, alquimia) o conexiones conceptuales muy abstractas que no son evidentes incluso con las tres pistas. La respuesta ``catalizador'' no es incorrecta desde un punto de vista químico-alquímico, pero es extremadamente difícil de deducir sin conocimiento previo del dominio.

\textbf{Caso de pistas insuficientes e inconsistentes (Tester 6, Generate):}
El puzzle ``Echoes Puzzle'' requería identificar una secuencia de ecos: ``\textit{Whisper, Roar, Silence}''. Las pistas fueron:
\begin{enumerate}
    \item ``Escucha con atención el patrón de sonidos.''
    \item ``La secuencia incluye tres ecos distintos.''
    \item ``El orden correcto está relacionado con la intensidad de cada eco.''
\end{enumerate}

El evaluador comentó que las pistas no le ayudaron y que sintió frustración al no poder resolver el puzzle. Este caso es particularmente problemático por múltiples razones: primero, el puzzle se basa en información que supuestamente debería estar presente en el entorno (los ``ecos'' que se pueden ``escuchar''), pero esa información nunca fue adecuadamente presentada al jugador durante la narrativa. Las pistas asumen que el jugador ha percibido estos ecos específicos, pero el LLM no los mencionó explícitamente en las descripciones de la ubicación. Segundo, la pista 3 es internamente inconsistente: si la secuencia correcta fuera por intensidad creciente, debería ser ``Silence, Whisper, Roar'', no la respuesta esperada. Esto sugiere que el LLM generó pistas que no corresponden con la lógica de la solución que él mismo estableció.

\subsubsection{Jailbreaking de Puzzles: Bypass No Intencional}

Detectamos múltiples instancias donde el LLM permitió al jugador avanzar sin resolver puzzles correctamente, contradiciendo la lógica determinística del sistema. Este comportamiento, que denominamos ``jailbreaking'', ocurrió en al menos 3 de los 16 mundos evaluados:

\paragraph{Jailbreaking por ``resolución automática'' (Testers 1 y 4, Inspiration):}
En estos casos, cuando el jugador simplemente declaraba ``resuelvo el puzzle'' sin proporcionar explícitamente la respuesta correcta, el LLM interpretaba esta intención como suficiente y en su respuesta narrativa ``analizaba el acertijo y llegaba a la conclusión'' por el jugador. Por ejemplo, si el puzzle preguntaba ``¿Qué tiene cuatro patas por la mañana...?'', el jugador escribía ``resuelvo el acertijo'' y después de algunos intentos, el LLM respondía algo como: ``\textit{Tras analizar cuidadosamente el acertijo, te das cuenta de que la respuesta es 'el ser humano'. Has resuelto el enigma.}'' Este comportamiento derrota completamente el propósito del puzzle como desafío para el jugador, ya que permite bypassear el mecanismo de validación de respuestas sin realmente resolver el acertijo.

\paragraph{Jailbreaking por entrega anticipada de recompensas (Tester 6, Generate):}
El jugador intentó resolver el ``Echoes Puzzle'' pero dio una respuesta incorrecta. El sistema correctamente marcó \verb|success: false| en el \verb|WorldUpdate|, sin embargo, el LLM simultáneamente incluyó en \verb|blocked_passages_available| el valor \verb|is_available: true| para el pasaje bloqueado. El código del motor confía ciegamente en este flag sin validar por qué ese pasaje debería desbloquearse, simplemente obedece el flag \verb|is_available|. Esto permitió al jugador avanzar a pesar de fallar el puzzle. Además, el NPC entregó la recompensa del puzzle (un ítem necesario para el objetivo) sin que el puzzle se resolviera. El jugador reportó: ``\textit{el juego me dejó seguir adelante luego de los puzzles a pesar de decirme en el prompt que mis respuestas eran incorrectas}''.

Este bug específico revela una debilidad arquitectónica: el sistema híbrido delega demasiada confianza en las decisiones estructuradas del LLM sin validar su coherencia interna. Una solución sería que el motor verifique explícitamente: si \verb|success: false| en cualquier puzzle del turno actual, entonces \textit{ningún} pasaje bloqueado por ese puzzle debería marcarse como disponible, independientemente de lo que diga el LLM.

\subsubsection{Efectividad del Sistema RAG}

Los 4 evaluadores con RAG habilitado (Testers 1, 2, 3, 7) experimentaron continuidad contextual notablemente mejor que aquellos sin RAG. El caso más ilustrativo ocurrió con Tester 7 (Gemini + RAG, EN):

En su partida de Inspiration (Avatar: The Last Airbender), el jugador robó un ítem en el turno 17. Veintisiete turnos más tarde (turno 44), al interactuar con un NPC en una ubicación diferente, el LLM recordó explícitamente este evento anterior: el NPC preguntó ``\textit{Have you come to try and claim what is not yours again?}'', haciendo referencia directa al robo previo.

Este comportamiento contrasta marcadamente con los evaluadores sin RAG, quienes reportaron que los NPCs ocasionalmente ``olvidaban'' interacciones previas o repetían diálogos idénticos. Sin embargo, RAG no solucionó todos los problemas de coherencia: el mismo Tester 7 reportó que el sistema ocasionalmente mezclaba contextos de diferentes puzzles, presentando acertijos de interacciones anteriores en lugar del actual.

\subsubsection{Problemas de Duplicación de Ítems}

Dos evaluadores (Testers 4 y 8) reportaron poder duplicar ítems indefinidamente. El caso más ilustrativo ocurrió con Tester 4 (OpenAI, sin RAG, ES), cuyo objetivo era obtener una ``Llave de Cristal''. El evaluador comentó: ``\textit{Me pasó que obtuve lo que requería el objetivo y el chat asentaba que lo tenía en mis manos pero no me dio por hecho el objetivo.}''

El análisis post-evaluación reveló que el bug ocurre en el sistema de manejo de ítems cuando el LLM intenta mover un ítem que ya está en el inventario del jugador. La secuencia problemática es:

\begin{enumerate}
    \item El LLM genera \texttt{``object\_name'': ``llave de cristal'', ``new\_location'': ``inventory''}
    \item El sistema encuentra correctamente el objeto ``Llave de Cristal''
    \item Detecta que \verb|new_location| es ``inventory'' (válido)
    \item Busca el ítem en la ubicación actual para removerlo, pero la comparación de identidad de objetos falla
    \item Al no encontrar el ítem para remover, el sistema interpreta la acción como ``drop item'' (porque entra a la última cláusula de una cascada de ``if's'', cuya semántica es ``el usuario quiso dropear el item'')
    \item Agrega el ítem en la ubicación actual sin remover el original del inventario, dejándolo duplicado
\end{enumerate}

Este comportamiento permite al jugador duplicar ítems indefinidamente repitiendo la misma acción. Aunque el bug no impidió técnicamente completar objetivos (el jugador \textit{tenía} el ítem objetivo), sí causó confusión porque el sistema de verificación de completitud del objetivo no reconocía las copias duplicadas como el ítem legítimo, llevando a situaciones donde el jugador había cumplido el objetivo pero el juego no lo registraba. Adicionalmente, rompe la economía de recursos del mundo y puede llevar a situaciones absurdas (Tester 8 reportó haber creado 6 copias de unos lentes).

% Santi: ta bien?
% Santi ans: si, pero todavia no lo arreglé xd
Este bug ha sido corregido en el repositorio de GitHub que acompaña este informe, implementando una validación adicional que previene la creación de copias cuando el ítem ya existe en el inventario del jugador.


\subsection{Experiencia del Usuario y Observaciones Generales}

\subsubsection{Creatividad y Originalidad de los Mundos}

La creatividad de los mundos generados recibió feedback mayormente positivo. En las preguntas abiertas sobre originalidad:

\textbf{Generate Mode - Comentarios representativos:}
\begin{itemize}
    \item Tester 1: ``\textit{Me encantó el concepto de dónde estaba ubicado y cuál era el objetivo}''
    \item Tester 3: ``\textit{Estuvo bien la creación del mundo algo mecánico, era interesante y las cosas cuadraban}''
    \item Tester 6: ``\textit{El mundo era coherente... la narración describió muy bien los alrededores, haciéndote sentir más inmerso}''
    \item Tester 8: ``\textit{Me gustó muchísimo la propuesta. El mundo era claro con sus pautas}''
\end{itemize}

\textbf{Inspiration Mode - Fidelidad temática:}
El sistema de inspiración demostró ser altamente efectivo en generar mundos temáticamente coherentes. Los evaluadores consistentemente reportaron que los mundos capturaban la esencia de las películas elegidas, con todos los elementos (ubicaciones, NPCs, objetos, puzzles) fuertemente relacionados con la temática inspiradora:

\begin{itemize}
    \item Tester 1 (Harry Potter): ``\textit{Me gustó mucho el concepto del bosque generado y el uso de magia}'' - Rating: Sí en todas las preguntas de correlación temática
    \item Tester 3 (El Caballero Oscuro): ``\textit{Si bien el mundo estuvo inspirado en Gotham City, no hizo referencias al protagonista ni al villano principal, pero sí a otros personajes relacionados}''
    \item Tester 5 (Minions): ``\textit{Sí, incluso (yo) era un personaje de la película}''
    \item Tester 6 (Coraline): ``\textit{Buena ambientación, relacionado a eventos de la película. La narrativa me hacía imaginarme el lugar en el que me encontraba.}''
    \item Tester 7 (Avatar: The Last Airbender): ``\textit{Sí estaba inspirado, estuvo bien el resultado, quería ser un maestro fuego, pero me hizo maestro tierra, pero podía hacer metal control, así que era de los buenos.}''
\end{itemize}

Este resultado representa una mejora significativa respecto a iteraciones tempranas del sistema, donde los mundos mostraban solo inspiración superficial. La insistencia iterativa en los prompts de generación—enfatizando repetidamente que \textit{todos} los componentes del mundo deben estar temática y lógicamente conectados con la inspiración—resultó en mundos donde la coherencia temática permea cada elemento generado. La elección de películas como fuente de inspiración también contribuyó al éxito: los LLMs tienen suficiente conocimiento sobre narrativas cinematográficas populares para generar mundos reconocibles, pero el mérito principal radica en el diseño del sistema de prompts que garantiza que esta inspiración no sea solo decorativa sino estructuralmente integral al mundo generado.

\subsubsection{Propósito de Objetos y NPCs: Generate vs Inspiration}

% XX: esta puede quedar por ahora
Una diferencia notable emergió entre los dos modos en cuanto a la percepción de utilidad de los elementos del mundo. Analizando las respuestas del formulario (ver Anexo XX), en Generate Mode solo el 25\% de los evaluadores respondió ``Sí'' a la pregunta ``Los objetos y NPCs tenían un propósito real'', mientras que en Inspiration Mode este porcentaje aumentó a 71.4\%. 

Múltiples evaluadores de Generate Mode reportaron frustración con elementos que parecían decorativos, mencionando puzzles sin impacto en el juego, ítems sin uso aparente, o NPCs que no contribuían al objetivo. En contraste, Inspiration Mode mostró mejor alineación entre elementos del mundo y objetivo central.

Esta diferencia sugiere que cuando el LLM genera desde un \textit{template} narrativo preexistente (una película), tiende a crear elementos más integrados al objetivo central. En Generate Mode, sin restricción temática, el LLM ocasionalmente genera elementos `decorativos' que enriquecen el mundo narrativamente pero no contribuyen mecánicamente al objetivo. Esto no es necesariamente negativo (algunos jugadores apreciaron la libertad de exploración) pero otros lo experimentaron como ruido que dificultaba identificar el `camino crítico' hacia el objetivo.

\subsubsection{Entretenimiento y Mantenimiento del Interés}

A pesar de los problemas técnicos, el sistema logró mantener el interés de los jugadores. En la pregunta `El juego fue entretenido y mantuvo mi interés', Generate Mode recibió respuestas 100\% positivas (6 ``Sí'', 2 ``Mayoritariamente''), mientras que Inspiration Mode obtuvo respuestas mayormente positivas excepto en dos casos que coinciden con los mundos donde el objetivo era técnicamente imposible (Testers 2 y 6), lo cual claramente frustró a los jugadores y afectó negativamente su percepción general de la experiencia.

Un dato particularmente revelador fue el tiempo de juego: aunque los mundos eran deliberadamente pequeños (4 ubicaciones, 4 objetos), múltiples evaluadores jugaron durante períodos significativamente más largos de lo anticipado. Muchos testers se quedaban hablando extensamente con NPCs, recorriendo ubicaciones sin un propósito mecánico claro, o explorando el mundo sin apurarse a resolver el objetivo. Este comportamiento indica que los jugadores encontraron los mundos suficientemente inmersivos como para priorizar la exploración narrativa por sobre la completitud del objetivo formal, disfrutando realizar acciones como hablar con NPCs sobre sus vidas, pegarle a NPCs, o robar ítems que no necesitaban.

\subsubsection{El Caso del Mystery de Una Sola Pista}
\label{sec:mystery-one-clue}

Tester 8 experimentó un problema crítico con objetivos tipo \verb|SOLVE_MYSTERY|. El sistema validó y eliminó múltiples \verb|MysteryClue| asociadas con ítems inexistentes, dejando solo 1 pista accesible. Cuando el jugador descubrió esta única pista en el turno 10, el sistema correctamente presentó la narración de completitud del objetivo. Sin embargo, la descripción del objetivo mencionaba `reparar el Aetherium Engine Core' y `encontrar instrucciones en un taller secreto', lo que hizo que el jugador creyera que había una segunda fase del objetivo que debía cumplir.

El jugador continuó explorando y tratando de resolver este puzzle inexistente durante más de una hora. Este caso revela dos problemas interrelacionados:
% Santi: estos cambios no los vamos a hacer no?
% Santi ans: deuda técnica ja. trabajo a futuro para ale
\begin{enumerate}
    \item \textbf{Validación excesivamente agresiva}: Cuando un \verb|SOLVE_MYSTERY| tiene múltiples pistas asociadas con ítems inexistentes, la validación de pistas elimina las pistas invalidas y puede quedar un mystery trivialmente fácil (1 sola pista = objetivo completado inmediatamente). Una solución sería implementar corrección automática similar a la de puzzles: si una pista referencia un ítem inexistente, el sistema debería crear ese ítem y ubicarlo en el mundo, en lugar de simplemente eliminar la pista. Esto mantendría la complejidad prevista del misterio y evitaría completitudes prematuras.
    
    \item \textbf{Discrepancia entre narración del objetivo y mecánicas}: El \verb|objective.description| generado por el LLM es puramente narrativo y no necesariamente refleja con precisión el tipo y mecánicas del objetivo implementado. En este caso, la descripción sugería un objetivo complejo multi-etapa (\verb|GET_ITEM| + usar ítem para reparar), pero el objetivo real era simplemente \verb|SOLVE_MYSTERY| con 1 pista. Esta desconexión entre lo que el sistema \textit{dice} que debes hacer y lo que \textit{mecánicamente} debes hacer causa confusión significativa.
\end{enumerate}

\subsubsection{Sobrecarga del Modelo y Estabilidad del Sistema}
\label{sec:sobrecarga}
La sobrecarga de modelos ocurrió en dos instancias específicas durante el período de pruebas. La primera fue al inicio de las evaluaciones, causada por sobreuso de la API key en pruebas internas previas. Pudimos resolver esto reprogramando la sesión para más tarde el mismo día, permitiendo que el límite de tasa se restableciera. La segunda ocurrencia fue durante la última partida en modo Inspiration de uno de los evaluadores. Ocurrió cerca del final de la partida cuando el evaluador estaba a punto de completar el objetivo. El modelo comenzó a devolver errores de sobrecarga, y estos errores persistieron durante más de 5 minutos. Debido a restricciones de tiempo del evaluador, no fue posible esperar más para que el límite de tasa se restableciera.

Este incidente subraya una limitación fundamental del uso de APIs con límites de tasa: la experiencia del usuario puede interrumpirse abruptamente por factores completamente fuera del control del sistema. Una mejora futura sería implementar un mecanismo de \textit{guardado de estado}: permitir al jugador guardar la partida actual y reanudarla más tarde, en lugar de perder todo el progreso cuando ocurre un error de API.

% Santi: no se donde meter esto, capaz una seccion de conclusiones preliminares?
% Santi ans: hm, no sé, me parece que ambas. acá como análisis está bien.
\subsubsection{Diferencias entre Español e Inglés}

No detectamos diferencias sistemáticas significativas entre evaluadores de habla española e inglesa en términos de calidad de generación, coherencia narrativa, o tasa de completitud de objetivos. Ambos idiomas produjeron mundos jugables y narrativamente ricos. Gemini y OpenAI demostraron capacidad comparable para generar contenido de calidad en ambos idiomas, sugiriendo que el sistema es agnóstico al idioma de generación siempre y cuando el LLM subyacente tenga entrenamiento adecuado en ese idioma.
% Resultados:
% Generacion si se creo bien el mundo y si hubo alguno imposible, que no siguio la tematica, si cumplio los parametros, en modo generate que tanto varia (si vimos diferencia en español ingles)
%Diferencia de NPCS y Objetos al pedo es que en generate todo es random entonces queda como out of context, mientras que en inspiration tiene algo en  que basarse entonces medio que si hay personajes son de la pelicula y se entiende que son necesarios
%Sam y las pistas que se borraron pq no existian

% Conexion LLM Jugador de ambos lados, tanto como transmite el estado el llm y como el jugador interactua.
% duplicacion de llave
% puzzle humans y man
% entiende slang (twack)
% permite irse por las ramas sin perder ambientacion -> edward no queria irse al bolsillo de la gente, y las viejas no se dejaban chamuyar
% Observaciones de RAG


%Experiencia de Player - Form 
% pruebas de 3 horas porque estaban explorando, la gente jugo mucho y no se canso, muchos pidieron volver a jugar
%Vicki, llm sobrecargado, no completo
% Sam se confundio y siguio jugando, deshabilitar chat 

% Inspiration mundos mas complejos a veces mas dificiles o imposibles generate no pasa pq todo esta mas chill


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%conclusiones
\chapter{Conclusiones y Trabajo Futuro} \label{cap:conclusiones}

En este capítulo se evalúan los resultados alcanzados y
dificultades encontradas, se establece lo que se planteó hacer y lo que se hizo
realmente, cuales fueron los aportes, se muestran posibles extensiones al trabajo, se
realiza una autocrítica de lo que se hizo y lo que faltó (por problemas de tiempo,
recursos, cómo se puede continuar, qué cosas hacer, prioridades, etc.) y se incluye
información sobre la gestión del proyecto, si aplica


%


% Trabajo a Futuro
%en caso de querer agregar idiomas no es tan facil y tal vez un uso de diccionarios seria mejor, ahora se hace con ifs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Parte final
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{ % inicio backmatter

\backmatter % no numerar capítulos 

% referencias bibliográficas

\newpage
\bibliographystyle{apacite}
\bibliography{referencias}

} % fin backmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% anexos

\begin{appendix}

\chapter{Manual de Evaluación}

% Los anexos contienen información adjunta al proyecto pero que no es fundamental
% para entender el trabajo. Por ejemplo, determinado material de los antecedentes o la
% implementación, que en el cuerpo principal del informe se encuentre resumido, aquí
% puede presentarse de forma completa. En caso de proyectos de desarrollo de
% software, se debería incluir un manual de usuario.

% \section{Sección del Anexo}

% Los anexos pueden tener secciones.

\chapter{Formulario de Evaluación}

\end{appendix}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
