\chapter{Diseño y Arquitectura del Sistema} \label{cap:diseno}

Este capítulo presenta el modelo conceptual del sistema de generación automática de mundos interactivos desarrollado como extensión de PAYADOR. El objetivo es explicar \textit{qué} componentes conforman el sistema y \textit{por qué} fueron diseñados de esta manera, sin enfocarnos aún en los detalles de implementación tecnológica que se abordarán en el Capítulo \ref{cap:implementacion}.

El desarrollo abordó un desafío complejo: permitir que modelos de lenguaje generen mundos narrativos coherentes, estructuralmente válidos y jugables, manteniendo o mejorando el desempeño que el sistema PAYADOR ofrece. Para lograr esto, diseñamos una arquitectura que separa claramente las responsabilidades entre el modelo de lenguaje (generación creativa y narrativa) y el sistema simbólico (validación estructural y mecánicas de juego).

La arquitectura resultante integra tres pilares fundamentales que se describirán en las siguientes secciones:

\begin{itemize}
    \item \textbf{Estructura de Clases}: Define los elementos básicos del mundo: ubicaciones, objetos, personajes, puzles y objetivos, y sus relaciones. Esta estructura actúa como el esqueleto sobre el cual se construye todo el contenido generado.
    \item \textbf{Pipeline de Generación Incremental}: Descompone la creación del mundo en cinco etapas secuenciales, cada una con responsabilidades específicas. Este enfoque surgió como solución a problemas críticos observados en aproximaciones de generación directa.
    \item \textbf{Sistema de Validación}: Verifica la coherencia estructural y la jugabilidad en cada etapa del pipeline, verificando que los mundos generados sean completables y libres de inconsistencias críticas.
\end{itemize}

A continuación presentaremos cada uno de estos componentes, que son parte de las contribuciones de este trabajo, indicando en qué sección se describirán en profundidad. Es importante mencionar que muchas de las decisiones de diseño presentadas aquí fueron resultado de etapas de testing interno que realizamos durante el desarrollo, las cuales nos permitieron identificar problemas y refinar la arquitectura iterativamente. Esto difiere de la evaluación con usuarios finales que se presentará en el Capítulo \ref{cap:evaluacion}.

\section{Visión General del Sistema}

El sistema extiende PAYADOR modificándolo de un motor de juegos con mundos predefinidos a una plataforma capaz de generar mundos interactivos de forma automática. Esta modificación requirió replantear fundamentalmente cómo se representan y validan los mundos, manteniendo la compatibilidad con el motor de juego original.

\subsection{Componentes Principales}

El motor de generación basado en LLM constituye el núcleo del sistema y utiliza un pipeline incremental de cinco etapas que descompone la creación del mundo en tareas específicas. Este motor puede generar mundos con responsabilidad creativa total \cite{colton2012computational} o guiados por semillas (\textit{seeds}) proporcionadas por el usuario. Para garantizar que estos mundos sean estructuralmente válidos, desarrollamos un sistema de representación estructurada que define esquemas de datos con taxonomías completas. La taxonomía de objetivos incluye cinco tipos (\textit{REACH\_LOCATION}, \textit{GET\_ITEM}, \textit{DELIVER\_AN\_ITEM}, \textit{FIND\_CHARACTER}, y \textit{SOLVE\_MYSTERY}), mientras que la taxonomía de puzles comprende siete categorías que van desde acertijos lógicos hasta desafíos de observación. Ambas taxonomías se describen en detalle en las secciones \ref{subsec:clase_objective} y \ref{subsec:clase_puzzle} respectivamente.

El sistema ofrece cinco modos de juego diferenciados con distintos niveles de control sobre la generación: \textit{Generate} (generación autónoma total), \textit{Inspiration} (guiado por tema del usuario), \textit{Preset} (mundos preconstruidos), \textit{Tutorial} (mundo didáctico) y \textit{Replay} (recuperación de partidas guardadas). La descripción detallada de estos modos se presenta en la Sección \ref{sec:modos_juego}.

Para mejorar la experiencia del jugador, incorporamos un sistema de asistencia adaptativo que implementa un mecanismo dinámico de pistas (\textit{hints}) ajustado a la situación inmediata. Cuando el jugador está en una ubicación sin puzles, el sistema ofrece pistas relacionadas con el objetivo principal. Si hay un puzle en la ubicación pero no ha sido presentado, las pistas sugieren explorar e interactuar con elementos del entorno. Una vez que el puzle ha sido propuesto y el jugador no lo ha resuelto, las pistas cambian automáticamente a las específicas de ese puzle, proporcionando ayuda progresiva. Este mecanismo fue crucial para mejorar la experiencia de usuario sin comprometer el desafío, como se describe en la Sección \ref{sec:sistema_hints}.

La persistencia de datos se resolvió mediante integración con MongoDB, lo cual proporcionó capacidades de reproducibilidad fundamentales tanto para el modo \textit{Replay} como para el proceso de depuración durante el desarrollo. La capacidad de recuperar mundos exactos junto con un estado específico del juego (cargando tanto el mundo como el historial de turnos) aceleró significativamente la identificación y corrección de errores en el pipeline de generación.

Complementariamente, desarrollamos una interfaz de juego mejorada con la biblioteca Streamlit que permite elegir entre los cinco modos de juego mencionados, además de proporcionar herramientas de depuración para análisis de mundos, sistema de acciones rápidas, visualización estructurada del objetivo, y soporte bilingüe completo (español e inglés) tanto en la interfaz como en la generación narrativa del modelo de lenguaje.

Para asegurar la calidad de los mundos generados, implementamos un sistema de validación multinivel con capas que verifican la jugabilidad desde consistencia referencial hasta accesibilidad de objetivos. Estas validaciones, que se ejecutan entre etapas del pipeline de generación, se describen en profundidad en la Sección \ref{sec:validaciones}.

La Figura \ref{fig:flujo_general} muestra el flujo general del sistema, ilustrando cómo estos componentes interactúan desde la configuración inicial hasta la interacción del jugador con el mundo generado, incluyendo el ciclo de persistencia y recuperación desde MongoDB.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figs/generation-pipeline.png}
    \caption{Flujo general del sistema de generación y juego}
    \label{fig:flujo_general}
\end{figure}

\section{Estructura de Clases} \label{sec:estructura_clases}

Antes de describir cómo se genera el contenido del mundo mediante el pipeline incremental, es fundamental entender qué elementos lo componen y cómo se relacionan entre sí. Esta sección presenta la arquitectura de clases que define la estructura de los mundos interactivos en el sistema.

Durante las etapas tempranas del desarrollo, nos enfrentamos a un problema crítico: los primeros intentos de generación produjeron mundos donde los elementos estaban desconectados. Teníamos puzles que no contribuían al progreso, ubicaciones sin propósito narrativo y personajes aislados de la trama principal. Esta desconexión hacía extremadamente difícil probar el sistema y resultaba en experiencias de juego frustrantes e incoherentes.

Este problema motivó replantear fundamentalmente la arquitectura del mundo. La idea central que surgió fue que \textbf{todo debe estar lógica y semánticamente conectado en torno al objetivo y la narrativa}. No buscábamos mundos que fueran simplemente colecciones de elementos temáticamente coherentes; necesitábamos mundos donde cada elemento tuviera un propósito funcional claro en la progresión hacia el objetivo.

Para implementar esta visión, diseñamos una estructura con \textbf{conexiones y referencias explícitas} entre todos sus componentes. Esto implicó cambios significativos respecto a PAYADOR original: antes, las relaciones entre elementos eran implícitas (por ejemplo, una ubicación podía listar objetos por nombre sin validación de que existieran), y las condiciones para avanzar estaban codificadas en la lógica del motor, no en la definición del mundo.

La nueva arquitectura modela explícitamente:
\begin{itemize}
    \item \textbf{Personajes con propósito}: Cada personaje relevante para la narrativa tiene algo útil para el jugador (p. ej.: información, objetos) y establece condiciones claras para obtenerlo (p. ej.: resolver un puzle, entregar un objeto).
    \item \textbf{puzles con consecuencias}: Su resolución produce efectos tangibles modelados directamente en su definición: entregar objetos específicos, desbloquear pasajes concretos, o revelar información necesaria para el objetivo.
    \item \textbf{objetos funcionales}: Los objetos tienen roles definidos en la progresión narrativa, ya sea como requisitos para puzles, moneda de intercambio con personajes, o componentes del objetivo (ver \ref{subsec:clase_objective}).
    \item \textbf{Ubicaciones con significado}: Contienen elementos críticos para el avance o sirven como puntos de conexión en la red de dependencias del mundo.
\end{itemize}

Este diseño orientado al objetivo (\textit{goal-oriented}) ofrece ventajas cruciales:
\begin{itemize}
    \item \textbf{Guía para la generación}: El modelo de lenguaje recibe una estructura clara que define qué elementos debe crear y cómo deben relacionarse, reduciendo la ambigüedad.
    \item \textbf{Validación automática}: Las referencias cruzadas explícitas permiten verificar estructuralmente la coherencia. Si un puzle referencia un objeto como recompensa, ese objeto debe existir y estar ubicado correctamente.
    \item \textbf{Mejora de jugabilidad}: Al forzar conexiones explícitas con el objetivo, minimizamos la generación de contenido irrelevante o puramente decorativo.
\end{itemize}

La validación y coherencia son desafiantes incluso con esta estructura explícita; sin ella, con definiciones implícitas, sería prácticamente imposible que el modelo de lenguaje generara mundos funcionales. El enfoque \textit{goal-oriented} no es meramente una decisión de diseño; constituye una necesidad técnica fundamental para hacer viable la generación automática de mundos jugables.

La Figura \ref{fig:world-class-diagram} muestra la estructura de clases completa y las relaciones entre los componentes del mundo. A continuación describiremos cada clase en detalle.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/diagramaWorld.png}
    \caption{Diagrama de clases: World y sus componentes principales}
    \label{fig:world-class-diagram}
\end{figure}

\subsection{Clase World}

La clase \verb|World| constituye el contenedor principal de todos los elementos del juego y encapsula la filosofía de diseño fundamental: un mundo narrativo (\textit{story-driven}) orientado al objetivo (\textit{goal-oriented}) donde cada elemento está conectado lógica y semánticamente al objetivo principal. La clase \verb|World| encapsula los siguientes elementos estructurales:
\begin{itemize}
    \item \textbf{Metadatos narrativos}: Título, historia de fondo (\textit{backstory}), concepto del jugador
    \item \textbf{Objetivo principal}: Instancia de \verb|Objective| que define la meta del mundo
    \item \textbf{Ubicaciones}: Lista de \verb|Location| con sus conexiones bidireccionales
    \item \textbf{Personajes}: Lista de \verb|Character| con sus inventarios y condiciones de interacción
    \item \textbf{objetos}: Catálogo global de \verb|Item| con sus propiedades y ubicaciones
    \item \textbf{puzles}: Conjunto de \verb|Puzzle| con sus recompensas y requisitos
    \item \textbf{Estado inicial}: Ubicación de inicio y configuración inicial del jugador
\end{itemize}

Esta estructura garantiza que todos los elementos del mundo estén explícitamente definidos y conectados, permitiendo tanto al modelo de lenguaje generarlos coherentemente como al motor del juego validarlos y ejecutarlos correctamente.

\subsection{Clase Location}

La clase \verb|Location| representa los espacios físicos del mundo donde transcurre la acción del jugador. Cada ubicación hereda de \verb|Component| los atributos básicos de nombre y descripciones, y añade funcionalidad específica para la navegación espacial. En términos de atributos y componentes, esta clase se mantuvo prácticamente igual a la implementación original de PAYADOR; nuestra contribución principal se centró en las validaciones de conectividad que garantizan la generación de mundos jugables. Los atributos principales son:

\begin{itemize}
    \item \textbf{items}: Lista de objetos presentes en la ubicación
    \item \textbf{connecting\_locations}: Lista de ubicaciones directamente accesibles
    \item \textbf{blocked\_locations}: Diccionario de pasajes bloqueados por obstáculos (objetos o puzles)
    \item \textbf{visited}: Indicador de si el jugador ha visitado previamente la ubicación. Este atributo se envía al modelo de lenguaje como parte del contexto del mundo, permitiendo que adapte la narrativa: ubicaciones visitadas por primera vez reciben descripciones más elaboradas y detalladas, mientras que ubicaciones ya conocidas generan narraciones más breves y enfocadas en cambios relevantes.
\end{itemize}

Para garantizar la jugabilidad del mundo generado, implementamos validaciones estrictas sobre la estructura espacial de ubicaciones. Estas validaciones son críticas porque previenen la generación de mundos imposibles de completar:

\begin{itemize}
    \item \textbf{Bidireccionalidad}: Si la ubicación A conecta con B, entonces B debe conectar con A. Esta regla evita conexiones unidireccionales accidentales que podrían atrapar al jugador.
    \item \textbf{Conectividad global}: Todas las ubicaciones deben ser accesibles desde cualquier punto del mundo. No puede haber ubicaciones aisladas o grupos de ubicaciones desconectadas del resto.
    \item \textbf{Alcanzabilidad del objetivo}: El objetivo debe ser completable considerando la estructura espacial del mundo y los elementos disponibles. Debe existir al menos una ruta válida desde el estado inicial hasta la consecución del objetivo.
\end{itemize}

Estas reglas se especifican explícitamente en el prompt de la Etapa 3 del pipeline (que se describirá en la Sección \ref{sec:pipeline}), guiando al modelo de lenguaje a generar estructuras espaciales coherentes y navegables. Sin embargo, dado que el modelo puede fallar en mantener estas restricciones, implementamos una \textbf{verificación automática post-generación} que valida la conectividad mediante búsqueda en profundidad (DFS). Esta función construye un grafo de adyacencia considerando tanto conexiones normales como pasajes bloqueados (que son conexiones estructurales, solamente que temporalmente inaccesibles), y verifica que todas las ubicaciones sean alcanzables desde cualquier punto de partida. Si la validación falla, el sistema reporta qué ubicaciones quedaron aisladas, permitiendo detectar y corregir mundos con estructuras espaciales inválidas antes de que lleguen al jugador.

\subsection{Clase Item}

La clase \verb|Item| representa los objetos interactuables del mundo. Al igual que \verb|Location|, hereda de \verb|Component| los atributos de nombre y descripciones. Esta clase se mantuvo idéntica a la implementación de PAYADOR en términos de estructura: los atributos de nombre, descripciones y \verb|gettable| no sufrieron modificaciones. Nuestra contribución se centró en las validaciones que garantizan el uso coherente de estos atributos durante la generación automática.

El único atributo específico de \verb|Item| es \verb|gettable| (booleano), que determina si el objeto puede ser tomado por el jugador y añadido a su inventario. Esta propiedad simple tiene implicaciones profundas para el diseño del mundo: algunos objetos deben ser portables para permitir la progresión (p. ej.: llaves, herramientas), mientras que otros actúan como elementos fijos del entorno (p. ej.: muebles, estructuras arquitectónicas). El contexto narrativo también influye: sería incoherente que el jugador pudiera cargar un tanque de agua o mover una estatua monumental.

En la Etapa 3 del pipeline, establecimos reglas explícitas sobre el uso de \verb|gettable|:
\begin{itemize}
    \item Todo objeto necesario para completar el objetivo principal debe ser \verb|gettable=True|, garantizando que el jugador pueda obtenerlo.
    \item Los objetos que bloquean pasajes pueden ser \verb|gettable=True| (se desbloquea al tomarlos) o \verb|gettable=False| (requieren otra solución, como un puzle).
    \item Cada objeto debe tener una justificación clara dentro del mundo: funcional (parte de la progresión) o atmosférica (ambientación).
\end{itemize}

Esta distinción permite al modelo de lenguaje crear mundos donde no todos los objetos mencionados en las descripciones necesitan ser manipulables, evitando inconsistencias donde elementos puramente narrativos pudieran confundirse con objetos funcionales del juego.

Durante el desarrollo enfrentamos un problema crítico relacionado con el manejo de referencias únicas versus duplicación de objetos. Cuando el jugador intentaba tomar un objeto, particularmente aquellos otorgados como recompensa de puzles, el sistema duplicaba el objeto en lugar de mover la referencia existente. La causa raíz era que el modelo de lenguaje frecuentemente no creaba los objetos de recompensa especificados en los puzles, y nuestra solución inicial fue crear el objeto automáticamente si no existía. Sin embargo, esto causaba duplicación cuando el objeto sí existía pero la lógica de búsqueda fallaba en encontrarlo en los contenedores esperados (como en inventarios de personajes o ubicaciones).

La solución definitiva fue dual:
\begin{itemize}
    \item \textbf{Prevención en generación}: Implementamos una validación exhaustiva de recompensas de puzles (que se detallará más adelante en la Subsección \ref{subsec:clase_puzzle}) que verifica y crea los objetos faltantes durante la generación del mundo, no durante el juego.
    \item \textbf{Corrección en transferencia}: Refactorizamos la lógica de transferencia de objetos para buscar la referencia exacta del objeto en todos los contenedores posibles, moviendo la referencia en lugar de crear copias, y reportando errores explícitos si el objeto no se encuentra en ningún contenedor.
\end{itemize}

Este error evidenció la importancia de mantener referencias únicas a los objetos del mundo y validar exhaustivamente su ubicación antes de cualquier operación de transferencia. La complejidad surge porque los objetos pueden existir en múltiples contextos: como elementos libres en ubicaciones, en inventarios de personajes, o actuando como obstáculos que bloquean pasajes.

Sin embargo, como se discutirá en detalle en el Capítulo \ref{cap:evaluacion}, este problema reaparece en casos límite específicos: cuando el modelo de lenguaje intenta mover un objeto al inventario del jugador pero la búsqueda de su ubicación actual falla (debido a problemas de comparación de identidad de objetos), el sistema interpreta incorrectamente la operación, añadiendo el objeto a la ubicación actual sin removerlo de su posición original, resultando en duplicación. Este comportamiento revela la fragilidad de la lógica de control de flujo cuando se combina con la búsqueda flexible de objetos y las múltiples ramificaciones condicionales del sistema de actualización del mundo.

\subsection{Clase Character}

La clase \verb|Character| representa tanto al jugador como a los personajes no jugadores (NPCs) del mundo. Al igual que las clases anteriores, hereda de \verb|Component| y se mantuvo estructuralmente similar a la implementación de PAYADOR, con ajustes menores para soportar las necesidades del sistema de generación. Los atributos principales son:

\begin{itemize}
    \item \textbf{inventory}: Lista de objetos que posee el personaje
    \item \textbf{location}: Referencia a la ubicación actual donde se encuentra
    \item \textbf{visited\_locations}: Diccionario que registra las ubicaciones visitadas y sus descripciones sucesivas
    \item \textbf{interaction}: Datos estructurados de interacción provenientes del proceso de generación, que incluyen información sobre puzles propuestos y condiciones de intercambio
\end{itemize}

Durante la Etapa 3 del pipeline, establecimos reglas para garantizar que los NPCs generados sean funcionalmente coherentes:
\begin{itemize}
    \item Si un personaje tiene capacidad de interacción, debe contar con texto de interacción definido. Este texto se utiliza cuando el sistema presenta automáticamente un puzle asociado al personaje, garantizando una transición narrativa fluida entre la exploración y el desafío.
    \item Todo objeto en el inventario de un personaje debe existir en la lista global de objetos del mundo, evitando referencias inexistentes.
    \item Los personajes deben estar asignados a una ubicación válida del mundo, resolviendo el problema de NPCs sin ubicación asignada que observamos en experimentos preliminares de generación directa.
\end{itemize}

Estas validaciones aseguran que los NPCs no solo sean temáticamente apropiados sino también funcionalmente integrados en la mecánica del juego, permitiendo intercambios de objetos, proposición de puzles y progresión narrativa coherente.

\subsection{Clase Puzzle} \label{subsec:clase_puzzle}

La clase \verb|Puzzle| representa los desafíos que obstaculizan el progreso del jugador hacia el objetivo. A diferencia de las clases anteriores, \verb|Puzzle| experimentó modificaciones y extensiones significativas respecto a la implementación base de PAYADOR, impulsadas por los problemas observados durante nuestras pruebas internas y las necesidades del sistema de generación automática.

Uno de los primeros cambios que implementamos fue la introducción de tipos explícitos de puzles. Sin esta categorización, el modelo de lenguaje quedaba sin guía clara al momento de crear desafíos, generando puzles inconsistentes o mal estructurados. Definimos siete tipos de puzles que el sistema puede generar. La Tabla \ref{tab:tipos_puzzles} presenta cada tipo con su descripción y un ejemplo representativo.

\begin{table}[h]
\centering
\caption{Tipología de puzles implementada en el sistema}
\label{tab:tipos_puzzles}
\begin{tabular}{|p{2.5cm}|p{5cm}|p{6cm}|}
\hline
\textbf{Tipo} & \textbf{Descripción} & \textbf{Ejemplo} \\
\hline
Riddle & Adivinanzas que requieren razonamiento lateral o conocimiento general & ``Vuela sin alas, llora sin ojos. Cuando aparece, la oscuridad huye.'' (Respuesta: nube) \\
\hline
Logic & Problemas lógicos que requieren deducción o razonamiento estructurado & ``Si todos los zorgos son plinks, y algunos plinks son truks, ¿pueden algunos zorgos ser truks?'' \\
\hline
Wordplay & Juegos de palabras, anagramas, o puzles lingüísticos & ``Reorganiza las letras de ALERO para encontrar el nombre del metal.'' (Respuesta: OREAL → ORO) \\
\hline
Observation & Observar detalles del entorno para encontrar la solución & ``Cuenta las velas encendidas en el candelabro del salón.'' \\
\hline
Sequence & Ordenar elementos o realizar acciones en una secuencia específica & ``Toca las estatuas en orden del más joven al más viejo según sus inscripciones.'' \\
\hline
Code & Descifrar códigos o patrones & ``La combinación de la caja fuerte está escrita en números romanos en el cuadro.'' \\
\hline
Memory & Recordar información presentada previamente en la narrativa & ``¿Cuál era el color de los ojos del guardián que encontraste en la entrada?'' \\
\hline
\end{tabular}
\end{table}

Inicialmente habíamos incluido un tipo adicional llamado \textit{Information}, donde resolver el puzle otorgaba información relevante para el objetivo. Sin embargo, en experimentos preliminares observamos que este tipo resultaba problemático: los puzles frecuentemente no se presentaban correctamente o, cuando se resolvían, entregaban información irrelevante u obvia, lo que podía confundir o frustrar al jugador. Dado que el sistema está diseñado con un enfoque \textit{goal-oriented}, todos los tipos de puzles terminan derivando en obtener una recompensa tangible (por ejemplo, un objeto) o completar un objetivo. Por esta razón, decidimos eliminar el tipo \textit{Information} y mantener solo aquellos donde la recompensa es funcionalmente clara.

La estructura de un puzle incluye los siguientes elementos:

\begin{itemize}
    \item \textbf{problem}: El enunciado del desafío que debe resolver el jugador (p. ej.: ``¿Qué tiene ojos pero no puede ver?'')
    \item \textbf{answer}: La respuesta esperada, oculta al jugador
    \item \textbf{puzzle\_type}: Categorización según la tipología presentada en la Tabla \ref{tab:tipos_puzzles}
    \item \textbf{proposed\_by\_character}: Nombre del personaje que propone el puzle, o \verb|None| si es de descubrimiento ambiental
    \item \textbf{proposed\_by\_location}: Nombre de la ubicación cuya investigación revela el puzle (para puzles ambientales), \verb|None| si es propuesto por un personaje
    \item \textbf{rewards}: Recompensa obtenida al resolver el puzle (p. ej.: objetos específicos, pasajes desbloqueados)
    \item \textbf{relevance\_to\_objective}: Explicación de cómo resolver este puzle contribuye a alcanzar el objetivo principal del mundo. Este campo ayuda al jugador a entender por qué vale la pena resolver el desafío
    \item \textbf{puzle\_hints}: Lista de pistas progresivas para ayudar al jugador. Las pistas siempre son tres y se entregan en orden de más general a más específica
    \item \textbf{interaction\_hint}: Sugerencia breve sobre cómo iniciar la interacción con el puzle (p. ej.: ``Intenta hablar con el guardián'' o ``Examina la inscripción en la pared''). Esta pista se diferencia de las \verb|puzzle_hints| en que se muestra cuando el puzle existe pero aún no ha sido presentado al jugador, guiándolo a descubrirlo
\end{itemize}

Durante el desarrollo identificamos seis problemas principales relacionados con los puzles que requirieron soluciones específicas. Estos problemas ilustran las complejidades de delegar la generación de contenido funcional a modelos de lenguaje.

\textbf{Problema 1: Puzles invisibles.} Uno de los problemas más persistentes fue que el modelo de lenguaje creaba puzles que nunca eran presentados al jugador durante la partida. Inicialmente intentamos resolver esto mediante instrucciones en el prompt, agregando los atributos \verb|interaction_hint| y especificando si el puzle era \verb|proposed_by_character| o \verb|proposed_by_location| para que el modelo supiera cuándo narrarlo. Sin embargo, observamos que en la salida del modelo frecuentemente se omitía la presentación del puzle: aunque el jugador hablara con el personaje que tenía un puzle asociado, la narración generada no lo mencionaba.

Ante esta situación, decidimos que no podíamos confiar en el modelo para esta tarea crítica que afecta directamente la jugabilidad. Implementamos una intervención lógica directa del sistema: si la entrada del usuario menciona a un personaje que tiene un puzle asociado, el sistema no solicita narración al modelo de lenguaje; en su lugar, narra automáticamente la proposición del puzle utilizando el \verb|interaction_text| generado previamente durante la creación del mundo. Esta intervención busca garantizar que los puzles sean efectivamente presentados al jugador. Adicionalmente, marcamos el puzle como presentado mediante un atributo \verb|given: True|, de forma que el sistema no lo ingrese al prompt del modelo de lenguaje en potenciales futuras interacciones del jugador con el mismo personaje.

\textbf{Problema 2: Puzles inventados durante el juego.} Otro problema recurrente fue que el modelo a veces generaba puzles que no existían en la estructura del mundo. Si el jugador hablaba con un NPC y le solicitaba algo que el personaje tenía en su inventario, ocasionalmente el modelo narraba ``resuelve este puzle y te lo daré'' aunque el NPC no tuviera ningún puzle asociado estructuralmente. Este problema era particularmente complejo de detectar porque no era inmediatamente visible durante el juego; solo al inspeccionar la representación simbólica del mundo (los archivos JSON) podíamos identificar que el jugador estaba intentando resolver un puzle que no existía en la estructura.

La solución requirió ser más explícitos en el prompt de narración. En el contexto de este documento, utilizamos el término ``alucinación'' cuando el modelo de lenguaje no respeta el estado del mundo representado simbólicamente, generando contenido inconsistente con la estructura definida. Especificamos en las instrucciones que si no hay un puzle presente en la estructura del mundo, el modelo no debe inventar puzles. Las validaciones estructurales del mundo fueron fundamentales para detectar este tipo de inconsistencias durante el desarrollo.

\textbf{Problema 3: Puzles excesivamente difíciles.} En nuestras pruebas internas observamos puzles tan complejos que resultaban imposibles de resolver sin ayuda externa. En múltiples ocasiones tuvimos que consultar directamente la respuesta en la representación simbólica del mundo, ya que podíamos invertir varios minutos intentando razonar el puzle sin acercarnos a la solución.

Este problema motivó la implementación del \textbf{sistema de pistas progresivas} mediante el atributo \verb|puzzle_hints|. Las pistas están ordenadas en cantidad ascendente de información: la primera puede orientar al jugador hacia la dirección correcta, la segunda proporciona más detalles, y la tercera prácticamente revela la respuesta, reconociendo que el jugador está significativamente atascado. Como se mencionará en la descripción del pipeline (Sección \ref{sec:pipeline}), esta idea resultó tan efectiva que posteriormente la expandimos a pistas para objetivos y pistas de exploración general. Como presentaremos en el Capítulo \ref{cap:evaluacion}, las evaluaciones con usuarios confirmaron la utilidad de este sistema: muchos participantes solicitaron las tres pistas para varios puzles, indicando que se habrían atascado de no existir este mecanismo.

\textbf{Problema 4: Recompensas no entregadas.} Cuando un puzle era propuesto por un NPC y su recompensa era un objeto en el inventario del personaje, observamos que el NPC no entregaba el objeto tras resolver el puzle correctamente. El problema radicaba en que el modelo de lenguaje no incluía en su salida la transformación necesaria (\verb|moved_object|) del inventario del NPC al jugador.

La solución nuevamente requirió intervención del sistema simbólico: cuando el jugador resuelve un puzle, se ejecuta una función que verifica las recompensas estructuradas, busca el objeto correspondiente y lo mueve automáticamente al inventario del jugador, sin depender de que el modelo genere esta acción en su narración.

\textbf{Problema 5: Recompensas inexistentes.} En varios mundos generados identificamos que las recompensas de puzles (especificadas como \verb|ItemReward| en la estructura) no existían en el conjunto de objetos del mundo. Cuando el jugador resolvía el puzle, no ocurría nada porque no había objeto que mover. Este problema se detectó durante validaciones post-generación y lo abordamos mediante una función de verificación que:

\begin{itemize}
    \item Verifica que todos los objetos de recompensa existan en \verb|world.items|
    \item Si un objeto de recompensa no existe, lo crea automáticamente
    \item Asigna el objeto creado al inventario del personaje que propone el puzle, o a la ubicación del puzle si es ambiental
    \item Registra todas las correcciones aplicadas para facilitar el análisis posterior
\end{itemize}

Esta estrategia de crear elementos faltantes contrasta con el enfoque adoptado para las pistas de misterio (que se describirá en la siguiente subsección), donde eliminamos pistas inválidas en lugar de crear los elementos referenciados. La diferencia refleja las distintas prioridades: los puzles son obstáculos activos que bloquean progresión y deben funcionar correctamente, mientras que las pistas son elementos opcionales de descubrimiento que pueden ajustarse en cantidad sin comprometer la jugabilidad fundamental.

\textbf{Problema 6: Validación de respuestas.} La verificación de respuestas de puzles presentó múltiples desafíos técnicos. Inicialmente, diferencias menores como puntuación o mayúsculas causaban que respuestas correctas fueran rechazadas (por ejemplo, ``a map'' versus ``A map.''). Implementamos normalización de respuestas que convierte todo a minúsculas, elimina puntuación al inicio y final, normaliza espacios en blanco, y remueve artículos iniciales en inglés (a, an, the).

Sin embargo, persisten limitaciones con sinónimos y respuestas semánticamente equivalentes. En el Capítulo \ref{cap:evaluacion} presentaremos cómo un evaluador respondió ``humans'' en lugar de la respuesta esperada ``man'', siendo marcado como incorrecto. Esto evidencia el problema fundamental de la validación basada en comparación de cadenas de texto: aunque empleamos el modelo de lenguaje para determinar la correctitud de la respuesta, el prompt prioriza coincidencia con la respuesta esperada. Podríamos ajustar las instrucciones para que acepte sinónimos más liberalmente, pero esto introduciría riesgos de falsos positivos donde respuestas incorrectas sean aceptadas por similitud superficial. Este problema permanece como una limitación conocida del sistema.

\subsection{Clase Objective} \label{subsec:clase_objective}

La clase \verb|Objective| experimentó cambios sustanciales respecto a la implementación de PAYADOR, evolucionando desde un sistema simple de tuplas a una estructura compleja con múltiples tipos, validaciones exhaustivas y elementos narrativos. Esta clase define la meta que el jugador debe alcanzar y proporciona el cierre narrativo de la aventura. Un objetivo estructurado contiene los siguientes elementos:

\begin{itemize}
    \item \textbf{type}: Tipo de objetivo según la taxonomía que describiremos a continuación
    \item \textbf{components}: Lista de componentes involucrados (p. ej.: objetos, personajes, ubicaciones). Todos los componentes referenciados deben existir en el mundo
    \item \textbf{description}: Descripción clara de lo que el jugador debe lograr (p. ej.: ``Debes encontrar el medallón dorado escondido en la mansión'')
    \item \textbf{success\_conditions}: Condiciones específicas que deben cumplirse para completar el objetivo
    \item \textbf{completion\_narration}: Descripción narrativa de lo que sucede tras completar el objetivo. Este atributo no se usa en objetivos de tipo \verb|solve_mystery| porque estos tienen su propio mecanismo de conclusión mediante \verb|mystery_solution|
    \item \textbf{objective\_hints}: Las pistas siempre son tres y se entregan en orden de más general a más específica, proporcionando ayuda progresiva al jugador
    \item \textbf{mystery\_clues}: Lista de pistas para objetivos de misterio. Solo se usa para objetivos de tipo \verb|solve_mystery|
    \item \textbf{mystery\_solution}: Solución del misterio. Solo se usa para objetivos de tipo \verb|solve_mystery|
\end{itemize}

Definimos cinco tipos de objetivos, algunos inspirados en los mundos diseñados originalmente para evaluar PAYADOR \cite{gongora2024payador} y otros completamente nuevos:

\begin{itemize}
    \item \textbf{REACH\_LOCATION}: La posición del personaje del jugador debe alcanzar un valor específico correspondiente a una ubicación objetivo
    \item \textbf{GET\_ITEM}: El jugador debe obtener un objeto específico en su inventario
    \item \textbf{DELIVER\_AN\_ITEM}: El jugador debe entregar un objeto a un personaje o ubicación
    \item \textbf{FIND\_CHARACTER}: La ubicación del personaje del jugador debe coincidir con la ubicación de otro personaje específico
    \item \textbf{SOLVE\_MYSTERY}: El jugador debe descubrir todas las pistas asociadas a un misterio
\end{itemize}

Al igual que con los puzles, la generación automática de objetivos presentó varios problemas que requirieron soluciones específicas.

\textbf{Problema fundamental: Objetivos imposibles.} El primer problema crítico que enfrentamos fue que el modelo de lenguaje generaba objetivos imposibles de completar. En experimentos preliminares observamos objetivos que pedían conseguir objetos que no habían sido incluidos en la lista de elementos del mundo, llegar a lugares inexistentes, o encontrar personajes no ubicados en ninguna localización. Este fue uno de los primeros problemas que motivó la implementación de validaciones exhaustivas.

Es importante mencionar que esta validación no era necesaria en PAYADOR original porque los objetivos los creaba una persona que validaba manualmente la coherencia, pero en nuestro sistema los crea un modelo de lenguaje y por eso implementamos verificaciones simbólicas. Desarrollamos una función de verificación que valida para cada tipo de objetivo:

\begin{itemize}
    \item \textbf{REACH\_LOCATION}: La ubicación objetivo existe y es alcanzable desde la ubicación inicial
    \item \textbf{GET\_ITEM}: El objeto objetivo existe, está ubicado en algún lugar accesible (ubicación o inventario de personaje), y tiene \verb|gettable=True|
    \item \textbf{DELIVER\_AN\_ITEM}: Tanto el objeto como el destino (ubicación o personaje) existen y son accesibles
    \item \textbf{FIND\_CHARACTER}: El personaje objetivo existe y está ubicado en una localización válida
    \item \textbf{SOLVE\_MYSTERY}: Todas las pistas del misterio están asociadas con objetos que existen en el mundo
\end{itemize}

\textbf{Problema: Objetivos compuestos y mecánicas no soportadas.} En experimentos preliminares, el modelo frecuentemente creaba objetivos compuestos como ``encuentra las 3 reliquias y únelas para armar la llave'' o ``consigue los 4 cristales elementales para activar el portal''. Estos objetivos presentaban dos problemas fundamentales: primero, el código no estaba preparado para manejar múltiples elementos como una sola unidad cohesiva; segundo, las mecánicas de combinación de objetos no existen en el motor de PAYADOR (como mencionamos previamente, no hay transformación para combinar objetos y crear otros).

Consideramos implementar un tipo de objetivo \verb|get_items| que se completara progresivamente. Sin embargo, esto generó múltiples problemas y confusiones tanto en la implementación como en la experiencia del jugador. La solución más simple y robusta fue establecer reglas explícitas en el prompt (que se detallará en el anexo correspondiente, ver Sección \ref{anexo:prompts}) que limitaran la complejidad de los objetivos: un solo objeto para \verb|GET_ITEM|, una sola ubicación para \verb|REACH_LOCATION|, un solo personaje para \verb|FIND_CHARACTER|, y un objeto con un destino para \verb|DELIVER_AN_ITEM|.

Esta restricción simplificó dramáticamente la verificación de completitud del objetivo y eliminó la ambigüedad sobre qué elementos eran requeridos versus opcionales.

\textbf{Problema de narración: Meta-comentarios del modelo.} Otro problema recurrente ocurría al narrar el objetivo al inicio de la aventura. En lugar de describir el objetivo, el modelo a veces respondía meta-comentarios como ``Perfecto! Narraré el objetivo entre símbolos'', lo cual claramente no era útil para el jugador. Intentamos mitigar esto con instrucciones más explícitas en el prompt y usando marcadores especiales para extraer solo la parte relevante, pero el problema persistía ocasionalmente.

La solución definitiva fue dual: primero, mantuvimos los intentos de corrección en el prompt para mejorar la narración inicial; segundo, creamos una acción rápida que muestra el objetivo directamente desde la estructura del mundo (\verb|objective.description|), sin depender del modelo para su narración. Esta segunda solución no solamente resuelve el problema de que el modelo comente sobre el objetivo, sino que también permite a los usuarios consultar el objetivo en cualquier momento sin tener que desplazarse hasta la narración inicial. Luego de programarla, esta característica nos resultó muy interesante y, como consideramos que suma a la inmersión narrativa, decidimos extenderla a otros elementos del juego, como se describirá en la Sección \ref{sec:acciones_rapidas} al hablar de la interfaz de usuario.

La implementación del objetivo tipo \verb|solve_mystery| (que describiremos a continuación) incluyó una narración de cierre al completar el objetivo mediante \verb|mystery_solution|. Esta característica nos resultó satisfactoria narrativamente, por lo que decidimos extenderla a todos los tipos de objetivos mediante \verb|completion_narration|, que proporciona un desenlace narrativo al completar la aventura.

Sin embargo, como presentaremos en el Capítulo \ref{cap:evaluacion}, la narración de cierre ocasionalmente causó confusión en las evaluaciones con usuarios. Un evaluador completó un objetivo de tipo \verb|solve_mystery| con una sola pista, recibió la narración de cierre, pero interpretó que el juego continuaba y siguió jugando durante una hora adicional. Aunque el evaluador reportó haberse divertido, esto evidenció la necesidad de comunicar más explícitamente cuándo el juego ha terminado.

\subsection{Objetivos de Misterio: Diseño y Desafíos} \label{subsec:objetivos_misterio}

El tipo de objetivo \verb|solve_mystery| requirió el diseño más complejo de todos los tipos de objetivos y recibió mayor atención durante el desarrollo. A diferencia de los demás tipos que se verifican mediante condiciones directas sobre el estado del mundo (posesión de un objeto, presencia en una ubicación), los objetivos de misterio se completan cuando el jugador descubre todas las pistas asociadas. El sistema opera de la siguiente manera:

\begin{itemize}
    \item Cada pista (\verb|MysteryClue|) está asociada con un objeto físico del mundo
    \item Cuando el jugador interactúa con un objeto que tiene una pista asociada, la parte simbólica del sistema detecta la interacción y marca la pista como descubierta
    \item Se muestra al jugador un mensaje especial con el nombre de la pista, su descripción, su relevancia con respecto a resolver el misterio, y el progreso actual (por ejemplo: ``2 de 4 pistas descubiertas'')
    \item Al descubrir todas las pistas, el objetivo se completa y se revela el \verb|mystery_solution|
\end{itemize}

Al igual que hicimos para los puzles, también incluimos reglas especiales en el prompt para favorecer que los objetivos de misterio se generen correctamente. Las reglas principales especifican que:

\begin{itemize}
    \item Cada pista debe estar asociada únicamente con un objeto o objeto físico que existe en el mundo, nunca con personajes o ubicaciones. El atributo \verb|associated_item| debe corresponder exactamente al nombre de un objeto que aparece en la lista de objetos del mundo
    \item El objetivo debe especificar explícitamente la lista \verb|mystery_clues| (pistas detalladas) y \verb|mystery_solution| (solución completa del misterio)
    \item En este caso no se usa \verb|completion_narration|; en su lugar se presenta la solución del misterio mediante \verb|mystery_solution|
\end{itemize}

Similar al problema de recompensas inexistentes en puzles, enfrentamos situaciones donde las pistas de misterio referenciaban objetos que no existían en el mundo. Sin embargo, adoptamos una estrategia opuesta a la usada con puzles: en lugar de crear los objetos faltantes, eliminamos las pistas inválidas.

Esta decisión se tomó porque crear objetos automáticamente para pistas podía resultar en objetos desconectados de la narrativa, mientras que eliminar pistas simplemente reducía el número de pistas a descubrir, manteniendo la coherencia del mundo. Esta diferencia en el enfoque de validación refleja las diferentes prioridades mencionadas anteriormente: los puzles son obstáculos activos que bloquean progresión y deben funcionar correctamente, mientras que las pistas son elementos opcionales de descubrimiento que pueden ajustarse en cantidad sin comprometer la jugabilidad fundamental.

Como presentaremos en el Capítulo \ref{cap:evaluacion}, esta estrategia de eliminación ocasionalmente resultó en objetivos de misterio con muy pocas pistas, lo cual contribuyó al problema donde un evaluador completó el objetivo más rápidamente de lo anticipado y experimentó confusión sobre si el juego había terminado.

\section{Pipeline de Generación Incremental} \label{sec:pipeline}

Con la estructura de clases definida, podemos ahora describir cómo el sistema genera mundos completos a partir de estas componentes básicas. El pipeline de generación incremental es el proceso que orquesta la creación del mundo en cinco etapas secuenciales, cada una con responsabilidades claramente delimitadas.

\subsection{Motivación: De la Generación Directa al Enfoque Incremental}

Al iniciar el proyecto realizamos varios experimentos preliminares usando una única llamada al modelo de lenguaje para generar el mundo completo. Esta aproximación de generación directa presentó problemas significativos durante las pruebas: sobrecarga en el procesamiento del modelo, inconsistencias narrativas y desconexión entre elementos del mundo.

La generación directa requiere que el modelo genere simultáneamente la historia, objetivos, elementos del mundo, personajes y sus interrelaciones, lo cual excede su capacidad de procesamiento coherente en una única invocación. Durante la experimentación con este enfoque, observamos problemas recurrentes que comprometían la jugabilidad:

\begin{itemize}
    \item \textbf{Objetos críticos sin ubicación}: El modelo frecuentemente olvidaba colocar objetos necesarios para completar el objetivo en ubicaciones específicas del mundo, dejándolos sin una posición definida o directamente omitiéndolos de la estructura.
    \item \textbf{NPCs sin contexto espacial}: Personajes importantes para la narrativa se generaban sin asignación a ninguna ubicación, imposibilitando la interacción con ellos.
    \item \textbf{Desconexión entre narrativa y estructura}: El trasfondo mencionaba elementos que luego no existían en el mundo jugable, o viceversa.
    \item \textbf{Límites de longitud de prompt}: Al intentar mitigar estos problemas agregando instrucciones más detalladas y explícitas, alcanzábamos repetidamente el límite de longitud de caracteres permitido por las APIs (que posteriormente se convierte en tokens para el procesamiento del modelo), sin que esto garantizara mejoras en la consistencia.
\end{itemize}

Para entender y caracterizar mejor estos problemas, realizamos un experimento controlado: en lugar de solicitar que el modelo generara todo el mundo de una vez, le proporcionamos manualmente una descripción narrativa (\textit{backstory}) completa y detallada, inspirada en uno de los mundos diseñados originalmente para evaluar PAYADOR \cite{gongora2024payador}. A partir de esta descripción en lenguaje natural, solicitamos que construyera la estructura del mundo. Los resultados fueron significativamente superiores: el modelo logró crear un mundo considerablemente más consistente, con la mayoría de los elementos correctamente ubicados y conectados lógicamente.

Si bien el enfoque incremental no elimina completamente los errores de generación—particularmente en mundos de alta complejidad donde el modelo puede omitir elementos o crear inconsistencias—la frecuencia y severidad de estos problemas se redujo drásticamente en comparación con el enfoque de generación directa. Este resultado reveló que el problema principal no era la capacidad del modelo para estructurar mundos coherentes, sino la carga de tener que inventar y estructurar simultáneamente. Inspirado en esos experimentos preliminares, propusimos que la creación del mundo se dé en etapas incrementales, permitiendo que:

\begin{itemize}
    \item Cada etapa se enfoque en un aspecto específico del mundo
    \item Los prompts puedan ser más explícitos sin exceder límites de longitud
    \item Las salidas validadas de etapas anteriores sirvan como contexto para etapas posteriores
    \item El modelo mantenga mejor coherencia al trabajar con tareas más acotadas
    \item Exista intervención simbólica y validación entre etapas, donde el sistema verifica automáticamente la coherencia estructural
\end{itemize}

\subsection{Etapas del Pipeline}

\subsubsection{Etapa 1: El Núcleo de la Aventura}

Esta etapa establece los fundamentos narrativos del mundo. El modelo de lenguaje recibe como entrada una idea del usuario (en el modo \textit{Inspiration}) o genera una propuesta original (modo \textit{Generate}), produciendo:

\begin{itemize}
    \item \textbf{Título}: Nombre identificativo de la aventura
    \item \textbf{Trasfondo} (\textit{backstory}): Contexto narrativo que motiva la aventura del jugador
    \item \textbf{Concepto del jugador}: Perfil del protagonista
    \item \textbf{Objetivo principal}: Meta estructurada según la taxonomía de \verb|ObjectiveType| presentada en la Sección \ref{subsec:clase_objective}
\end{itemize}

Esta etapa es análoga al experimento exitoso que realizamos con la descripción narrativa manual: se crea primero el por qué antes que el qué y el cómo.

El prompt de esta etapa (disponible en el Anexo \ref{anexo:prompts}, Sección \ref{anexo:prompt_step1}) difiere significativamente según el modo seleccionado, reflejando las diferentes necesidades de cada aproximación.

En el modo \textit{Generate}, el prompt enfatiza la autonomía completa del modelo de lenguaje. Le indicamos explícitamente que tiene libertad para inventar cualquier tipo de historia, con ambientaciones diversas (p. ej.: medieval, ciencia ficción, moderna, fantástica), personajes únicos con personalidades interesantes, y objetivos desafiantes. También le sugerimos categorías temáticas amplias como inspiración (p. ej.: misterio, aventura, supervivencia, social, exploración) que puede elegir o combinar libremente, pero sin imponer restricciones. El énfasis está en la creatividad sin límites y en la generación de conceptos originales.

Sin embargo, durante las pruebas iniciales con el modo \textit{Inspiration}, observamos un problema recurrente: aunque mencionábamos el tema proporcionado por el usuario al inicio del prompt, el modelo tendía a generar mundos donde solamente la ambientación general guardaba relación con la temática. Los NPCs, puzles y especialmente el objetivo principal frecuentemente se desviaban hacia elementos genéricos sin conexión clara con el tema especificado. Por ejemplo, en un mundo con tema ``piratas del Caribe'', podríamos obtener una ambientación pirata pero con un objetivo de resolver un acertijo matemático abstracto, o NPCs con motivaciones completamente desvinculadas del contexto pirata. Para resolver este problema, diseñamos una estrategia de reiteración temática constante en el prompt. En lugar de mencionar el tema una sola vez, lo reforzamos en múltiples secciones, estableciendo que el tema proporcionado debe ser la base fundamental de todo el concepto del mundo, que cada ubicación, personaje, objeto y especialmente el objetivo principal deben ser componentes intrínsecamente ligados al tema, que el modelo no debe proponer elementos desconectados, que los personajes deben asumir roles que muestren distintas dimensiones del tema, que el objetivo principal debe estar intrínsecamente relacionado con la temática, y que los puzles imaginados para etapas posteriores deben surgir naturalmente del tema.

Esta reiteración constante resultó ser clave para mantener la coherencia temática. Al enfatizar la obligación temática en cada sección relevante del prompt (no solamente al principio), logramos que el modelo mantuviera la coherencia temática no únicamente en la ambientación superficial, sino en todos los elementos estructurales del mundo, especialmente en aquellos que afectan directamente la jugabilidad como el objetivo, los puzles futuros y las motivaciones de los NPCs.

\subsubsection{Etapa 2: El Esqueleto del Mundo}

Una vez establecido el núcleo narrativo en la Etapa 1, esta etapa identifica las entidades principales necesarias para completar el objetivo. El modelo determina las ubicaciones clave en la secuencia de acciones necesarias para llegar al objetivo, los personajes relevantes para la narrativa, los objetos necesarios para completar el objetivo, y las relaciones preliminares entre estas entidades.

En esta etapa se utilizan parámetros de configuración especificados por el usuario (o usando otros por defecto), que permiten controlar explícitamente el tamaño y complejidad del mundo:

\begin{itemize}
    \item \textbf{Número de ubicaciones}: Define la cantidad de lugares del mundo
    \item \textbf{Cantidad de NPCs}: Determina cuántos personajes pueblan el mundo
    \item \textbf{Cantidad de objetos}: Especifica el número de objetos interactuables
    \item \textbf{Número de puzles}: Establece cuántos desafíos incluir
\end{itemize}

Incorporamos estos parámetros en el prompt del modelo de forma explícita (esta prompt está disponible en el Anexo \ref{anexo:prompts}, donde se puede ver que la función que la genera recibe como parámetros estos valores que mencionamos), garantizando que el esqueleto generado respete las restricciones de tamaño. Por ejemplo, si el usuario especifica 5 ubicaciones, el modelo de lenguaje tiene que generar 5 ubicaciones, y si especifica un rango (por ejemplo: 2 a 4 puzles), tiene que generar un número de puzles en ese rango.

Durante las pruebas iniciales observamos que el modelo tendía a generar entidades (p. ej.: ubicaciones, NPCs, objetos) que, aunque temáticamente coherentes, carecían de conexión funcional con el objetivo principal. Esto resultaba en mundos donde el jugador podía encontrarse con elementos interesantes pero irrelevantes para completar la aventura. Para mitigar este problema, establecimos reglas explícitas en el prompt de esta etapa.

Primero, cada entidad generada debe tener una relación identificable con el camino hacia el objetivo. No basta con que sean temáticamente apropiadas; deben tener un propósito dentro de la progresión del juego. Segundo, debe existir una ruta lógica hacia el objetivo: una secuencia clara de eventos, ubicaciones y acciones que permitan al jugador avanzar desde el punto de partida hasta la consecución del objetivo. Esta ruta no necesariamente debe ser lineal, pero sí debe ser identificable y coherente.

Sin embargo, como se detallará en el Capítulo \ref{cap:evaluacion}, la evaluación con jugadores humanos reveló que esto no fue completamente suficiente. En varios mundos generados seguimos encontrando puzles, objetos o NPCs que no tenían un propósito real para alcanzar el objetivo. Esta característica puede interpretarse de dos maneras: como una limitación del sistema que genera contenido irrelevante, o como un elemento de ambientación con contenido exploratorio opcional y accesorio. La valoración depende en última instancia de las expectativas y preferencias del jugador: algunos usuarios pueden apreciar la profundidad adicional y la sensación de un mundo más vívido, mientras que otros pueden preferir experiencias más optimizadas donde cada elemento tenga un propósito claro.

La salida de esta etapa es una lista de entidades sin detalles exhaustivos, funcionando como un esqueleto que será completado en etapas posteriores, pero ya con las cantidades definidas que guiarán el resto del pipeline. La Figura \ref{fig:ejemplo_esqueleto} muestra un ejemplo de la salida de esta etapa.

\begin{figure}[h]
\centering
\begin{minipage}{0.9\textwidth}
\small
\begin{verbatim}
{
  "key_locations": [
    {"name": "Entrada del Templo", "purpose": "Punto de inicio"},
    {"name": "Sala de las Estatuas", "purpose": "Puzle principal"},
    {"name": "Cámara del Tesoro", "purpose": "Ubicación del objetivo"}
  ],
  "key_items": [
    {"name": "Antorcha", "purpose": "Iluminar pasajes oscuros"},
    {"name": "Llave de Piedra", "purpose": "Abrir Cámara del Tesoro"},
    {"name": "Medallón Dorado", "purpose": "Objetivo principal"}
  ],
  "key_characters": [
    {"name": "Guardián del Templo", "purpose": "Propone puzle de estatuas"}
  ]
}
\end{verbatim}
\end{minipage}
\caption{Ejemplo de esqueleto de mundo generado en la Etapa 2}
\label{fig:ejemplo_esqueleto}
\end{figure}

\subsubsection{Etapa 3: El Mundo Jugable}

Esta etapa materializa el esqueleto agregando detalles descriptivos y funcionales: descripciones textuales de ubicaciones, atributos de personajes (p. ej.: descripciones, el lugar donde está), propiedades de objetos (p. ej.: el nombre, si se puede agarrar), y conexiones entre ubicaciones.

Con el esqueleto ya definido en la Etapa 2, diseñamos el prompt de esta etapa (disponible en el Anexo \ref{anexo:prompts}) para ser significativamente más específico sobre los requisitos de cada elemento, evitando las omisiones observadas en la generación directa.

En esta etapa se asignan explícitamente ubicaciones a todos los objetos y personajes, resolviendo el problema de elementos sin posición definida que observamos en experimentos preliminares. El prompt especifica que cada personaje debe estar ubicado en un lugar que existe en el mundo, y cada objeto debe tener una ubicación inicial definida o estar en el inventario de algún personaje.

Como el tamaño del mundo se fijó en la Etapa 2, en esta etapa se le indica claramente al modelo que no debe agregar ubicaciones ni elementos nuevos que no formen parte del esqueleto existente. Esta medida surgió como respuesta a un patrón observado en experimentos preliminares, donde el modelo tendía a expandirse más allá del alcance definido e incluir contenido adicional.

Adicionalmente, establecimos reglas obligatorias de conexión entre ubicaciones. Si la ubicación A conecta con B, entonces B debe conectar con A, evitando conexiones unidireccionales accidentales que podrían atrapar al jugador. Todas las ubicaciones deben ser accesibles desde cualquier punto del mundo, sin ubicaciones aisladas o grupos desconectados. Finalmente, el objetivo debe ser completable con los elementos creados, existiendo al menos una ruta lógica desde el estado inicial hasta su consecución.

Diseñamos reglas para garantizar la consistencia funcional. Los personajes con capacidad de interacción deben contar con texto de interacción definido, y todo objeto en su inventario debe existir en la lista global de objetos, evitando referencias inexistentes. Los objetos necesarios para cumplir el objetivo principal deben ser obtenibles (\textit{gettable: true}), mientras que los decorativos pueden no serlo. Cada objeto debe tener una justificación clara: funcional (parte de un puzle o requisito del objetivo) o atmosférica (contribuyendo a la ambientación).

Incorporamos en el prompt una lista de verificación que el modelo debe ejecutar antes de finalizar la generación: todas las ubicaciones deben ser accesibles desde la ubicación inicial, el jugador debe poder completar el objetivo con los elementos disponibles, debe existir al menos una ruta de solución desde el estado inicial, todos los elementos referenciados deben existir efectivamente, y en objetivos de tipo misterio, cada pista debe estar asociada a un objeto físico existente.

El resultado es una estructura funcional pero lineal, enfocada exclusivamente en la ruta principal hacia el objetivo. El mundo en este punto (es decir, el mundo generado en la Etapa 3) es jugable y completable, aunque aún carece de los puzles y pasajes bloqueados que añadirán complejidad en la siguiente etapa.

\subsubsection{Etapa 4: Los Desafíos}

Con el mundo base establecido, esta etapa introduce complejidad mediante pasajes bloqueados (conexiones entre ubicaciones que requieren condiciones específicas para desbloquearse) y puzles (desafíos clasificados según la taxonomía presentada en la Sección \ref{subsec:clase_puzzle} que obstaculizan el progreso).

El modelo analiza el mundo generado e identifica puntos estratégicos donde insertar estos obstáculos, asegurando que existan soluciones viables y coherentes con la narrativa. El prompt para esta etapa se encuentra en el Anexo \ref{anexo:prompts}, Sección \ref{anexo:prompt_step4}.

Inicialmente, diseñamos esta etapa con la ambición de crear cadenas de dependencias complejas (\textit{dependency chains}): secuencias lógicas de tareas interdependientes donde completar una etapa desbloquea la siguiente. La visión era que, por ejemplo, para obtener el objetivo final, el jugador primero necesitaría la Llave A, que solo obtendría del Personaje B, quien la entregaría a cambio del Objeto C, que a su vez requeriría resolver el Puzle D en la Ubicación E.

Sin embargo, al hacer experimentos preliminares esta estructura demostró ser problemática. El modelo fallaba consistentemente al generar estas cadenas, produciendo mundos con errores estructurales graves (p. ej.: dependencias circulares imposibles de resolver donde A requiere B, B requiere C y C requiere A; referencias a objetos que no existían en los inventarios correctos; o generaciones sin sentido donde las relaciones de dependencia no tenían lógica coherente).

Al analizar estos fallos, comprendimos que el problema radicaba en la complejidad creciente del esquema del mundo. Con cada característica que añadíamos (p. ej.: cadenas de dependencias, múltiples tipos de puzles, diversos tipos de objetivos, validaciones cruzadas), el modelo de datos se volvía más intrincado y las restricciones más numerosas. El modelo simplemente no podía mantener toda esta información en contexto mientras generaba salidas estructuralmente válidas.

Esto nos obligó a tomar decisiones difíciles de diseño. Descartamos la implementación formal de estructuras de cadenas de dependencias; sin embargo, este no fue el único recorte. Como se detalló en las Secciones \ref{subsec:clase_puzzle} y \ref{subsec:clase_objective}, también tuvimos que reducir la cantidad de tipos de objetivos y tipos de puzles que inicialmente habíamos planificado. La complejidad del esquema era el cuello de botella fundamental del sistema, y solo mediante simplificación estratégica pudimos lograr generaciones consistentes y jugables.

Aunque descartamos la implementación formal de cadenas de dependencias, decidimos mantener esa filosofía dentro del prompt. Explicar al modelo la generación de puzles como un ``hilo conductor lógico'' donde cada desafío está motivado por el anterior resultó mucho más efectivo que simplemente pedirle ``añadir puzles al mundo'': los resultados eran más coherentes, mejor integrados narrativamente y con una progresión más natural.

El prompt enfatiza la conexión entre cada puzle y un pasaje bloqueado o recurso esencial para avanzar, evitando la aparición de desafíos sin consecuencias mecánicas claras. Para reforzar esta coherencia, establecimos reglas específicas: todo pasaje bloqueado debe tener un obstáculo definido y un requisito concreto para desbloquearlo; los obstáculos y sus soluciones deben estar físicamente separados (p. ej.: no colocar la llave junto a la puerta que abre); y las soluciones deben poder descubrirse a través de la exploración.

Durante las primeras pruebas observamos puzles excesivamente complejos, donde el jugador podía quedar bloqueado sin una vía clara de avance. Para resolverlo, implementamos un sistema obligatorio de pistas asociado a cada puzle, compuesto por tres a cinco pistas progresivas (\textit{puzle\_hints}) que van desde una orientación general hasta una ayuda casi explícita. La efectividad de este sistema motivó la creación de pistas para los objetivos, con el fin de mantener coherencia en la asistencia ofrecida al jugador. Más adelante surgió la idea de extender este enfoque a situaciones en las que el jugador se encontrara en una ubicación con un puzle aún no iniciado, naciendo así la pista de interacción (\textit{interaction\_hint}): una sugerencia breve que orienta al jugador sobre cómo comenzar la acción (por ejemplo: ``intenta hablar con [personaje]'', ``examina [objeto]'', ``busca pistas en esta ubicación''). Este enfoque consolidó un sistema de ayuda más orgánico y adaptativo, que se integra con el mecanismo general que se describirá en la Sección \ref{sec:sistema_hints} del Capítulo \ref{cap:implementacion}.

En esta etapa se mantuvieron las mismas restricciones técnicas definidas en la Etapa 3, que limitan la capacidad del modelo para alterar la estructura del mundo: no se permite crear nuevas ubicaciones, deben preservarse las rutas de conectividad global entre ellas, y se prohíben mecánicas de combinación o transformación de objetos, dado que el motor del juego no las soporta. Adicionalmente, si un puzle otorgado por un personaje incluye una recompensa física, el objeto correspondiente debe existir previamente y encontrarse en el inventario de dicho personaje.

Sobre esta base, el modelo cuenta con cierta libertad para realizar una redistribución estratégica de los objetos del mundo, con el fin de ajustar la dificultad y el equilibrio narrativo. Esto implica poder mover elementos relevantes a ubicaciones menos accesibles o asignarlos a personajes que los entreguen mediante intercambio, siempre que la modificación mantenga coherencia lógica y motivación narrativa dentro del contexto del mundo.

El resultado de esta etapa es un mundo con obstáculos estratégicamente distribuidos que hacen la experiencia más desafiante. Aunque no implementamos cadenas de dependencias formales, los puzles generados mantienen coherencia narrativa y progresión lógica gracias a la filosofía de diseño preservada en el prompt.

\subsubsection{Etapa 5: Expansión del Mundo (Opcional)}

La etapa final enriquece el mundo con contenido extra que incrementa la inmersión: ubicaciones secundarias que no son necesarias para completar el objetivo, personajes complementarios con narrativas propias, objetos decorativos o de utilidad marginal, y rutas alternativas que permiten exploración lateral.

Esta expansión se realiza respetando la coherencia lógica y espacial del mundo establecido en las etapas anteriores.

Esta quinta etapa es opcional. Durante la etapa de testing interno, evitamos esta etapa del pipeline para garantizar que los mundos generados cumplieran exactamente con los parámetros de tamaño especificados en la configuración inicial. La inclusión de esta etapa puede resultar en mundos que excedan las cantidades configuradas, lo cual puede ser deseable para aumentar la riqueza del contenido, pero puede no ser adecuado cuando se requiere control preciso sobre las dimensiones del mundo (por ejemplo, en evaluaciones comparativas o estudios de rendimiento). La decisión de incluir o no ejecutar esta etapa debe tomarse en función de los objetivos específicos de cada caso de uso: mayor control y predictibilidad (sin expansión) versus mayor profundidad y contenido exploratorio (con expansión).

\section{Sistema de Validación} \label{sec:validaciones}

El sistema de validación actúa como salvaguarda crítica entre las etapas del pipeline, verificando que los mundos generados sean estructuralmente válidos y jugables antes de continuar con la siguiente fase o entregar el mundo al jugador.

\subsection{Arquitectura de Validación Multinivel}

Las validaciones se ejecutan en puntos específicos del pipeline, aprovechando que cada etapa tiene responsabilidades claramente delimitadas:

\begin{itemize}
    \item \textbf{Etapa 2}: Validación de esquema más verificación de tamaños configurados
    \item \textbf{Etapa 3}: Validación de esquema más conectividad de ubicaciones (mediante búsqueda en profundidad) más completabilidad del objetivo
    \item \textbf{Etapa 4}: Validación de esquema más recompensas de puzles más re-validación de conectividad y completabilidad
\end{itemize}

Si cualquier validación falla, se descarta la generación y se reintenta la etapa correspondiente. El sistema implementa un máximo de tres intentos por etapa; tras agotarlos, el pipeline completo falla con una excepción descriptiva que indica qué validación específica no pudo ser satisfecha.

\subsection{Tipos de Validación}

Esta validación verifica que la salida del modelo de lenguaje cumpla con la estructura de datos esperada, incluyendo tipos correctos y presencia de campos obligatorios. La implementación mediante modelos estructurados (que se describirá en detalle en el Capítulo \ref{cap:implementacion}) permite rechazar automáticamente salidas mal formadas antes de que lleguen al motor del juego.

Implementada mediante búsqueda en profundidad (DFS) sobre el grafo de ubicaciones, esta validación detecta particiones en el mundo. Construimos un diccionario de adyacencia que incluye tanto conexiones normales como pasajes bloqueados (que son conexiones estructuralmente presentes, solamente que temporalmente inaccesibles), ejecutamos DFS desde la primera ubicación y comparamos el conjunto de nodos visitados contra el conjunto total de ubicaciones. Si detectamos ubicaciones no alcanzables, se registra información detallada con la lista de ubicaciones aisladas y el mapa de adyacencia completo para facilitar el diagnóstico.

Esta validación verifica que el objetivo sea alcanzable con los elementos disponibles en el mundo. Para cada tipo de objetivo se realizan verificaciones específicas, como se describió en la Sección \ref{subsec:clase_objective}. Por ejemplo, para \verb|GET_ITEM| se verifica que el objeto exista, esté ubicado en algún lugar accesible y tenga la propiedad \verb|gettable=True|.

A diferencia de las validaciones anteriores que rechazan mundos inválidos, la verificación de recompensas de puzles implementa una estrategia de reparación. Si un puzle otorga como recompensa un objeto que no existe en el mundo, el sistema lo crea automáticamente y lo coloca en el inventario del personaje que propone el puzle (o en la ubicación del puzle si es ambiental). Esta heurística refleja una observación del desarrollo: cuando el modelo menciona un objeto recompensa inexistente, generalmente es una omisión coherente con la narrativa, no un error conceptual fundamental. Crear el objeto permite continuar la generación en lugar de rechazar todo el mundo.

\subsection{Estrategias Diferenciadas: Corrección vs. Rechazo}

El sistema aplica estrategias diferentes según el tipo de error detectado. Las recompensas faltantes en puzles se corrigen automáticamente, mientras que los objetivos imposibles causan rechazo y reintento completo de la etapa. Esta asimetría refleja diferencias en criticidad: los puzles son problemas localizados que pueden repararse sin comprometer la estructura general del mundo, mientras que los objetivos imposibles invalidan completamente la jugabilidad. Los detalles de implementación de estas estrategias se presentan en la Sección \ref{sec:orquestacion_pipeline} del Capítulo \ref{cap:implementacion}.

Sin embargo, esta estrategia de rechazo para objetivos presenta una limitación fundamental: si el modelo es consistentemente inconsistente (generando repetidamente objetivos con objetos que no incluye en la lista de elementos del mundo), los tres reintentos fallarán y el pipeline completo fallará. La validación \verb|verify_objective_completability()| detecta correctamente estos problemas, pero no puede corregirlos automáticamente como sí hace \verb|verify_puzzle_rewards_and_fix()| con los puzles. El modelo puede omitir un objeto importante del objetivo en \verb|world.items| aunque lo referencie en \verb|objective.components|, y las instrucciones del prompt no siempre son suficientes para prevenir esta inconsistencia.

Como se discutirá en el Capítulo \ref{cap:evaluacion}, esta fragilidad resultó en algunos mundos que, tras agotar los reintentos, pasaron las validaciones pero presentaron problemas sutiles durante el juego real, evidenciando que la validación post-generación no puede compensar completamente la inconsistencia inherente del modelo durante la generación.

\section{Conclusiones del Capítulo}

Este capítulo presentó el diseño y arquitectura del sistema de generación automática de mundos interactivos. Describimos la estructura de clases que define los elementos básicos del mundo y sus relaciones explícitas, el pipeline de generación incremental que descompone la creación en cinco etapas manejables, y el sistema de validación multinivel que garantiza la jugabilidad de los mundos resultantes.

Los conceptos y estructuras presentados aquí constituyen el modelo conceptual del sistema. En el siguiente capítulo abordaremos cómo estos diseños se materializan mediante tecnologías específicas: la integración con modelos de lenguaje mediante esquemas estructurados, el ciclo de juego que combina generación narrativa con mecánicas simbólicas, el sistema de memoria persistente con recuperación aumentada, la persistencia de trazas para reproducibilidad, y la interfaz de usuario que permite a los jugadores interactuar con los mundos generados.


\chapter{Implementación y Tecnologías} \label{cap:implementacion}

En el capítulo anterior presentamos el modelo conceptual del sistema: la estructura de clases, el pipeline de generación incremental y el sistema de validación. Este capítulo describe cómo materializamos ese diseño usando Python, modelos de lenguaje y bases de datos especializadas.

Es importante recordar que el sistema PAYADOR está construido usando Python como ingrediente base, y que estamos expandiendo sus capacidades. PAYADOR fue diseñado de manera minimalista para ser expandible, y nuestra implementación se beneficia de esa arquitectura. Mientras que el capítulo anterior se enfocó en el \textit{qué} y el \textit{por qué}, este capítulo se enfoca en el \textit{cómo}: las bibliotecas, herramientas y técnicas específicas que permiten que el diseño funcione en la práctica.

Los componentes de implementación que abordaremos son:

\begin{itemize}
    \item \textbf{Integración con modelos de lenguaje}: Uso de la biblioteca Pydantic para garantizar salidas estructuradas del modelo, validaciones automáticas y manejo de errores.
    \item \textbf{Orquestación del pipeline}: La función \verb|create_world_incrementally()| que coordina la ejecución secuencial de las cinco etapas, con sistema de reintentos y validaciones intermedias.
    \item \textbf{Lógica de juego y ciclo de interacción}: El game loop que combina generación narrativa del modelo con intervenciones deterministas del sistema simbólico.
    \item \textbf{Sistema de memoria con RAG}: Implementación de memoria episódica persistente usando embeddings de Gemini y ChromaDB como base vectorial.
    \item \textbf{Persistencia de trazas con MongoDB}: Serialización completa del estado del mundo para reproducibilidad y análisis.
    \item \textbf{Interfaz de usuario con Streamlit}: Implementación de la interfaz web que permite a los jugadores interactuar con los mundos generados.
    \item \textbf{Estrategias de prompting}: Diseño de prompts especializados por función y manejo robusto de errores de API.
\end{itemize}

A continuación detallaremos cada uno de estos componentes.

\section{Integración con Modelos de Lenguaje}

\subsection{Modelos Estructurados con Pydantic}

La integración con modelos de lenguaje es uno de los desafíos centrales del enfoque neurosimbólico, y en particular porque IVIE presenta requisitos que no satisface PAYADOR, que fue construido lo más minimal posible para ser expandido. Necesitamos que el modelo de lenguaje genere mundos jugables, pero la salida en lenguaje natural no garantiza la coherencia estructural requerida por el motor del juego, lo cual implica una dificultad técnica significativa. Resolvemos esto usando los modelos de lenguaje junto a la biblioteca Pydantic\footnote{Pydantic es una biblioteca de Python para validación de datos usando anotaciones de tipo. Define ``modelos'' que son clases Python con campos tipados y reglas de validación. Ver: \url{https://docs.pydantic.dev/latest/concepts/models/}}, para que su salida respete una estructura determinada.

Los modelos de lenguaje modernos pueden generar salidas estructuradas en JSON cuando se les solicita explícitamente en el prompt, pero sin validación automática esto resulta frágil: el modelo puede omitir campos, usar tipos incorrectos, o generar estructuras mal formadas. Implementamos modelos Pydantic que definen esquemas tipados con validaciones embebidas. Cuando el modelo genera una salida que no cumple con el esquema, Pydantic rechaza automáticamente la estructura antes de que llegue al motor del juego, aunque es importante aclarar que Pydantic no reintenta autónomamente la llamada al modelo de lenguaje; esa responsabilidad recae en la lógica del pipeline que describiremos más adelante.

La arquitectura de modelos sigue la jerarquía del mundo de juego. En el nivel superior tenemos \verb|GeneratedWorld|, que encapsula listas de ubicaciones generadas (\verb|List[GeneratedLocation]|), objetos generados (\verb|List[GeneratedItem]|), puzles generados (\verb|List[GeneratedPuzzle]|), el personaje del jugador (\verb|GeneratedCharacter|), y el objetivo principal (\verb|GeneratedObjective|). Todos estos son modelos Pydantic especializados.

Definimos enumeraciones para tipos de entidades críticas, forzando al modelo a usar valores válidos. Por ejemplo, \verb|ItemActionType| es una enumeración que restringe las acciones de objetos a cuatro categorías que el motor puede procesar: \verb|UNLOCK_PASSAGE| para llaves, \verb|SOLVE_PUZZLE| para pistas, \verb|GIVE_TO_CHARACTER| para entregas y \verb|LORE| para elementos decorativos. Esto elimina la ambigüedad que observamos en experimentos preliminares donde el modelo generaba nombres de acciones que el motor no reconocía.

Similarmente, \verb|ObjectiveType| restringe los objetivos a cinco tipos implementados: \verb|GET_ITEM|, \verb|REACH_LOCATION|, \verb|FIND_CHARACTER|, \verb|DELIVER_AN_ITEM| y \verb|SOLVE_MYSTERY|. Cada tipo tiene lógica de verificación específica en el motor, y el uso de enumeraciones garantiza que no se generen objetivos no soportados.

Los modelos Pydantic incorporan reglas de coherencia mediante descripciones de campos que actúan como especificación para el modelo de lenguaje. Por ejemplo, \verb|GeneratedItem| tiene el campo:

\begin{verbatim}
is_objective_target: bool = Field(
    default=False, 
    description="Whether this item is required to complete the 
                 main objective. Note: objective targets must 
                 always be gettable=True"
)
\end{verbatim}

Esta descripción instruye al modelo sobre la relación entre \verb|is_objective_target| y \verb|gettable|, funcionando como reglas adicionales fuera del prompt principal. Observamos que incluir estas anotaciones explícitas en las descripciones reduce significativamente errores de coherencia interna en la salida del modelo de lenguaje.

Un caso más complejo es \verb|GeneratedLocation.items|, cuya descripción advierte: \textit{``An item required to unlock a passage CANNOT be placed in the location behind that very passage or any location only accessible through it''}. Esta regla intenta prevenir configuraciones imposibles donde la llave está del otro lado de la puerta que debe abrir, aunque es importante aclarar que esto es una instrucción para guiar al modelo, no una verificación automática de Pydantic.

Para puzles implementamos un sistema de recompensas tipadas mediante herencia de Pydantic. \verb|PuzzleReward| es la clase base con \verb|reward_type: RewardType|, y las subclases especializan el comportamiento: \verb|PassageReward| desbloquea un pasaje entre dos ubicaciones existentes, \verb|ItemReward| otorga un objeto del mundo al inventario del jugador, y \verb|ObjectiveReward| marca el objetivo principal como completado.

Esta jerarquía le permite al motor aplicar la recompensa correcta automáticamente mediante polimorfismo, y al modelo de lenguaje generar recompensas válidas sin necesidad de instrucciones complejas en los prompts.

Los esquemas documentan explícitamente las restricciones de referencia mediante anotaciones en las descripciones. Por ejemplo, \verb|GeneratedPuzzle.proposed_by_character| especifica: \textit{``Note: if specified, this character must exist in the world''}. Si bien Pydantic no valida estas referencias automáticamente (requeriría acceso al contexto del mundo completo durante el parsing), estas anotaciones cumplen dos funciones: instruyen al modelo sobre la restricción durante la generación, y documentan las validaciones que luego ejecutamos explícitamente en el pipeline de generación.

Estas validaciones post-parsing incluyen verificar conectividad bidireccional de ubicaciones, existencia de objetos referenciados en inventarios, y validez de las relaciones de dependencia. Las implementamos en funciones especializadas (descritas en la Sección \ref{sec:validaciones} del capítulo anterior) que rechazan mundos con referencias a objetos que no existen en el sistema orientado a objetos.

Para soportar la generación en etapas implementamos modelos intermedios. \verb|WorldConcept| captura solamente el concepto inicial (título, historia de fondo, concepto del jugador, objetivo general), y \verb|WorldSkeleton| define las entidades clave mediante \verb|KeyEntity| (nombre más propósito) sin detalles completos. Esto permite que cada etapa del pipeline genere y valide su salida antes de pasar al siguiente.

El módulo \verb|world_builder.py| traduce instancias de \verb|GeneratedWorld| a objetos del motor (\verb|World|, \verb|Location|, \verb|Item|, entre otros). Este proceso incluye resolución de nombres a referencias de objetos, establecimiento de conexiones bidireccionales y validación de la jugabilidad del mundo resultante. Como se mencionó en el Capítulo \ref{cap:diseno}, la separación entre modelos de generación (Pydantic) y la representación estructurada del motor (clases Python tradicionales, es decir, el estado simbólico) mantiene las responsabilidades claras. Mientras que Pydantic valida la estructura de la salida del modelo de lenguaje, el motor implementa la lógica de juego.

\subsection{Orquestación del Pipeline y Sistema de Reintentos} \label{sec:orquestacion_pipeline}

Ahora que el contexto de PAYADOR está definido mediante las estructuras de clases presentadas en el Capítulo \ref{cap:diseno}, y que hemos explicado cómo Pydantic valida la estructura de las salidas del modelo de lenguaje, podemos describir cómo se orquesta la ejecución del pipeline completo.

La función \verb|create_world_incrementally()| coordina la ejecución secuencial de las cinco etapas del pipeline, manteniendo una única instancia del modelo de lenguaje y solicitando estructuras Pydantic específicas en cada etapa. Para cada etapa del pipeline, es importante tener en cuenta cuál era su propósito según lo definido en la Sección \ref{sec:pipeline}:

\begin{itemize}
    \item \textbf{Etapa 1} (Concepto del mundo): Genera título, backstory, concepto del jugador y objetivo
    \item \textbf{Etapa 2} (Esqueleto): Identifica entidades clave con cantidades configuradas
    \item \textbf{Etapa 3} (Mundo jugable): Materializa el esqueleto con detalles y conexiones
    \item \textbf{Etapa 4} (Desafíos): Introduce puzles y pasajes bloqueados
    \item \textbf{Etapa 5} (Expansión opcional): Enriquece con contenido adicional
\end{itemize}

Implementamos un sistema de reintentos con un máximo de tres intentos por etapa, ejecutando validaciones específicas según la etapa. Para la Etapa 2, validamos el esquema Pydantic más la verificación de tamaños configurados. Para la Etapa 3, validamos el esquema Pydantic más conectividad de ubicaciones mediante búsqueda en profundidad más completabilidad del objetivo. Para la Etapa 4, validamos el esquema Pydantic más recompensas de puzles más re-validación de conectividad y completabilidad.

Si cualquier validación falla, se descarta la generación y se reintenta la etapa. Escribimos fluidamente la lógica: el sistema registra el error específico, incrementa el contador de intentos y regenera desde el modelo de lenguaje. Tras tres intentos fallidos, el pipeline completo falla con excepción descriptiva.

Las recompensas faltantes en puzles se corrigen automáticamente dentro del intento actual mediante una función especializada, permitiendo recuperar mundos con omisiones menores. Por otro lado, los objetivos imposibles causan rechazo y reintento completo de la etapa. Esta asimetría refleja diferencias en criticidad: cuando un puzle presenta un error estructural, el sistema puede corregirlo localmente; en cambio, cuando un objetivo es imposible de completar, el mundo completo se vuelve injugable y debe regenerarse.

Sin embargo, esta estrategia de rechazo para objetivos presenta una limitación fundamental: si el modelo es consistentemente inconsistente (generando repetidamente objetivos con objetos que no incluye en la lista de elementos del mundo), los tres reintentos fallarán y el pipeline fallará. La validación \verb|verify_objective_completability()| detecta correctamente estos problemas, pero no puede corregirlos automáticamente como sí hace \verb|verify_puzzle_rewards_and_fix()| con los puzles (volveremos a esto más adelante, al detallar la clase Puzzle en el contexto de implementación). El modelo puede omitir un objeto importante del objetivo en \verb|world.items| aunque lo referencie en \verb|objective.components|, y las instrucciones del prompt no siempre son suficientes para prevenir esta inconsistencia.

Como se discutirá en el Capítulo \ref{cap:evaluacion}, esta fragilidad resultó en algunos mundos que, tras agotar los reintentos, pasaron las validaciones pero presentaron problemas sutiles durante el juego real, evidenciando que la validación post-generación no puede compensar completamente la inconsistencia inherente del modelo durante la generación.

Implementamos serialización completa del estado usando la biblioteca jsonpickle, guardando el mundo en el turno 0 con todas las referencias de objetos. Un \textbf{turno} representa una iteración completa del ciclo de juego: el par formado por la acción del jugador y la respuesta del sistema. El \textbf{turno 0} es especial porque representa el estado inicial del mundo antes de cualquier interacción del jugador, incluyendo la narración inicial que describe la escena de apertura. Este JSON permitió detectar inconsistencias que no eran inmediatamente visibles durante el juego (puzles existentes pero no presentados, recompensas mencionadas pero no estructuradas). Por ejemplo, identificamos casos donde un objeto faltaba en \verb|world.items| pese a estar en \verb|objective.components|, lo cual era invisible durante el juego pero inmediato al inspeccionar el JSON.

Tras la Etapa 4, se verifica tamaño del mundo, conectividad y completabilidad del objetivo. Si estas validaciones finales fallan, se emiten advertencias pero no se rechaza el mundo porque ya se alcanzó el límite de intentos. En la práctica, estas validaciones rara vez fallan si las validaciones intermedias fueron exitosas, ya que los problemas críticos habrán sido detectados y corregidos en etapas anteriores.

\section{Lógica de Juego y Ciclo de Interacción} \label{sec:logica_juego}

Es importante explicar por qué el ciclo de interacción (game loop) es necesario antes de describirlo. Un ciclo de juego coordina la secuencia repetitiva de acciones que constituyen la experiencia del jugador: recibir entrada, procesarla, actualizar el estado del mundo, generar retroalimentación narrativa y verificar condiciones de victoria o derrota. Sin este ciclo, el sistema no podría mantener coherencia entre turnos ni gestionar la progresión del jugador hacia el objetivo.

La lógica de juego implementa un ciclo que combina generación narrativa del modelo de lenguaje con intervenciones deterministas del sistema simbólico. Este enfoque busca generar un equilibrio, aprovechando la potencial capacidad del modelo para generar narrativas que puedan percibirse como ricas y creativas. Además, busca también responder a acciones impredecibles del jugador sin dejarlo completamente responsable de las mecánicas críticas del juego que, como observamos durante el desarrollo, frecuentemente olvida o ejecuta incorrectamente.

\subsection{Ciclo Básico de Interacción}

El \verb|game_loop| procesa cada acción del jugador mediante una secuencia de seis pasos coordinados. En primer lugar, detecta comandos especiales que describiremos en la Sección \ref{sec:acciones_rapidas}. A continuación, procesa la acción estructuradamente generando un \verb|WorldUpdate| que contiene las transformaciones a aplicar al mundo. Posteriormente, aplica los cambios mediante \verb|world.update_from_structured()|. El siguiente paso consiste en generar narrativa usando un segundo modelo de lenguaje especializado en narración. Luego verifica la completitud del objetivo para determinar si el jugador ha ganado. Finalmente, presenta la narrativa al jugador junto con el estado formateado del mundo.

Es importante aclarar que ``segundo modelo de lenguaje'' se refiere a una segunda instancia o configuración del mismo modelo base, no necesariamente a un modelo arquitectónicamente diferente. Esta separación permite usar prompts y parámetros especializados para cada tarea: uno optimizado para razonamiento estructurado y otro para generación narrativa fluida.

En la descripción anterior mencionamos \verb|WorldUpdate|, que representa las transformaciones que el modelo de lenguaje propone aplicar al mundo basándose en la acción del jugador. También mencionamos el estado formateado del mundo, que es una representación textual del estado simbólico actual (p. ej.: ubicación del jugador, inventario, objetos visibles, personajes presentes, puzles activos) que se incluye en el prompt para que el modelo tenga contexto completo al generar respuestas.

\subsection{Acciones Rápidas (Quick Actions)} \label{sec:acciones_rapidas}

Implementamos acciones que responden sin invocar al modelo de lenguaje, procesándose directamente mediante lógica simbólica del sistema. Estas acciones rápidas mejoran la experiencia del usuario al proporcionar respuestas instantáneas para consultas comunes:

\begin{itemize}
    \item \textbf{Ver objetivo}: Muestra \verb|objective.description| directamente desde la estructura del mundo, con progreso de pistas descubiertas para objetivos de tipo misterio (por ejemplo: ``2 de 4 pistas descubiertas'')
    \item \textbf{Solicitar ayuda}: Activa el sistema de hints adaptativo que describiremos en la Sección \ref{sec:sistema_hints}
    \item \textbf{Inspeccionar mundo} (modo desarrollo): Muestra estadísticas del grafo de ubicaciones y puzles, útil para verificar la estructura generada
    \item \textbf{Resumen} (modo desarrollo): Lista todas las ubicaciones con sus conexiones e inventarios, proporcionando una vista completa del estado del mundo
\end{itemize}

Las acciones de desarrollo (inspeccionar y resumen) son funciones lógicas rutinarias que el sistema ejecuta para proporcionar información de depuración. Estas herramientas fueron esenciales durante el desarrollo porque nos permitieron verificar rápidamente si el pipeline había generado mundos estructuralmente válidos sin necesidad de jugarlos completamente.

\subsection{Sistema de Pistas Adaptativo} \label{sec:sistema_hints}

El sistema de pistas adaptativo ajusta dinámicamente las sugerencias según la situación inmediata del jugador, implementado mediante \verb|world.update_hints()|. Este sistema opera de la siguiente manera: cuando el jugador está en una ubicación donde no hay puzles presentes, ofrece pistas relacionadas con el objetivo principal (\verb|objective_hints|); si hay un puzle en la ubicación pero aún no ha sido presentado al jugador, usa la pista de interacción (\verb|interaction_hint|) que sugiere cómo comenzar la acción (p. ej.: ``intenta hablar con el guardián'' o ``examina la inscripción en la pared''); una vez que el puzle ha sido presentado al jugador pero no resuelto, cambia automáticamente a las pistas específicas de ese puzle (\verb|puzzle_hints|).

Las pistas están siempre en cantidad de tres y se entregan en orden ascendente de especificidad, proporcionando ayuda progresiva. El sistema rastrea qué pistas han sido entregadas mediante un atributo \verb|given| en cada pista. El mecanismo se actualiza automáticamente cuando el jugador cambia de ubicación, cuando se propone un puzle, o cuando se resuelve un puzle.

\subsection{Intervenciones Deterministas del Sistema}

Todas estas verificaciones ilustran una característica fundamental de nuestro enfoque neurosimbólico: mientras que el modelo de lenguaje interpreta las intenciones en la entrada del jugador y genera texto narrativo (tareas con un alto nivel de subjetividad), el sistema maneja mecánicas deterministas y validaciones específicas (tareas con un alto nivel de objetividad).

Implementamos intervenciones simbólicas para mecánicas críticas donde confiar en el modelo de lenguaje resultó poco confiable:

\begin{itemize}
    \item \textbf{Proposición forzada de puzles}: Si la entrada del jugador menciona a un personaje que tiene un puzle asociado, el sistema intercepta la acción y narra automáticamente la proposición del puzle usando el texto predefinido, sin consultar al modelo
    \item \textbf{Entrega automática de recompensas}: Cuando el jugador resuelve un puzle, la función \verb|_apply_puzzle_rewards| verifica las recompensas estructuradas y mueve automáticamente los objetos al inventario del jugador
    \item \textbf{Desbloqueo automático de pasajes}: Los pasajes bloqueados que requieren condiciones cumplidas se desbloquean automáticamente sin necesidad de que el modelo lo genere en la narración
    \item \textbf{Descubrimiento de pistas de misterio}: Para objetivos de tipo misterio, el sistema analiza la narración generada y, si detecta interacción con un objeto asociado a una pista, marca automáticamente la pista como descubierta
\end{itemize}

\subsection{Verificación de Completitud del Objetivo}

La función \verb|check_objective_completion| evalúa en cada turno si el objetivo ha sido alcanzado, con verificaciones específicas por tipo de objetivo. Por ejemplo, para \verb|GET_ITEM|, verifica que el objeto objetivo esté en el inventario del jugador; para \verb|REACH_LOCATION|, verifica que la ubicación actual del jugador coincida con la ubicación objetivo. Para \verb|FIND_CHARACTER|, verifica que el jugador esté en la misma ubicación que el personaje objetivo. Para \verb|DELIVER_AN_ITEM|, verifica que el objeto haya sido entregado al destinatario correcto. Para \verb|SOLVE_MYSTERY|, verifica que todas las pistas hayan sido descubiertas.

Al completarse el objetivo, el sistema presenta la narración de cierre (ya sea \verb|completion_narration| para objetivos estándar o \verb|mystery_solution| para objetivos de misterio) y registra el éxito en el log de la partida. La detección de completitud es puramente simbólica, basándose en verificaciones del estado estructurado del mundo, no en interpretaciones del modelo de lenguaje que podrían ser ambiguas o incorrectas.

Esta sección sobre el ciclo de juego es fundamental porque conecta todos los componentes del sistema: recibe mundos generados por el pipeline, los mantiene actualizados mediante transformaciones validadas, consulta al modelo para narrativa, y verifica mecánicas mediante lógica determinista. A continuación describiremos cómo el sistema mantiene memoria de eventos pasados para enriquecer las narraciones.

\section{Sistema de Memoria Persistente con RAG}

Los modelos de lenguaje son fundamentalmente sin estado: cada invocación recibe solamente el contexto del prompt actual y no tiene acceso a interacciones previas. Para narrativas interactivas largas esto representa un problema crítico: el jugador puede resolver un puzle, hablar con un personaje o descubrir información importante en el turno 5, pero para el turno 20 el modelo no tiene acceso a ese contexto a menos que lo incluyamos explícitamente en el prompt. Incluir todo el historial completo en cada prompt rápidamente excede los límites de longitud de contexto y aumenta significativamente los costos computacionales de cada invocación.

Para intentar resolver este problema, implementamos un sistema \textbf{RAG} (\textit{Retrieval-Augmented Generation}, Generación Aumentada por Recuperación) con memoria episódica. RAG es una técnica que combina recuperación de información con generación de texto: primero busca información relevante en una base de datos y luego la inyecta en el prompt del modelo para enriquecer su respuesta. Es importante aclarar que RAG no es un proceso simbólico sino estadístico, por lo que puede fallar. No obstante, consideramos que se justifica implementarlo porque el sistema simbólico por sí solo no puede mantener un historial narrativo coherente de todos los eventos pasados sin exceder los límites de longitud del prompt. RAG permite seleccionar los recuerdos más relevantes para cada acción, lo cual fue una diferencia notable con respecto a PAYADOR original, pero no con tanto impacto como esparábamos. Al final, la única utilidad que tuvo el RAG fue con respecto a la narración; el sistema es capaz de recordar eventos pasados y hacer alusión a ellos. Como veremos en la parte de experimentación, algunos jugadores destacaron esto como algo muy positivo.

\subsection{Arquitectura del Sistema de Memoria}

El sistema se compone de cuatro componentes que trabajan coordinadamente: \verb|AtomicMemory| como unidad básica de memoria, \verb|EmbeddingService| para generar representaciones vectoriales, \verb|MemoryStore| como base de datos vectorial persistente, y \verb|IntelligentMemorySystem| que coordina la ingestión y recuperación. La Figura \ref{fig:rag_overview} ilustra el proceso.

\begin{figure}
    \centering
    \includegraphics[width=0.75\linewidth]{figs/rag-overview.png}
    \caption{Vista general del sistema de recuperación de recuerdos relevantes}
    \label{fig:rag_overview}
\end{figure}

\verb|AtomicMemory| encapsula la información de un turno de juego: número de turno, acción del jugador, narración resultante, resumen del estado del mundo y timestamp. El término ``cada memoria'' en este contexto se refiere a una instancia de \verb|AtomicMemory| que representa un turno completo. Cada memoria puede serializarse a texto mediante \verb|to_text()| para generar embeddings, o a diccionario mediante \verb|to_dict()| para el almacenamiento en ChromaDB. La serialización a diccionario aplana metadatos a tipos primitivos (p. ej.: strings, ints, floats, bools) porque ChromaDB no soporta estructuras anidadas complejas en sus metadatos.

\verb|EmbeddingService| genera representaciones vectoriales densas usando el modelo de embeddings \verb|gemini-embedding-001| de Google. Configuramos el servicio con \verb|task_type="RETRIEVAL_DOCUMENT"| y \verb|output_dimensionality=768|, obteniendo embeddings de 768 dimensiones que capturan el significado semántico del texto. Aplicamos normalización L2 a los vectores resultantes como recomienda la documentación oficial de Gemini\footnote{\url{https://ai.google.dev/gemini-api/docs/embeddings}}, lo cual mejora la calidad de las búsquedas por similitud coseno.

La decisión de usar word embeddings por sobre métodos de búsqueda léxica tradicional (p. ej.: usando palabras clave, o el algoritmo BM25) permite recuperar memorias conceptualmente relevantes aunque no compartan términos exactos. El beneficio principal que observamos es relativo a la narración: cuando el sistema recupera eventos pasados relevantes, el modelo puede elaborar narraciones más coherentes con la historia acumulada del jugador.

\verb|MemoryStore| maneja la persistencia mediante ChromaDB, una base de datos vectorial diseñada para aplicaciones de embeddings. Creamos un \verb|PersistentClient| que escribe en disco (directorio \verb|gamelogs/memory_db|) para que las memorias persistan entre sesiones. Cada mundo de juego tiene su propia colección identificada por \verb|world_id|.

El método \verb|add_memory()| almacena exactamente tres elementos por cada memoria: el embedding vectorial para búsquedas de similitud, el documento de texto para recuperación legible, y los metadatos estructurados para filtrado y reconstrucción. Cada memoria recibe un ID único basado en turno y timestamp (\verb|turn_{turn_number}_{timestamp}|).

\verb|search_memories()| ejecuta búsquedas por similitud coseno usando un query embedding como entrada y devolviendo las top-k memorias más relevantes. ChromaDB ordena los resultados por score de similitud automáticamente, priorizando memorias semánticamente cercanas a la acción actual.

\subsection{Ingestión y Recuperación de Memorias}

\verb|IntelligentMemorySystem| orquesta el flujo completo. Durante la ingestión mediante \verb|ingest_memory()|, el sistema crea un \verb|AtomicMemory| con los datos del turno, genera su representación textual, computa el embedding mediante \verb|EmbeddingService|, almacena en \verb|MemoryStore| con el vector y metadatos, y actualiza el contador de último turno procesado.

La recuperación mediante \verb|retrieve_relevant_memories()| funciona inversamente: recibe la acción actual del jugador, genera su embedding, busca en ChromaDB las memorias más similares, y retorna objetos \verb|AtomicMemory| reconstruidos desde los metadatos almacenados. El método \verb|format_memories_for_prompt()| transforma estas memorias recuperadas en un formato de texto estructurado que puede inyectarse en el prompt del modelo de lenguaje.

\subsection{Resúmenes Contextuales Enriquecidos}

Para mejorar la calidad de los embeddings implementamos \verb|create_world_state_summary()| en \verb|world_utils.py|, que genera resúmenes ricos del estado del mundo en cada turno. En lugar de almacenar un resumen de las acciones del personaje del jugador (por ejemplo: ``el jugador tomó la llave''), capturamos:

\begin{itemize}
    \item La ubicación actual del personaje del jugador
    \item La descripción del lugar en que se encuentra (dada por el atributo ``Descriptions'' de su objeto), truncada a 100 caracteres para evitar embeddings excesivamente largos
    \item Objetos visibles en la ubicación
    \item Personajes presentes en la ubicación
    \item Inventario del jugador
    \item Objeto clave mencionado en la acción
    \item La acción textual completa del jugador
\end{itemize}

Este contexto adicional mejora la recuperación posterior: si el jugador pregunta sobre un personaje, el embedding de la memoria incluye información de dónde estaba ese personaje y qué objetos tenía disponibles.

\subsection{Integración con el Ciclo de Juego}

Integramos el sistema RAG en dos puntos del ciclo de turno en \verb|game_logic.py|. Antes de procesar la acción del jugador, llamamos a \verb|retrieve_relevant_memories()| con el input actual, obtenemos las top-3 memorias más relevantes y las formateamos para inclusión en el prompt mediante \verb|format_memories_for_prompt()|. El prompt utilizado (disponible en el Anexo \ref{anexo:prompts}) incluye una sección denominada ``Recuerdos Relevantes del Pasado'' (en inglés: ``Relevant Past Memories'', dependiendo del idioma de la partida) que precede al estado actual del mundo, con instrucciones explícitas al modelo de considerar esos eventos pasados al generar la respuesta.

Después de procesar exitosamente el turno, ejecutamos \verb|ingest_memory()| con el número de turno, acción del jugador, narración generada y resumen del estado del mundo. Esta ingestión post-turno asegura que cada memoria refleja el resultado final después de aplicar cambios estructurados al mundo, no predicciones intermedias.

\subsection{Consideraciones de Rendimiento}

El sistema tiene dos puntos de latencia: generación de embeddings (mediante llamadas a la API de Gemini) y búsquedas en ChromaDB. Los embeddings agregan menos de un segundo por turno, pero esto es aceptable porque sucede post-turno (una vez que el jugador ya vio la narración), de forma no bloqueante para la experiencia. Las búsquedas vectoriales en ChromaDB son rápidas incluso con cientos de memorias, típicamente de unos 50ms en total, porque usa índices optimizados para similitud coseno.

Un problema recurrente durante el desarrollo y evaluación fue el manejo de errores en la API de embeddings: si Gemini está temporalmente no disponible, el sistema genera un vector con todas sus entradas en cero como fallback. Esto degrada la calidad de búsquedas pero permite que el juego continúe. Una mejora futura sería implementar reintentos con exponential backoff (es decir, esperar un tiempo creciente entre reintentos duplicando la espera en cada intento: 1s, 2s, 4s, 8s) para la generación de embeddings, lo cual aumentaría la robustez del sistema ante fallos transitorios de la API.

\section{Persistencia de Trazas con MongoDB} \label{sec:mongodb}

El sistema de memoria RAG mantiene contexto semántico, pero para recuperar las partidas en su totalidad necesitamos persistir el estado exacto del mundo en cada turno. Implementamos un sistema de trazas con MongoDB que serializa toda la sesión de juego, permitiendo replay completo, análisis del comportamiento del modelo de lenguaje y depuración de problemas específicos.

\subsection{Arquitectura Singleton del Handler}

\verb|MongoHandler| implementa el patrón singleton para tener una única instancia de conexión a la base de datos compartida por todo el sistema. Durante la construcción, cargamos la configuración desde \verb|config.ini| y variables de entorno (\verb|MONGO_URI|). A continuación, creamos el cliente de PyMongo y seleccionamos cuál base de datos se usará y cuál colección (una colección de documentos de trazas de partidas). Finalmente, ejecutamos \verb|client.admin.command('ping')| para validar conectividad. Si la conexión falla, la instancia se deja como \verb|None| y se imprime el error, permitiendo que el sistema continúe sin persistencia.

\subsection{Estructura de Documentos de Traza}

Cada partida se almacena como un documento MongoDB con la siguiente estructura:

\begin{itemize}
    \item \verb|world_id|: Identificador único generado como \verb|"generated_{timestamp}"| al inicio de la sesión
    \item \verb|nickname|: Identificación del jugador, lo cual facilita la organización y análisis posterior de las trazas
    \item \verb|language|: Idioma de la partida (español o inglés)
    \item \verb|narrative_model_name|: Nombre del modelo usado para narración
    \item \verb|reasoning_model_name|: Nombre del modelo usado para razonamiento
    \item \verb|inspiration|: Tema o frase inspiradora si se usó el modo \texttt{inspiration} (vacío en otros modos)
    \item \verb|created_at|: Timestamp de creación de la partida
    \item \verb|turns|: Objeto anidado con turnos indexados numéricamente (0, 1, 2, ...)
\end{itemize}

Cada entrada en \verb|turns| es un subdocumento que captura el estado completo de ese turno: fecha/hora, input del usuario, estado simbólico del mundo pre-turno (serializado con jsonpickle), estado renderizado del mundo pre-turno en forma de texto legible para humanos, predicciones del modelo, cambios estructurados aplicados y narración resultante.

\subsection{Concepto de Turno}

Es importante definir qué es un turno en el contexto de nuestro sistema. Un turno representa una iteración completa del ciclo de juego: el par formado por la acción del jugador y la respuesta del sistema (que incluye tanto las transformaciones al mundo como la narración generada). Cada turno se identifica numéricamente comenzando desde 0.

El turno 0 es especial: captura \verb|initial_symbolic_world_state| (mundo completo serializado con \verb|jsonpickle.encode(world, unpicklable=True)|), \verb|initial_rendered_world_state| (representación textual para humanos) y opcionalmente \verb|starting_narration| (primera descripción de la escena). El turno 0 se representa de esta forma porque incluye la narración inicial, y permite recrear el mundo exactamente como estaba al inicio de la partida.

\subsection{Inicialización y Adición de Turnos}

\verb|initialize_trace()| inserta el documento base cuando comienza una nueva partida. Invocado desde \verb|create_game_loop()| después de generar el mundo, el método recibe un diccionario con metadatos de sesión y el turno 0. Usamos \verb|collection.insert_one()| y retornamos el \verb|inserted_id| de MongoDB, aunque este ID rara vez se usa posteriormente (preferimos buscar por el \verb|world_id| que es más semántico para nosotros).

\verb|add_turn_to_trace()| agrega turnos subsecuentes usando el operador \verb|$set| de MongoDB. En lugar de recuperar el documento completo, modificarlo en memoria y reescribirlo, usamos \verb|update_one()| con \verb|{"$set": {f"turns.{turn_number}": turn_data}}|. Esta notación con dot notation de MongoDB actualiza solo el subdocumento del turno específico, minimizando tráfico de red.

\subsection{Serialización con jsonpickle}

Usamos la biblioteca jsonpickle en lugar de JSON estándar para serializar el objeto \verb|World|. La \textbf{serialización completa} se refiere a convertir objetos Python complejos (con atributos, métodos y referencias entre objetos) en una representación de texto que preserve toda su información estructural. Python pickle puede serializar objetos arbitrarios con referencias circulares y métodos, pero genera formato binario no legible por humanos ni compatible con MongoDB. jsonpickle resuelve esto convirtiendo objetos Python a JSON agregando metadatos de tipo (como \texttt{"py/object"}) que permiten deserialización precisa, reconstruyendo el objeto original con toda su funcionalidad.

Configuramos dos modos: \verb|unpicklable=True| en el turno 0 incluye toda la información necesaria para reconstruir el objeto completo con métodos, usado por \verb|create_world_from_trace()| para cargar partidas guardadas. \verb|unpicklable=False| en turnos subsecuentes genera JSON más limpio sin metadatos de reconstrucción, suficiente para análisis y visualización pero no para ejecución.

\subsection{Recuperación y Análisis}

\verb|get_trace_by_world_id()| recupera el documento completo de una partida mediante \verb|find_one({"world_id": world_id})|. Este método es fundamental para el modo replay de la interfaz: permite al jugador ingresar un \verb|world_id| de partida previa y volver a jugarla o analizarla.

\verb|trace_exists()| verifica existencia sin transferir todo el documento, usando \verb|count_documents()| que retorna 0 o 1.

La integración entre MongoDB (almacenamiento estructurado completo) y ChromaDB (índice semántico) es lo que permite que el modo replay no solamente restaure el estado del mundo, sino también el contexto conversacional.

Un desafío que encontramos al analizar partidas con problemas fue que inicialmente se serializaba solo el estado renderizado como texto, lo cual era insuficiente para reproducir errores. Agregar serialización simbólica completa con jsonpickle nos permitió cargar el mundo exacto en el estado donde ocurrió cierto error y depurar interactivamente, lo cual fue crítico para diagnosticar comportamiento inesperado del modelo o del motor. Esto nos ofrece algo clave para el testing: la reproducibilidad. Sin embargo, implementamos esta funcionalidad en una etapa muy avanzada del desarrollo, y nos habría gustado tenerla desde mucho antes porque habría acelerado significativamente el proceso de identificación y corrección de errores.

\section{Estrategias de Prompting y Manejo de Errores}

La interacción con modelos de lenguaje mediante prompts representa tanto el punto de mayor flexibilidad como el de mayor fragilidad del sistema. Como se ha demostrado en algunos trabajos \cite{wei2022chain, brown2020language}, la forma en que se redacta el prompt puede llevar a un incremento sustancial en el desempeño del modelo.

\subsection{Jerarquía de Prompts Especializados}

Creamos una biblioteca que carga prompts que escribimos, basándose en su función y la fase del pipeline. Organizamos los prompts en tres categorías principales:

\begin{itemize}
    \item \textbf{Generación incremental}: Usadas en la Etapa 1 del pipeline (ver Anexo \ref{anexo:prompts}, Sección \ref{anexo:prompt_step1}), Etapa 2 (Sección \ref{anexo:prompt_step2}), Etapa 3 (Sección \ref{anexo:prompt_step3}), Etapa 4 (Sección \ref{anexo:prompt_step4}), y opcionalmente Etapa 5
    \item \textbf{Juego}: Prompts para actualización estructurada del mundo (p. ej.: \verb|prompt_world_update_structured|) y narración de escenas (p. ej.: \verb|prompt_narrate_current_scene|)
    \item \textbf{Utilidad}: Prompts para generar descripciones alternativas (p. ej.: \verb|prompt_describe_objective|)
\end{itemize}

Esta separación tiene como objetivo poder ajustar cada prompt independientemente según su contexto de uso. Por ejemplo, \verb|prompt_narrate_current_scene| incluye instrucciones tanto para cuando el jugador visita una ubicación por primera vez, como también para cuando vuelve a visitar una ubicación en la que ya estuvo en esta partida, modificando las instrucciones para evitar repetir descripciones que el jugador ya conoce.

\subsection{Reglas Embebidas en Prompts}

Los prompts de generación incluyen secciones explícitas de reglas que actúan como especificación ejecutable para el modelo. Por ejemplo, \verb|PROMPT_STEP_3_DETAILS| (disponible en el Anexo \ref{anexo:prompts}) contiene bloques de ``RESTRICCIONES TÉCNICAS OBLIGATORIAS'':

\begin{itemize}
    \item \textbf{Conectividad global}: ``TODAS las ubicaciones deben ser accesibles desde cualquier punto del mundo - NO puede haber ubicaciones aisladas''
    \item \textbf{Bidireccionalidad}: ``Si A conecta con B, entonces B DEBE conectar con A''
    \item \textbf{Completabilidad}: ``El objetivo DEBE ser completable con los elementos que crees''
    \item \textbf{Consistencia de referencias}: ``Todo objeto en inventarios de personajes DEBE existir en la lista de objetos del mundo''
\end{itemize}

Estas reglas tienen una relación muy cercana con las validaciones posteriores que hacemos en el código, y observamos que incluirlas en el prompt reduce la cantidad de mundos rechazados en validación. En experimentos preliminares notamos que el modelo tiende a seguir instrucciones explícitas cuando están claramente enumeradas y destacadas tipográficamente.

\subsection{Instrucciones Multilingües Consistentes}

Todos los prompts principales tienen versiones en español e inglés mantenidas en paralelo, que se seleccionan según el parámetro \verb|language|. Una instrucción crítica al final de cada prompt en español es: ``La respuesta DEBE estar íntegramente en español. Todos los valores de texto deben ser generados en español. Las claves del JSON deben permanecer en inglés para coincidir con el esquema''. Tuvimos que agregar esta regla porque las claves de los esquemas Pydantic están en inglés y, en ocasiones, la salida del modelo no estaba completamente en español.

Esta arquitectura facilita mantener coherencia entre idiomas aunque sería complicado agregar soporte para más idiomas aparte de español e inglés, porque requeriría extender manualmente todos los diccionarios de prompts.

\subsection{Validación por Capas con Reintentos}

Como mencionamos en la Sección sobre orquestación del pipeline, implementamos validación multicapa después de cada etapa, con reintentos automáticos. Si cualquier validación falla (descritas en la Sección \ref{sec:validaciones} del Capítulo \ref{cap:diseno}), el LLM se vuelve a llamar. El sistema imprime el error específico, incrementa el contador de intentos y regenera desde el modelo. Configuramos un máximo de tres intentos por defecto, lanzando \verb|ValueError| si se agotan.

\subsection{Manejo de Errores de API}

Los adaptadores de modelos (\verb|GeminiModel|, \verb|OpenAIModel|) implementan manejo robusto de errores de red. Gracias a esta funcionalidad, pudimos detectar automáticamente aquellos casos en que los servicios estaban sobrecargados (error 503) y aplicar reintentos con una espera fija de 2 segundos. Para OpenAI también manejamos limitaciones de tasa (\textit{rate limiting}, error 429) con espera exponencial (\textit{exponential backoff}): la espera se duplica en cada reintento.

\verb|prompt_model_structured()| en \verb|GeminiModel| maneja casos especiales de JSON malformado mediante verificaciones específicas. En primer lugar, si la respuesta incluye marcadores markdown (\verb|```json|), los remueve automáticamente. Además, implementamos \verb|_is_json_complete()| que valida heurísticamente la completitud del JSON mediante tres verificaciones secuenciales: la respuesta no está vacía, la cuenta de llaves de apertura/cierre coincide, y la cuenta de corchetes de apertura/cierre coincide. Si detectamos JSON incompleto, reintentamos la generación completa hasta un máximo de intentos configurado.

Cuando se agotan los reintentos, los métodos \verb|prompt_model()| retornan mensajes de error legibles para el usuario, mientras que \verb|prompt_model_structured()| retorna estructuras vacías válidas. Este método inspecciona el esquema esperado e intenta instanciar un objeto mínimo compatible, priorizando que el sistema continúe funcionando sobre generar contenido rico, pero arriesgando a que el sistema presente fallos.

\section{Interfaz de Usuario con Streamlit}

La interfaz de usuario determina cómo los jugadores interactúan con el sistema de diálogo y experimentan la narrativa generada. Implementamos una interfaz web con la biblioteca Streamlit que balancea accesibilidad para usuarios no técnicos con funcionalidades avanzadas para desarrollo y testing. La Figura \ref{fig:interfaz} muestra la interfaz.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figs/interfaz.png}
    \caption{Nueva interfaz del sistema en Streamlit}
    \label{fig:interfaz}
\end{figure}

\subsection{Modos de Juego} \label{sec:modos_juego}

Migramos la interfaz original de PAYADOR que usaba Gradio a Streamlit durante el desarrollo, priorizando mejor integración con el ciclo de desarrollo Python y mayor control sobre layout y componentes personalizados. Para entender este cambio, es importante mencionar que la interfaz original de PAYADOR usaba la biblioteca Gradio, que proporcionaba funcionalidad básica pero limitada personalización.

Diseñamos cinco modos de generación de mundos que ofrecen diferentes niveles de control y previsibilidad. La Figura \ref{fig:interfaz} muestra el selector de modos en el sidebar izquierdo, donde el usuario puede elegir entre: Generate, Inspiration, Preset, Tutorial y Replay. Cuando el usuario selecciona cada modo, la interfaz adapta los controles mostrados.

\subsubsection{Modo Inspiration}

El modo \texttt{inspiration} permite al usuario proporcionar una frase o temática que inspira la generación del mundo, como definimos en la Sección \ref{sec:pipeline} del capítulo anterior. Implementamos un campo de texto donde el usuario ingresa conceptos (p. ej.: ``el misterio sobre el robo del cuadro'' o ``exploración espacial en una estación abandonada''). Este input se pasa directamente como parámetro \verb|theme| a \verb|run_step_1_concept()|, como se explicó en el Capítulo \ref{cap:diseno}.

Agregamos sugerencias populares predefinidas como botones que, al ser seleccionados, completan automáticamente el campo de texto con descripciones más detalladas. Esta funcionalidad reduce la barrera de entrada para usuarios que no tienen clara una temática inicial.

Cuando generamos el mundo desde un texto de inspiración (correspondiente al modo \texttt{inspiration} detallado en la Sección \ref{sec:modos_juego}), el sistema ejecuta las cuatro etapas del pipeline de forma secuencial con feedback visual. Cada etapa muestra su mensaje de progreso (p. ej.: ``Etapa 1: Generando concepto del mundo...''), actualiza una barra de progreso y muestra mensajes de confirmación con detalles. Este feedback permite informarle al usuario sobre el proceso que se está ejecutando, durante los 30-60 segundos que típicamente toma la generación completa.

\subsubsection{Modo Generate}

El modo \texttt{generate} crea mundos completamente aleatorios sin input del usuario, como se describió en la Sección \ref{sec:pipeline}. Este modo solicita al modelo proponer un tema original y luego procede con el pipeline completo. Observamos durante el desarrollo que este modo produce mundos variados e inesperados, aunque el conjunto de conceptos que el modelo maneja es relativamente limitado, porque notamos repetición de conceptos, personajes o lugares. Probablemente esto esté relacionado con el caché que el modelo mantiene. Como se alinea con la limitación que tienen los modelos al generar narrativa con temáticas diferentes \cite{garcia2024payador, ammanabrolu2024letter}, esta falta de variación temática es un problema conocido en el campo.

El botón único ``Generate Random World'' minimiza la fricción al usuario, lo cual es ideal para iteración rápida durante desarrollo.

\subsubsection{Modo Preset}

Por otro lado, el modo \texttt{preset} carga mundos preconstruidos manualmente desde \verb|example_worlds.py|. Implementamos una interfaz de selección con botones para cada mundo disponible. Los mundos preset son fundamentales durante desarrollo: como su construcción manual asegura que no hay errores y que están estáticos (el modelo no genera nada), permiten testear funcionalidad del motor de juego sin la variabilidad introducida por generación con modelo.

\subsubsection{Modo Replay}

Finalmente, el modo \texttt{replay} permite cargar partidas guardadas desde MongoDB mediante \verb|world_id|, como se explicó en la Sección \ref{sec:mongodb}. Este modo rehidrata el mundo completo usando \verb|jsonpickle.decode()|, permitiéndole al jugador acceder tanto al mundo jugable como a sus detalles: el objetivo, las ubicaciones que contenía, un diagrama visual del mundo, entre otros. Esta funcionalidad también fue útil para la etapa de evaluación, la cual se discutirá en el Capítulo \ref{cap:evaluacion}.

\subsection{Arquitectura de Sesión con Streamlit}

Streamlit usa un modelo de ejecución stateless donde cada interacción re-ejecuta el script completo. Manejamos estado persistente mediante \verb|st.session_state|, un diccionario que sobrevive entre ejecuciones. Almacenamos allí el objeto \verb|World|, el \verb|game_loop|, el historial de chat, ubicaciones visitadas, configuración de idioma y modo de generación.

Ya que cada interacción puede modificar el estado, también implementamos inicialización condicional al inicio del código: verificamos existencia de cada clave antes de crear valores por defecto. Esta inicialización lazy previene resetear estado cuando el usuario interactúa con otros widgets (los widgets son los componentes interactivos de la interfaz como botones, campos de texto y selectores).

\subsection{Interfaz de Chat Conversacional}

El núcleo de la UI es una interfaz de chat implementada con \verb|st.chat_message()| y \verb|st.chat_input()|. Mantenemos \verb|chat_history| como lista de diccionarios con estructura \verb|\{``role'': ``user''|``assistant'', ``content'': texto\}|.

\subsection{Visualización del Grafo con Mermaid.js}

Generamos visualizaciones del mundo como diagramas de grafo usando sintaxis Mermaid. Un módulo especializado exporta el mundo a formato Mermaid\footnote{\url{https://mermaid.js.org/}}, que es una biblioteca JavaScript para crear diagramas a partir de definiciones textuales. La función \verb|render_mermaid()| en la UI lo renderiza mediante una página HTML embebida con Mermaid.js desde CDN. Esta visualización permite al usuario (o a nosotros durante el desarrollo) ver la estructura completa del mundo como un grafo navegable. Incluimos un screenshot de esta funcionalidad en la Figura \ref{fig:mermaid_viz}, que ilustra cómo el concepto neurosimbólico permite tanto generar contenido mediante el modelo como validar y visualizar su estructura mediante el sistema simbólico.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/mermaid-example.png}
    \caption{Visualización de un mundo generado usando Mermaid.js}
    \label{fig:mermaid_viz}
\end{figure}

\subsection{Sidebar de Configuración}

Implementamos un sidebar persistente con \verb|st.sidebar| que contiene controles de configuración global (p. ej.: selector de idioma español/inglés, selector de modo de generación, campo de identificación del jugador y opción de modo de depuración). Bloqueamos estos controles durante juego activo para prevenir cambios de configuración que corrompan el estado del mundo a mitad de partida.

La identificación del jugador que se puede ingresar en el sidebar permite distinguir entre diferentes evaluadores en las trazas guardadas. Esta funcionalidad podría tener otros usos a futuro, como personalización de la narrativa o análisis de patrones de juego por usuario.

\subsection{Experiencia de Usuario Multilingüe}

Soportar múltiples idiomas no es solo traducir strings de la interfaz, sino garantizar coherencia narrativa completa en cada idioma. Centralizamos todos los textos de UI en \verb|ui_components.py| mediante funciones que retornan diccionarios de strings. Cada string tiene una clave invariante y valores específicos por idioma.

El parámetro \verb|language| se propaga a través de toda la cadena de generación: desde la UI hasta los prompts del modelo. Los prompts tienen versiones paralelas, y funciones dispatcher seleccionan la versión correcta.

El sistema RAG mantiene consistencia de idioma almacenando el parámetro \verb|language| en metadatos de trazas MongoDB. Al cargar memorias con \verb|load_memories_from_db()|, usamos el idioma original de la traza para regenerar resúmenes.

Nos preguntamos: ¿de dónde viene la necesidad de sincronización entre versiones de idiomas? La sincronización se refiere a mantener paridad entre las versiones en español e inglés de los prompts y textos de interfaz. Por ejemplo, si agregamos un objeto a la versión española de un prompt, debemos recordar agregarlo a la inglesa. Implementamos validaciones básicas que verifican estructura paralela, aunque no pueden verificar equivalencia semántica completa de contenidos. Esto es relevante cuando mantenemos mundos preset o prompts en ambos idiomas.

\section{Conclusiones del Capítulo}

Este capítulo presentó cómo los diseños conceptuales del Capítulo \ref{cap:diseno} se materializan mediante tecnologías específicas. Describimos la integración con modelos de lenguaje mediante Pydantic, la orquestación del pipeline con reintentos y validaciones, el ciclo de juego que balancea generación narrativa con mecánicas deterministas, el sistema RAG con embeddings y ChromaDB, la persistencia de trazas con MongoDB para reproducibilidad, las estrategias de prompting con manejo robusto de errores, y la interfaz de usuario con Streamlit.

En el siguiente capítulo presentaremos la evaluación del sistema con usuarios reales, analizando tanto las fortalezas del enfoque incremental como las limitaciones observadas durante las pruebas.
